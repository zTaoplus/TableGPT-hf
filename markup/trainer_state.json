{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7478188616535106,
  "eval_steps": 100,
  "global_step": 1800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008309098462816784,
      "grad_norm": 1.089022159576416,
      "learning_rate": 1.6155546744299638e-06,
      "loss": 0.642,
      "step": 2
    },
    {
      "epoch": 0.0016618196925633569,
      "grad_norm": 0.9815763831138611,
      "learning_rate": 3.2311093488599276e-06,
      "loss": 0.6233,
      "step": 4
    },
    {
      "epoch": 0.0024927295388450354,
      "grad_norm": 1.0434454679489136,
      "learning_rate": 4.176148251266233e-06,
      "loss": 0.5941,
      "step": 6
    },
    {
      "epoch": 0.0033236393851267137,
      "grad_norm": 0.5963555574417114,
      "learning_rate": 4.846664023289891e-06,
      "loss": 0.5749,
      "step": 8
    },
    {
      "epoch": 0.004154549231408392,
      "grad_norm": 0.6162733435630798,
      "learning_rate": 5.366756461815503e-06,
      "loss": 0.5708,
      "step": 10
    },
    {
      "epoch": 0.004985459077690071,
      "grad_norm": 0.6379160284996033,
      "learning_rate": 5.791702925696196e-06,
      "loss": 0.5513,
      "step": 12
    },
    {
      "epoch": 0.005816368923971749,
      "grad_norm": 0.5352903604507446,
      "learning_rate": 6.150990041544092e-06,
      "loss": 0.5404,
      "step": 14
    },
    {
      "epoch": 0.006647278770253427,
      "grad_norm": 0.4780384302139282,
      "learning_rate": 6.462218697719855e-06,
      "loss": 0.5361,
      "step": 16
    },
    {
      "epoch": 0.007478188616535106,
      "grad_norm": 0.4527023732662201,
      "learning_rate": 6.736741828102501e-06,
      "loss": 0.5426,
      "step": 18
    },
    {
      "epoch": 0.008309098462816784,
      "grad_norm": 0.44566652178764343,
      "learning_rate": 6.9823111362454665e-06,
      "loss": 0.5248,
      "step": 20
    },
    {
      "epoch": 0.009140008309098464,
      "grad_norm": 0.4546664357185364,
      "learning_rate": 7.204455596790266e-06,
      "loss": 0.5497,
      "step": 22
    },
    {
      "epoch": 0.009970918155380142,
      "grad_norm": 0.42800113558769226,
      "learning_rate": 7.407257600126161e-06,
      "loss": 0.5321,
      "step": 24
    },
    {
      "epoch": 0.01080182800166182,
      "grad_norm": 0.4123365581035614,
      "learning_rate": 7.593817358519103e-06,
      "loss": 0.5204,
      "step": 26
    },
    {
      "epoch": 0.011632737847943497,
      "grad_norm": 0.4245568811893463,
      "learning_rate": 7.766544715974056e-06,
      "loss": 0.5065,
      "step": 28
    },
    {
      "epoch": 0.012463647694225177,
      "grad_norm": 0.4247898757457733,
      "learning_rate": 7.927350038651771e-06,
      "loss": 0.5219,
      "step": 30
    },
    {
      "epoch": 0.013294557540506855,
      "grad_norm": 0.40010368824005127,
      "learning_rate": 8.07777337214982e-06,
      "loss": 0.5057,
      "step": 32
    },
    {
      "epoch": 0.014125467386788533,
      "grad_norm": 0.41238918900489807,
      "learning_rate": 8.21907437417073e-06,
      "loss": 0.5237,
      "step": 34
    },
    {
      "epoch": 0.014956377233070212,
      "grad_norm": 0.4247264862060547,
      "learning_rate": 8.352296502532466e-06,
      "loss": 0.5063,
      "step": 36
    },
    {
      "epoch": 0.01578728707935189,
      "grad_norm": 0.3864520788192749,
      "learning_rate": 8.4783138254134e-06,
      "loss": 0.508,
      "step": 38
    },
    {
      "epoch": 0.016618196925633568,
      "grad_norm": 0.4220370650291443,
      "learning_rate": 8.59786581067543e-06,
      "loss": 0.5038,
      "step": 40
    },
    {
      "epoch": 0.017449106771915246,
      "grad_norm": 0.40105101466178894,
      "learning_rate": 8.711583618380362e-06,
      "loss": 0.5106,
      "step": 42
    },
    {
      "epoch": 0.018280016618196927,
      "grad_norm": 0.4071868360042572,
      "learning_rate": 8.82001027122023e-06,
      "loss": 0.4948,
      "step": 44
    },
    {
      "epoch": 0.019110926464478605,
      "grad_norm": 0.40586385130882263,
      "learning_rate": 8.923616337611421e-06,
      "loss": 0.4931,
      "step": 46
    },
    {
      "epoch": 0.019941836310760283,
      "grad_norm": 0.4099101126194,
      "learning_rate": 9.022812274556125e-06,
      "loss": 0.4969,
      "step": 48
    },
    {
      "epoch": 0.02077274615704196,
      "grad_norm": 0.406324565410614,
      "learning_rate": 9.117958249201042e-06,
      "loss": 0.4872,
      "step": 50
    },
    {
      "epoch": 0.02160365600332364,
      "grad_norm": 0.3798843324184418,
      "learning_rate": 9.209372032949067e-06,
      "loss": 0.5046,
      "step": 52
    },
    {
      "epoch": 0.022434565849605317,
      "grad_norm": 0.43784841895103455,
      "learning_rate": 9.297335404938772e-06,
      "loss": 0.49,
      "step": 54
    },
    {
      "epoch": 0.023265475695886995,
      "grad_norm": 0.3758995831012726,
      "learning_rate": 9.382099390404021e-06,
      "loss": 0.4886,
      "step": 56
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 0.39702391624450684,
      "learning_rate": 9.46388857940024e-06,
      "loss": 0.501,
      "step": 58
    },
    {
      "epoch": 0.024927295388450354,
      "grad_norm": 0.4044371545314789,
      "learning_rate": 9.542904713081735e-06,
      "loss": 0.4989,
      "step": 60
    },
    {
      "epoch": 0.02575820523473203,
      "grad_norm": 0.40961170196533203,
      "learning_rate": 9.61932968171916e-06,
      "loss": 0.4972,
      "step": 62
    },
    {
      "epoch": 0.02658911508101371,
      "grad_norm": 0.40774595737457275,
      "learning_rate": 9.693328046579783e-06,
      "loss": 0.5112,
      "step": 64
    },
    {
      "epoch": 0.027420024927295387,
      "grad_norm": 0.38950157165527344,
      "learning_rate": 9.765049173626534e-06,
      "loss": 0.4815,
      "step": 66
    },
    {
      "epoch": 0.028250934773577065,
      "grad_norm": 0.4139240086078644,
      "learning_rate": 9.834629048600696e-06,
      "loss": 0.494,
      "step": 68
    },
    {
      "epoch": 0.029081844619858747,
      "grad_norm": 0.3895152509212494,
      "learning_rate": 9.902191828929632e-06,
      "loss": 0.4961,
      "step": 70
    },
    {
      "epoch": 0.029912754466140425,
      "grad_norm": 0.41599810123443604,
      "learning_rate": 9.967851176962429e-06,
      "loss": 0.4831,
      "step": 72
    },
    {
      "epoch": 0.030743664312422102,
      "grad_norm": 0.38586515188217163,
      "learning_rate": 1e-05,
      "loss": 0.4891,
      "step": 74
    },
    {
      "epoch": 0.03157457415870378,
      "grad_norm": 0.42240798473358154,
      "learning_rate": 1e-05,
      "loss": 0.498,
      "step": 76
    },
    {
      "epoch": 0.03240548400498546,
      "grad_norm": 0.4082052707672119,
      "learning_rate": 1e-05,
      "loss": 0.5065,
      "step": 78
    },
    {
      "epoch": 0.033236393851267136,
      "grad_norm": 0.39114272594451904,
      "learning_rate": 1e-05,
      "loss": 0.5058,
      "step": 80
    },
    {
      "epoch": 0.03406730369754882,
      "grad_norm": 0.3758786916732788,
      "learning_rate": 1e-05,
      "loss": 0.4778,
      "step": 82
    },
    {
      "epoch": 0.03489821354383049,
      "grad_norm": 0.40339937806129456,
      "learning_rate": 1e-05,
      "loss": 0.4871,
      "step": 84
    },
    {
      "epoch": 0.03572912339011217,
      "grad_norm": 0.3937039077281952,
      "learning_rate": 1e-05,
      "loss": 0.4884,
      "step": 86
    },
    {
      "epoch": 0.036560033236393855,
      "grad_norm": 0.39950326085090637,
      "learning_rate": 1e-05,
      "loss": 0.4911,
      "step": 88
    },
    {
      "epoch": 0.03739094308267553,
      "grad_norm": 0.40640124678611755,
      "learning_rate": 1e-05,
      "loss": 0.4938,
      "step": 90
    },
    {
      "epoch": 0.03822185292895721,
      "grad_norm": 0.3924129903316498,
      "learning_rate": 1e-05,
      "loss": 0.4749,
      "step": 92
    },
    {
      "epoch": 0.039052762775238885,
      "grad_norm": 0.41971638798713684,
      "learning_rate": 1e-05,
      "loss": 0.5009,
      "step": 94
    },
    {
      "epoch": 0.039883672621520566,
      "grad_norm": 0.41278988122940063,
      "learning_rate": 1e-05,
      "loss": 0.4774,
      "step": 96
    },
    {
      "epoch": 0.04071458246780224,
      "grad_norm": 0.4028111398220062,
      "learning_rate": 1e-05,
      "loss": 0.4972,
      "step": 98
    },
    {
      "epoch": 0.04154549231408392,
      "grad_norm": 0.38868770003318787,
      "learning_rate": 1e-05,
      "loss": 0.5061,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_alpaca_gpt4_zh.json_loss": 1.3997056484222412,
      "eval_alpaca_gpt4_zh.json_runtime": 1.5167,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 431.864,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.461,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_ultrainteract_sft.json_loss": 0.49314773082733154,
      "eval_ultrainteract_sft.json_runtime": 18.0377,
      "eval_ultrainteract_sft.json_samples_per_second": 159.111,
      "eval_ultrainteract_sft.json_steps_per_second": 6.653,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_code_feedback_multi_turn.json_loss": 0.5926230549812317,
      "eval_code_feedback_multi_turn.json_runtime": 15.6326,
      "eval_code_feedback_multi_turn.json_samples_per_second": 64.992,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.751,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_tested_143k_python_alpaca.json_loss": 0.3845483958721161,
      "eval_tested_143k_python_alpaca.json_runtime": 14.0687,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.763,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.895,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_synthetic_text_to_sql.json_loss": 0.18924549221992493,
      "eval_synthetic_text_to_sql.json_runtime": 3.3674,
      "eval_synthetic_text_to_sql.json_samples_per_second": 414.267,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.521,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_codefeedback_filtered_instruction.json_loss": 0.452396959066391,
      "eval_codefeedback_filtered_instruction.json_runtime": 9.9762,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.617,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.317,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_train_data_for_qwen.json_loss": 0.03302949294447899,
      "eval_train_data_for_qwen.json_runtime": 3.6722,
      "eval_train_data_for_qwen.json_samples_per_second": 119.821,
      "eval_train_data_for_qwen.json_steps_per_second": 5.174,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.5227365493774414,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8851,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 395.204,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.975,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_all_merge_code.json_loss": 0.27760905027389526,
      "eval_all_merge_code.json_runtime": 16.8673,
      "eval_all_merge_code.json_samples_per_second": 205.249,
      "eval_all_merge_code.json_steps_per_second": 8.597,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_xlam_function_calling_60k.json_loss": 0.029053715988993645,
      "eval_xlam_function_calling_60k.json_runtime": 4.3986,
      "eval_xlam_function_calling_60k.json_samples_per_second": 201.653,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.412,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_table_python_code_datas.json_loss": 0.2059054672718048,
      "eval_table_python_code_datas.json_runtime": 66.631,
      "eval_table_python_code_datas.json_samples_per_second": 69.997,
      "eval_table_python_code_datas.json_steps_per_second": 2.927,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_Table_GPT.json_loss": 0.10291070491075516,
      "eval_Table_GPT.json_runtime": 10.6856,
      "eval_Table_GPT.json_samples_per_second": 83.009,
      "eval_Table_GPT.json_steps_per_second": 3.463,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_tabular_llm_data.json_loss": 0.1424272358417511,
      "eval_tabular_llm_data.json_runtime": 50.5957,
      "eval_tabular_llm_data.json_samples_per_second": 57.91,
      "eval_tabular_llm_data.json_steps_per_second": 2.431,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_gpt_4o_200k.json_loss": 0.8805375695228577,
      "eval_gpt_4o_200k.json_runtime": 27.2701,
      "eval_gpt_4o_200k.json_samples_per_second": 130.949,
      "eval_gpt_4o_200k.json_steps_per_second": 5.464,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_MathInstruct.json_loss": 0.18097896873950958,
      "eval_MathInstruct.json_runtime": 12.998,
      "eval_MathInstruct.json_samples_per_second": 251.962,
      "eval_MathInstruct.json_steps_per_second": 10.54,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_alpaca_cleaned.json_loss": 0.9604266881942749,
      "eval_alpaca_cleaned.json_runtime": 2.3787,
      "eval_alpaca_cleaned.json_samples_per_second": 374.154,
      "eval_alpaca_cleaned.json_steps_per_second": 15.975,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_multi_turn_datas_0816.json_loss": 0.37960726022720337,
      "eval_multi_turn_datas_0816.json_runtime": 71.2302,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.419,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.401,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_sharegpt_gpt4.json_loss": 0.7926105260848999,
      "eval_sharegpt_gpt4.json_runtime": 21.6967,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.969,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.811,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_python_code_critic_21k.json_loss": 0.6935310363769531,
      "eval_python_code_critic_21k.json_runtime": 1.9498,
      "eval_python_code_critic_21k.json_samples_per_second": 148.217,
      "eval_python_code_critic_21k.json_steps_per_second": 6.667,
      "step": 100
    },
    {
      "epoch": 0.04154549231408392,
      "eval_agent_instruct.json_loss": 0.412548691034317,
      "eval_agent_instruct.json_runtime": 0.2478,
      "eval_agent_instruct.json_samples_per_second": 88.792,
      "eval_agent_instruct.json_steps_per_second": 4.036,
      "step": 100
    },
    {
      "epoch": 0.0423764021603656,
      "grad_norm": 0.39699098467826843,
      "learning_rate": 1e-05,
      "loss": 0.4951,
      "step": 102
    },
    {
      "epoch": 0.04320731200664728,
      "grad_norm": 0.3797388970851898,
      "learning_rate": 1e-05,
      "loss": 0.4842,
      "step": 104
    },
    {
      "epoch": 0.04403822185292896,
      "grad_norm": 0.39232781529426575,
      "learning_rate": 1e-05,
      "loss": 0.4704,
      "step": 106
    },
    {
      "epoch": 0.04486913169921063,
      "grad_norm": 0.4147080183029175,
      "learning_rate": 1e-05,
      "loss": 0.4709,
      "step": 108
    },
    {
      "epoch": 0.045700041545492315,
      "grad_norm": 0.39272984862327576,
      "learning_rate": 1e-05,
      "loss": 0.486,
      "step": 110
    },
    {
      "epoch": 0.04653095139177399,
      "grad_norm": 0.4013234078884125,
      "learning_rate": 1e-05,
      "loss": 0.4878,
      "step": 112
    },
    {
      "epoch": 0.04736186123805567,
      "grad_norm": 0.39967939257621765,
      "learning_rate": 1e-05,
      "loss": 0.4541,
      "step": 114
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 0.4109064042568207,
      "learning_rate": 1e-05,
      "loss": 0.4827,
      "step": 116
    },
    {
      "epoch": 0.049023680930619026,
      "grad_norm": 0.3964918553829193,
      "learning_rate": 1e-05,
      "loss": 0.4835,
      "step": 118
    },
    {
      "epoch": 0.04985459077690071,
      "grad_norm": 0.3853227496147156,
      "learning_rate": 1e-05,
      "loss": 0.4817,
      "step": 120
    },
    {
      "epoch": 0.05068550062318238,
      "grad_norm": 0.416704922914505,
      "learning_rate": 1e-05,
      "loss": 0.4892,
      "step": 122
    },
    {
      "epoch": 0.05151641046946406,
      "grad_norm": 0.40346354246139526,
      "learning_rate": 1e-05,
      "loss": 0.5067,
      "step": 124
    },
    {
      "epoch": 0.052347320315745745,
      "grad_norm": 0.3858357071876526,
      "learning_rate": 1e-05,
      "loss": 0.4719,
      "step": 126
    },
    {
      "epoch": 0.05317823016202742,
      "grad_norm": 0.4062234163284302,
      "learning_rate": 1e-05,
      "loss": 0.4975,
      "step": 128
    },
    {
      "epoch": 0.0540091400083091,
      "grad_norm": 0.3902006447315216,
      "learning_rate": 1e-05,
      "loss": 0.4775,
      "step": 130
    },
    {
      "epoch": 0.054840049854590775,
      "grad_norm": 0.3962676227092743,
      "learning_rate": 1e-05,
      "loss": 0.5028,
      "step": 132
    },
    {
      "epoch": 0.055670959700872456,
      "grad_norm": 0.3826255798339844,
      "learning_rate": 1e-05,
      "loss": 0.4983,
      "step": 134
    },
    {
      "epoch": 0.05650186954715413,
      "grad_norm": 0.3956339955329895,
      "learning_rate": 1e-05,
      "loss": 0.4811,
      "step": 136
    },
    {
      "epoch": 0.05733277939343581,
      "grad_norm": 0.4008605480194092,
      "learning_rate": 1e-05,
      "loss": 0.4766,
      "step": 138
    },
    {
      "epoch": 0.05816368923971749,
      "grad_norm": 0.39566484093666077,
      "learning_rate": 1e-05,
      "loss": 0.4783,
      "step": 140
    },
    {
      "epoch": 0.05899459908599917,
      "grad_norm": 0.38632383942604065,
      "learning_rate": 1e-05,
      "loss": 0.47,
      "step": 142
    },
    {
      "epoch": 0.05982550893228085,
      "grad_norm": 0.38042911887168884,
      "learning_rate": 1e-05,
      "loss": 0.4688,
      "step": 144
    },
    {
      "epoch": 0.060656418778562524,
      "grad_norm": 0.38130396604537964,
      "learning_rate": 1e-05,
      "loss": 0.4702,
      "step": 146
    },
    {
      "epoch": 0.061487328624844205,
      "grad_norm": 0.38854876160621643,
      "learning_rate": 1e-05,
      "loss": 0.4817,
      "step": 148
    },
    {
      "epoch": 0.06231823847112588,
      "grad_norm": 0.38222822546958923,
      "learning_rate": 1e-05,
      "loss": 0.4789,
      "step": 150
    },
    {
      "epoch": 0.06314914831740756,
      "grad_norm": 0.3624544143676758,
      "learning_rate": 1e-05,
      "loss": 0.4701,
      "step": 152
    },
    {
      "epoch": 0.06398005816368924,
      "grad_norm": 0.3881637752056122,
      "learning_rate": 1e-05,
      "loss": 0.4697,
      "step": 154
    },
    {
      "epoch": 0.06481096800997092,
      "grad_norm": 0.37969231605529785,
      "learning_rate": 1e-05,
      "loss": 0.4698,
      "step": 156
    },
    {
      "epoch": 0.0656418778562526,
      "grad_norm": 0.3876888155937195,
      "learning_rate": 1e-05,
      "loss": 0.4811,
      "step": 158
    },
    {
      "epoch": 0.06647278770253427,
      "grad_norm": 0.3710530400276184,
      "learning_rate": 1e-05,
      "loss": 0.4832,
      "step": 160
    },
    {
      "epoch": 0.06730369754881595,
      "grad_norm": 0.38774943351745605,
      "learning_rate": 1e-05,
      "loss": 0.4867,
      "step": 162
    },
    {
      "epoch": 0.06813460739509763,
      "grad_norm": 0.4072688817977905,
      "learning_rate": 1e-05,
      "loss": 0.4773,
      "step": 164
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.39731457829475403,
      "learning_rate": 1e-05,
      "loss": 0.4705,
      "step": 166
    },
    {
      "epoch": 0.06979642708766098,
      "grad_norm": 0.38253140449523926,
      "learning_rate": 1e-05,
      "loss": 0.4858,
      "step": 168
    },
    {
      "epoch": 0.07062733693394267,
      "grad_norm": 0.39321497082710266,
      "learning_rate": 1e-05,
      "loss": 0.4746,
      "step": 170
    },
    {
      "epoch": 0.07145824678022435,
      "grad_norm": 0.38764169812202454,
      "learning_rate": 1e-05,
      "loss": 0.4719,
      "step": 172
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 0.40300771594047546,
      "learning_rate": 1e-05,
      "loss": 0.473,
      "step": 174
    },
    {
      "epoch": 0.07312006647278771,
      "grad_norm": 0.38746315240859985,
      "learning_rate": 1e-05,
      "loss": 0.462,
      "step": 176
    },
    {
      "epoch": 0.07395097631906938,
      "grad_norm": 0.3941344916820526,
      "learning_rate": 1e-05,
      "loss": 0.4758,
      "step": 178
    },
    {
      "epoch": 0.07478188616535106,
      "grad_norm": 0.3742758333683014,
      "learning_rate": 1e-05,
      "loss": 0.4557,
      "step": 180
    },
    {
      "epoch": 0.07561279601163273,
      "grad_norm": 0.39056631922721863,
      "learning_rate": 1e-05,
      "loss": 0.4611,
      "step": 182
    },
    {
      "epoch": 0.07644370585791442,
      "grad_norm": 0.38500699400901794,
      "learning_rate": 1e-05,
      "loss": 0.4814,
      "step": 184
    },
    {
      "epoch": 0.0772746157041961,
      "grad_norm": 0.38584327697753906,
      "learning_rate": 1e-05,
      "loss": 0.4752,
      "step": 186
    },
    {
      "epoch": 0.07810552555047777,
      "grad_norm": 0.4003129303455353,
      "learning_rate": 1e-05,
      "loss": 0.474,
      "step": 188
    },
    {
      "epoch": 0.07893643539675946,
      "grad_norm": 0.3768055737018585,
      "learning_rate": 1e-05,
      "loss": 0.4754,
      "step": 190
    },
    {
      "epoch": 0.07976734524304113,
      "grad_norm": 0.40754181146621704,
      "learning_rate": 1e-05,
      "loss": 0.485,
      "step": 192
    },
    {
      "epoch": 0.0805982550893228,
      "grad_norm": 0.4062899351119995,
      "learning_rate": 1e-05,
      "loss": 0.4818,
      "step": 194
    },
    {
      "epoch": 0.08142916493560448,
      "grad_norm": 0.4031081199645996,
      "learning_rate": 1e-05,
      "loss": 0.4899,
      "step": 196
    },
    {
      "epoch": 0.08226007478188617,
      "grad_norm": 0.4203024208545685,
      "learning_rate": 1e-05,
      "loss": 0.4731,
      "step": 198
    },
    {
      "epoch": 0.08309098462816784,
      "grad_norm": 0.3789962828159332,
      "learning_rate": 1e-05,
      "loss": 0.4697,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_alpaca_gpt4_zh.json_loss": 1.3937013149261475,
      "eval_alpaca_gpt4_zh.json_runtime": 1.5779,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 415.103,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 17.745,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_ultrainteract_sft.json_loss": 0.48087990283966064,
      "eval_ultrainteract_sft.json_runtime": 18.0898,
      "eval_ultrainteract_sft.json_samples_per_second": 158.653,
      "eval_ultrainteract_sft.json_steps_per_second": 6.634,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_code_feedback_multi_turn.json_loss": 0.5856905579566956,
      "eval_code_feedback_multi_turn.json_runtime": 15.2998,
      "eval_code_feedback_multi_turn.json_samples_per_second": 66.406,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.81,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_tested_143k_python_alpaca.json_loss": 0.38071146607398987,
      "eval_tested_143k_python_alpaca.json_runtime": 14.571,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 159.083,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.657,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_synthetic_text_to_sql.json_loss": 0.1834651082754135,
      "eval_synthetic_text_to_sql.json_runtime": 3.4415,
      "eval_synthetic_text_to_sql.json_samples_per_second": 405.347,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.144,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_codefeedback_filtered_instruction.json_loss": 0.4459405839443207,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0032,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.144,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.298,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_train_data_for_qwen.json_loss": 0.027732888236641884,
      "eval_train_data_for_qwen.json_runtime": 3.6664,
      "eval_train_data_for_qwen.json_samples_per_second": 120.01,
      "eval_train_data_for_qwen.json_steps_per_second": 5.182,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.5004411935806274,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8955,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 393.034,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.882,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_all_merge_code.json_loss": 0.27034658193588257,
      "eval_all_merge_code.json_runtime": 16.7802,
      "eval_all_merge_code.json_samples_per_second": 206.314,
      "eval_all_merge_code.json_steps_per_second": 8.641,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_xlam_function_calling_60k.json_loss": 0.025544606149196625,
      "eval_xlam_function_calling_60k.json_runtime": 4.4785,
      "eval_xlam_function_calling_60k.json_samples_per_second": 198.059,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.262,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_table_python_code_datas.json_loss": 0.18892470002174377,
      "eval_table_python_code_datas.json_runtime": 66.2909,
      "eval_table_python_code_datas.json_samples_per_second": 70.357,
      "eval_table_python_code_datas.json_steps_per_second": 2.942,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_Table_GPT.json_loss": 0.08769090473651886,
      "eval_Table_GPT.json_runtime": 10.5864,
      "eval_Table_GPT.json_samples_per_second": 83.787,
      "eval_Table_GPT.json_steps_per_second": 3.495,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_tabular_llm_data.json_loss": 0.13387778401374817,
      "eval_tabular_llm_data.json_runtime": 50.6178,
      "eval_tabular_llm_data.json_samples_per_second": 57.885,
      "eval_tabular_llm_data.json_steps_per_second": 2.43,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_gpt_4o_200k.json_loss": 0.8706625699996948,
      "eval_gpt_4o_200k.json_runtime": 27.2412,
      "eval_gpt_4o_200k.json_samples_per_second": 131.088,
      "eval_gpt_4o_200k.json_steps_per_second": 5.47,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_MathInstruct.json_loss": 0.1821545660495758,
      "eval_MathInstruct.json_runtime": 12.955,
      "eval_MathInstruct.json_samples_per_second": 252.798,
      "eval_MathInstruct.json_steps_per_second": 10.575,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_alpaca_cleaned.json_loss": 0.953500509262085,
      "eval_alpaca_cleaned.json_runtime": 2.477,
      "eval_alpaca_cleaned.json_samples_per_second": 359.31,
      "eval_alpaca_cleaned.json_steps_per_second": 15.341,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_multi_turn_datas_0816.json_loss": 0.36204150319099426,
      "eval_multi_turn_datas_0816.json_runtime": 71.0035,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.603,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.408,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_sharegpt_gpt4.json_loss": 0.7859343886375427,
      "eval_sharegpt_gpt4.json_runtime": 21.8373,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.537,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.793,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_python_code_critic_21k.json_loss": 0.670155942440033,
      "eval_python_code_critic_21k.json_runtime": 1.955,
      "eval_python_code_critic_21k.json_samples_per_second": 147.829,
      "eval_python_code_critic_21k.json_steps_per_second": 6.65,
      "step": 200
    },
    {
      "epoch": 0.08309098462816784,
      "eval_agent_instruct.json_loss": 0.25963565707206726,
      "eval_agent_instruct.json_runtime": 0.25,
      "eval_agent_instruct.json_samples_per_second": 88.001,
      "eval_agent_instruct.json_steps_per_second": 4.0,
      "step": 200
    },
    {
      "epoch": 0.08392189447444952,
      "grad_norm": 0.4241124391555786,
      "learning_rate": 1e-05,
      "loss": 0.4755,
      "step": 202
    },
    {
      "epoch": 0.0847528043207312,
      "grad_norm": 0.3872305154800415,
      "learning_rate": 1e-05,
      "loss": 0.4835,
      "step": 204
    },
    {
      "epoch": 0.08558371416701288,
      "grad_norm": 0.39577803015708923,
      "learning_rate": 1e-05,
      "loss": 0.474,
      "step": 206
    },
    {
      "epoch": 0.08641462401329456,
      "grad_norm": 0.3834820091724396,
      "learning_rate": 1e-05,
      "loss": 0.4861,
      "step": 208
    },
    {
      "epoch": 0.08724553385957623,
      "grad_norm": 0.39258092641830444,
      "learning_rate": 1e-05,
      "loss": 0.4867,
      "step": 210
    },
    {
      "epoch": 0.08807644370585792,
      "grad_norm": 0.388187974691391,
      "learning_rate": 1e-05,
      "loss": 0.4687,
      "step": 212
    },
    {
      "epoch": 0.08890735355213959,
      "grad_norm": 0.3739369511604309,
      "learning_rate": 1e-05,
      "loss": 0.4645,
      "step": 214
    },
    {
      "epoch": 0.08973826339842127,
      "grad_norm": 0.40178972482681274,
      "learning_rate": 1e-05,
      "loss": 0.4668,
      "step": 216
    },
    {
      "epoch": 0.09056917324470296,
      "grad_norm": 0.3905222713947296,
      "learning_rate": 1e-05,
      "loss": 0.4712,
      "step": 218
    },
    {
      "epoch": 0.09140008309098463,
      "grad_norm": 0.3990921676158905,
      "learning_rate": 1e-05,
      "loss": 0.4832,
      "step": 220
    },
    {
      "epoch": 0.0922309929372663,
      "grad_norm": 0.41032111644744873,
      "learning_rate": 1e-05,
      "loss": 0.4592,
      "step": 222
    },
    {
      "epoch": 0.09306190278354798,
      "grad_norm": 0.3870002031326294,
      "learning_rate": 1e-05,
      "loss": 0.4846,
      "step": 224
    },
    {
      "epoch": 0.09389281262982967,
      "grad_norm": 0.4083975553512573,
      "learning_rate": 1e-05,
      "loss": 0.4839,
      "step": 226
    },
    {
      "epoch": 0.09472372247611134,
      "grad_norm": 0.3854992091655731,
      "learning_rate": 1e-05,
      "loss": 0.4813,
      "step": 228
    },
    {
      "epoch": 0.09555463232239302,
      "grad_norm": 0.4331085979938507,
      "learning_rate": 1e-05,
      "loss": 0.4703,
      "step": 230
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 0.40281176567077637,
      "learning_rate": 1e-05,
      "loss": 0.4804,
      "step": 232
    },
    {
      "epoch": 0.09721645201495638,
      "grad_norm": 0.42869019508361816,
      "learning_rate": 1e-05,
      "loss": 0.4712,
      "step": 234
    },
    {
      "epoch": 0.09804736186123805,
      "grad_norm": 0.3803359568119049,
      "learning_rate": 1e-05,
      "loss": 0.4507,
      "step": 236
    },
    {
      "epoch": 0.09887827170751974,
      "grad_norm": 0.4039638042449951,
      "learning_rate": 1e-05,
      "loss": 0.4867,
      "step": 238
    },
    {
      "epoch": 0.09970918155380142,
      "grad_norm": 0.3940512239933014,
      "learning_rate": 1e-05,
      "loss": 0.4844,
      "step": 240
    },
    {
      "epoch": 0.10054009140008309,
      "grad_norm": 0.41648751497268677,
      "learning_rate": 1e-05,
      "loss": 0.4717,
      "step": 242
    },
    {
      "epoch": 0.10137100124636476,
      "grad_norm": 0.39018139243125916,
      "learning_rate": 1e-05,
      "loss": 0.4752,
      "step": 244
    },
    {
      "epoch": 0.10220191109264645,
      "grad_norm": 0.40828827023506165,
      "learning_rate": 1e-05,
      "loss": 0.4871,
      "step": 246
    },
    {
      "epoch": 0.10303282093892813,
      "grad_norm": 0.3828389346599579,
      "learning_rate": 1e-05,
      "loss": 0.4581,
      "step": 248
    },
    {
      "epoch": 0.1038637307852098,
      "grad_norm": 0.384918212890625,
      "learning_rate": 1e-05,
      "loss": 0.4709,
      "step": 250
    },
    {
      "epoch": 0.10469464063149149,
      "grad_norm": 0.39105528593063354,
      "learning_rate": 1e-05,
      "loss": 0.4613,
      "step": 252
    },
    {
      "epoch": 0.10552555047777316,
      "grad_norm": 0.38168248534202576,
      "learning_rate": 1e-05,
      "loss": 0.4569,
      "step": 254
    },
    {
      "epoch": 0.10635646032405484,
      "grad_norm": 0.3731848895549774,
      "learning_rate": 1e-05,
      "loss": 0.4791,
      "step": 256
    },
    {
      "epoch": 0.10718737017033651,
      "grad_norm": 0.4119926989078522,
      "learning_rate": 1e-05,
      "loss": 0.4761,
      "step": 258
    },
    {
      "epoch": 0.1080182800166182,
      "grad_norm": 0.390621542930603,
      "learning_rate": 1e-05,
      "loss": 0.4424,
      "step": 260
    },
    {
      "epoch": 0.10884918986289988,
      "grad_norm": 0.4007403552532196,
      "learning_rate": 1e-05,
      "loss": 0.4719,
      "step": 262
    },
    {
      "epoch": 0.10968009970918155,
      "grad_norm": 0.3870653212070465,
      "learning_rate": 1e-05,
      "loss": 0.4639,
      "step": 264
    },
    {
      "epoch": 0.11051100955546324,
      "grad_norm": 0.39271020889282227,
      "learning_rate": 1e-05,
      "loss": 0.4673,
      "step": 266
    },
    {
      "epoch": 0.11134191940174491,
      "grad_norm": 0.383316308259964,
      "learning_rate": 1e-05,
      "loss": 0.4418,
      "step": 268
    },
    {
      "epoch": 0.11217282924802659,
      "grad_norm": 0.38648444414138794,
      "learning_rate": 1e-05,
      "loss": 0.4496,
      "step": 270
    },
    {
      "epoch": 0.11300373909430826,
      "grad_norm": 0.38853171467781067,
      "learning_rate": 1e-05,
      "loss": 0.4533,
      "step": 272
    },
    {
      "epoch": 0.11383464894058995,
      "grad_norm": 0.3953942358493805,
      "learning_rate": 1e-05,
      "loss": 0.4723,
      "step": 274
    },
    {
      "epoch": 0.11466555878687162,
      "grad_norm": 0.4089873731136322,
      "learning_rate": 1e-05,
      "loss": 0.472,
      "step": 276
    },
    {
      "epoch": 0.1154964686331533,
      "grad_norm": 0.4045029580593109,
      "learning_rate": 1e-05,
      "loss": 0.4792,
      "step": 278
    },
    {
      "epoch": 0.11632737847943499,
      "grad_norm": 0.3800019323825836,
      "learning_rate": 1e-05,
      "loss": 0.4605,
      "step": 280
    },
    {
      "epoch": 0.11715828832571666,
      "grad_norm": 0.401726096868515,
      "learning_rate": 1e-05,
      "loss": 0.4726,
      "step": 282
    },
    {
      "epoch": 0.11798919817199834,
      "grad_norm": 0.381879597902298,
      "learning_rate": 1e-05,
      "loss": 0.4606,
      "step": 284
    },
    {
      "epoch": 0.11882010801828001,
      "grad_norm": 0.38936713337898254,
      "learning_rate": 1e-05,
      "loss": 0.4559,
      "step": 286
    },
    {
      "epoch": 0.1196510178645617,
      "grad_norm": 0.3803952634334564,
      "learning_rate": 1e-05,
      "loss": 0.4502,
      "step": 288
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 0.3992755115032196,
      "learning_rate": 1e-05,
      "loss": 0.4661,
      "step": 290
    },
    {
      "epoch": 0.12131283755712505,
      "grad_norm": 0.40693166851997375,
      "learning_rate": 1e-05,
      "loss": 0.4735,
      "step": 292
    },
    {
      "epoch": 0.12214374740340674,
      "grad_norm": 0.4072551131248474,
      "learning_rate": 1e-05,
      "loss": 0.4728,
      "step": 294
    },
    {
      "epoch": 0.12297465724968841,
      "grad_norm": 0.37639522552490234,
      "learning_rate": 1e-05,
      "loss": 0.4703,
      "step": 296
    },
    {
      "epoch": 0.12380556709597008,
      "grad_norm": 0.3756197988986969,
      "learning_rate": 1e-05,
      "loss": 0.4625,
      "step": 298
    },
    {
      "epoch": 0.12463647694225176,
      "grad_norm": 0.3938250243663788,
      "learning_rate": 1e-05,
      "loss": 0.4776,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_alpaca_gpt4_zh.json_loss": 1.3848012685775757,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4739,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 444.408,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.998,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_ultrainteract_sft.json_loss": 0.4735104739665985,
      "eval_ultrainteract_sft.json_runtime": 17.9837,
      "eval_ultrainteract_sft.json_samples_per_second": 159.589,
      "eval_ultrainteract_sft.json_steps_per_second": 6.673,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_code_feedback_multi_turn.json_loss": 0.583854615688324,
      "eval_code_feedback_multi_turn.json_runtime": 15.888,
      "eval_code_feedback_multi_turn.json_samples_per_second": 63.948,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.706,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_tested_143k_python_alpaca.json_loss": 0.3772309124469757,
      "eval_tested_143k_python_alpaca.json_runtime": 14.0774,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.661,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.89,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_synthetic_text_to_sql.json_loss": 0.17958146333694458,
      "eval_synthetic_text_to_sql.json_runtime": 3.3256,
      "eval_synthetic_text_to_sql.json_samples_per_second": 419.471,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.741,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_codefeedback_filtered_instruction.json_loss": 0.4411393404006958,
      "eval_codefeedback_filtered_instruction.json_runtime": 9.982,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.516,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.313,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_train_data_for_qwen.json_loss": 0.02432125434279442,
      "eval_train_data_for_qwen.json_runtime": 3.6438,
      "eval_train_data_for_qwen.json_samples_per_second": 120.752,
      "eval_train_data_for_qwen.json_steps_per_second": 5.214,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4877805709838867,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.9454,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 382.954,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.449,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_all_merge_code.json_loss": 0.26341408491134644,
      "eval_all_merge_code.json_runtime": 16.8743,
      "eval_all_merge_code.json_samples_per_second": 205.164,
      "eval_all_merge_code.json_steps_per_second": 8.593,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_xlam_function_calling_60k.json_loss": 0.024481041356921196,
      "eval_xlam_function_calling_60k.json_runtime": 4.4068,
      "eval_xlam_function_calling_60k.json_samples_per_second": 201.279,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.396,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_table_python_code_datas.json_loss": 0.17971698939800262,
      "eval_table_python_code_datas.json_runtime": 65.964,
      "eval_table_python_code_datas.json_samples_per_second": 70.705,
      "eval_table_python_code_datas.json_steps_per_second": 2.956,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_Table_GPT.json_loss": 0.079325832426548,
      "eval_Table_GPT.json_runtime": 10.5617,
      "eval_Table_GPT.json_samples_per_second": 83.982,
      "eval_Table_GPT.json_steps_per_second": 3.503,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_tabular_llm_data.json_loss": 0.1272648274898529,
      "eval_tabular_llm_data.json_runtime": 50.7091,
      "eval_tabular_llm_data.json_samples_per_second": 57.781,
      "eval_tabular_llm_data.json_steps_per_second": 2.426,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_gpt_4o_200k.json_loss": 0.8660110235214233,
      "eval_gpt_4o_200k.json_runtime": 27.3556,
      "eval_gpt_4o_200k.json_samples_per_second": 130.54,
      "eval_gpt_4o_200k.json_steps_per_second": 5.447,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_MathInstruct.json_loss": 0.18220728635787964,
      "eval_MathInstruct.json_runtime": 12.8844,
      "eval_MathInstruct.json_samples_per_second": 254.184,
      "eval_MathInstruct.json_steps_per_second": 10.633,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_alpaca_cleaned.json_loss": 0.9499232172966003,
      "eval_alpaca_cleaned.json_runtime": 2.3915,
      "eval_alpaca_cleaned.json_samples_per_second": 372.15,
      "eval_alpaca_cleaned.json_steps_per_second": 15.89,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_multi_turn_datas_0816.json_loss": 0.35043877363204956,
      "eval_multi_turn_datas_0816.json_runtime": 71.1503,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.484,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.403,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_sharegpt_gpt4.json_loss": 0.7806702256202698,
      "eval_sharegpt_gpt4.json_runtime": 21.8924,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.37,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.786,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_python_code_critic_21k.json_loss": 0.6610754132270813,
      "eval_python_code_critic_21k.json_runtime": 1.9521,
      "eval_python_code_critic_21k.json_samples_per_second": 148.044,
      "eval_python_code_critic_21k.json_steps_per_second": 6.659,
      "step": 300
    },
    {
      "epoch": 0.12463647694225176,
      "eval_agent_instruct.json_loss": 0.23821832239627838,
      "eval_agent_instruct.json_runtime": 0.2414,
      "eval_agent_instruct.json_samples_per_second": 91.133,
      "eval_agent_instruct.json_steps_per_second": 4.142,
      "step": 300
    },
    {
      "epoch": 0.12546738678853345,
      "grad_norm": 0.3890456259250641,
      "learning_rate": 1e-05,
      "loss": 0.4715,
      "step": 302
    },
    {
      "epoch": 0.12629829663481512,
      "grad_norm": 0.3873625695705414,
      "learning_rate": 1e-05,
      "loss": 0.4791,
      "step": 304
    },
    {
      "epoch": 0.1271292064810968,
      "grad_norm": 0.38953831791877747,
      "learning_rate": 1e-05,
      "loss": 0.4657,
      "step": 306
    },
    {
      "epoch": 0.12796011632737847,
      "grad_norm": 0.37805208563804626,
      "learning_rate": 1e-05,
      "loss": 0.4597,
      "step": 308
    },
    {
      "epoch": 0.12879102617366014,
      "grad_norm": 0.38848230242729187,
      "learning_rate": 1e-05,
      "loss": 0.4695,
      "step": 310
    },
    {
      "epoch": 0.12962193601994185,
      "grad_norm": 0.3913848102092743,
      "learning_rate": 1e-05,
      "loss": 0.466,
      "step": 312
    },
    {
      "epoch": 0.13045284586622352,
      "grad_norm": 0.3754233419895172,
      "learning_rate": 1e-05,
      "loss": 0.4531,
      "step": 314
    },
    {
      "epoch": 0.1312837557125052,
      "grad_norm": 0.37724804878234863,
      "learning_rate": 1e-05,
      "loss": 0.468,
      "step": 316
    },
    {
      "epoch": 0.13211466555878687,
      "grad_norm": 0.4013948440551758,
      "learning_rate": 1e-05,
      "loss": 0.4753,
      "step": 318
    },
    {
      "epoch": 0.13294557540506854,
      "grad_norm": 0.39871910214424133,
      "learning_rate": 1e-05,
      "loss": 0.4593,
      "step": 320
    },
    {
      "epoch": 0.13377648525135022,
      "grad_norm": 0.39900311827659607,
      "learning_rate": 1e-05,
      "loss": 0.4516,
      "step": 322
    },
    {
      "epoch": 0.1346073950976319,
      "grad_norm": 0.3790094554424286,
      "learning_rate": 1e-05,
      "loss": 0.4647,
      "step": 324
    },
    {
      "epoch": 0.1354383049439136,
      "grad_norm": 0.3906997740268707,
      "learning_rate": 1e-05,
      "loss": 0.4717,
      "step": 326
    },
    {
      "epoch": 0.13626921479019527,
      "grad_norm": 0.3750073313713074,
      "learning_rate": 1e-05,
      "loss": 0.4734,
      "step": 328
    },
    {
      "epoch": 0.13710012463647694,
      "grad_norm": 0.39233022928237915,
      "learning_rate": 1e-05,
      "loss": 0.4662,
      "step": 330
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.38809096813201904,
      "learning_rate": 1e-05,
      "loss": 0.4679,
      "step": 332
    },
    {
      "epoch": 0.1387619443290403,
      "grad_norm": 0.38319242000579834,
      "learning_rate": 1e-05,
      "loss": 0.4549,
      "step": 334
    },
    {
      "epoch": 0.13959285417532197,
      "grad_norm": 0.40156930685043335,
      "learning_rate": 1e-05,
      "loss": 0.4683,
      "step": 336
    },
    {
      "epoch": 0.14042376402160367,
      "grad_norm": 0.3875245153903961,
      "learning_rate": 1e-05,
      "loss": 0.4707,
      "step": 338
    },
    {
      "epoch": 0.14125467386788534,
      "grad_norm": 0.39791354537010193,
      "learning_rate": 1e-05,
      "loss": 0.4689,
      "step": 340
    },
    {
      "epoch": 0.14208558371416702,
      "grad_norm": 0.37518465518951416,
      "learning_rate": 1e-05,
      "loss": 0.4493,
      "step": 342
    },
    {
      "epoch": 0.1429164935604487,
      "grad_norm": 0.384185791015625,
      "learning_rate": 1e-05,
      "loss": 0.4582,
      "step": 344
    },
    {
      "epoch": 0.14374740340673037,
      "grad_norm": 0.3930719494819641,
      "learning_rate": 1e-05,
      "loss": 0.4641,
      "step": 346
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 0.3965315520763397,
      "learning_rate": 1e-05,
      "loss": 0.4482,
      "step": 348
    },
    {
      "epoch": 0.14540922309929372,
      "grad_norm": 0.38150152564048767,
      "learning_rate": 1e-05,
      "loss": 0.4599,
      "step": 350
    },
    {
      "epoch": 0.14624013294557542,
      "grad_norm": 0.3823580741882324,
      "learning_rate": 1e-05,
      "loss": 0.4682,
      "step": 352
    },
    {
      "epoch": 0.1470710427918571,
      "grad_norm": 0.3897857367992401,
      "learning_rate": 1e-05,
      "loss": 0.4843,
      "step": 354
    },
    {
      "epoch": 0.14790195263813877,
      "grad_norm": 0.3888656795024872,
      "learning_rate": 1e-05,
      "loss": 0.4451,
      "step": 356
    },
    {
      "epoch": 0.14873286248442044,
      "grad_norm": 0.38737910985946655,
      "learning_rate": 1e-05,
      "loss": 0.4669,
      "step": 358
    },
    {
      "epoch": 0.14956377233070212,
      "grad_norm": 0.3939470052719116,
      "learning_rate": 1e-05,
      "loss": 0.462,
      "step": 360
    },
    {
      "epoch": 0.1503946821769838,
      "grad_norm": 0.3907855749130249,
      "learning_rate": 1e-05,
      "loss": 0.4567,
      "step": 362
    },
    {
      "epoch": 0.15122559202326546,
      "grad_norm": 0.3716069459915161,
      "learning_rate": 1e-05,
      "loss": 0.4627,
      "step": 364
    },
    {
      "epoch": 0.15205650186954717,
      "grad_norm": 0.375012069940567,
      "learning_rate": 1e-05,
      "loss": 0.453,
      "step": 366
    },
    {
      "epoch": 0.15288741171582884,
      "grad_norm": 0.3938294053077698,
      "learning_rate": 1e-05,
      "loss": 0.4666,
      "step": 368
    },
    {
      "epoch": 0.15371832156211052,
      "grad_norm": 0.3724190890789032,
      "learning_rate": 1e-05,
      "loss": 0.4478,
      "step": 370
    },
    {
      "epoch": 0.1545492314083922,
      "grad_norm": 0.3778214752674103,
      "learning_rate": 1e-05,
      "loss": 0.4768,
      "step": 372
    },
    {
      "epoch": 0.15538014125467386,
      "grad_norm": 0.3786708116531372,
      "learning_rate": 1e-05,
      "loss": 0.4727,
      "step": 374
    },
    {
      "epoch": 0.15621105110095554,
      "grad_norm": 0.37252336740493774,
      "learning_rate": 1e-05,
      "loss": 0.4702,
      "step": 376
    },
    {
      "epoch": 0.1570419609472372,
      "grad_norm": 0.3846096694469452,
      "learning_rate": 1e-05,
      "loss": 0.455,
      "step": 378
    },
    {
      "epoch": 0.15787287079351892,
      "grad_norm": 0.3841463327407837,
      "learning_rate": 1e-05,
      "loss": 0.4534,
      "step": 380
    },
    {
      "epoch": 0.1587037806398006,
      "grad_norm": 0.3918958604335785,
      "learning_rate": 1e-05,
      "loss": 0.4698,
      "step": 382
    },
    {
      "epoch": 0.15953469048608226,
      "grad_norm": 0.39745306968688965,
      "learning_rate": 1e-05,
      "loss": 0.4616,
      "step": 384
    },
    {
      "epoch": 0.16036560033236394,
      "grad_norm": 0.386709064245224,
      "learning_rate": 1e-05,
      "loss": 0.4459,
      "step": 386
    },
    {
      "epoch": 0.1611965101786456,
      "grad_norm": 0.37585878372192383,
      "learning_rate": 1e-05,
      "loss": 0.4637,
      "step": 388
    },
    {
      "epoch": 0.1620274200249273,
      "grad_norm": 0.38213974237442017,
      "learning_rate": 1e-05,
      "loss": 0.4595,
      "step": 390
    },
    {
      "epoch": 0.16285832987120896,
      "grad_norm": 0.3784959018230438,
      "learning_rate": 1e-05,
      "loss": 0.4617,
      "step": 392
    },
    {
      "epoch": 0.16368923971749066,
      "grad_norm": 0.36265328526496887,
      "learning_rate": 1e-05,
      "loss": 0.4564,
      "step": 394
    },
    {
      "epoch": 0.16452014956377234,
      "grad_norm": 0.39517781138420105,
      "learning_rate": 1e-05,
      "loss": 0.4681,
      "step": 396
    },
    {
      "epoch": 0.165351059410054,
      "grad_norm": 0.41185057163238525,
      "learning_rate": 1e-05,
      "loss": 0.4575,
      "step": 398
    },
    {
      "epoch": 0.1661819692563357,
      "grad_norm": 0.3843752145767212,
      "learning_rate": 1e-05,
      "loss": 0.4675,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_alpaca_gpt4_zh.json_loss": 1.3846310377120972,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4849,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 441.103,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.856,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_ultrainteract_sft.json_loss": 0.4681845009326935,
      "eval_ultrainteract_sft.json_runtime": 18.0413,
      "eval_ultrainteract_sft.json_samples_per_second": 159.079,
      "eval_ultrainteract_sft.json_steps_per_second": 6.651,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_code_feedback_multi_turn.json_loss": 0.5780166983604431,
      "eval_code_feedback_multi_turn.json_runtime": 15.8547,
      "eval_code_feedback_multi_turn.json_samples_per_second": 64.082,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.712,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_tested_143k_python_alpaca.json_loss": 0.3740081787109375,
      "eval_tested_143k_python_alpaca.json_runtime": 14.0982,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.418,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.88,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_synthetic_text_to_sql.json_loss": 0.1788129061460495,
      "eval_synthetic_text_to_sql.json_runtime": 3.3361,
      "eval_synthetic_text_to_sql.json_samples_per_second": 418.157,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.685,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_codefeedback_filtered_instruction.json_loss": 0.437978595495224,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0086,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.049,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.294,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_train_data_for_qwen.json_loss": 0.021963851526379585,
      "eval_train_data_for_qwen.json_runtime": 3.6486,
      "eval_train_data_for_qwen.json_samples_per_second": 120.594,
      "eval_train_data_for_qwen.json_steps_per_second": 5.207,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4728742837905884,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.9604,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 380.026,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.323,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_all_merge_code.json_loss": 0.25926658511161804,
      "eval_all_merge_code.json_runtime": 16.8793,
      "eval_all_merge_code.json_samples_per_second": 205.103,
      "eval_all_merge_code.json_steps_per_second": 8.59,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_xlam_function_calling_60k.json_loss": 0.022318964824080467,
      "eval_xlam_function_calling_60k.json_runtime": 4.41,
      "eval_xlam_function_calling_60k.json_samples_per_second": 201.133,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.39,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_table_python_code_datas.json_loss": 0.17380967736244202,
      "eval_table_python_code_datas.json_runtime": 66.2685,
      "eval_table_python_code_datas.json_samples_per_second": 70.38,
      "eval_table_python_code_datas.json_steps_per_second": 2.943,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_Table_GPT.json_loss": 0.07711787521839142,
      "eval_Table_GPT.json_runtime": 10.5631,
      "eval_Table_GPT.json_samples_per_second": 83.972,
      "eval_Table_GPT.json_steps_per_second": 3.503,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_tabular_llm_data.json_loss": 0.12095072120428085,
      "eval_tabular_llm_data.json_runtime": 50.7873,
      "eval_tabular_llm_data.json_samples_per_second": 57.692,
      "eval_tabular_llm_data.json_steps_per_second": 2.422,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_gpt_4o_200k.json_loss": 0.8614335656166077,
      "eval_gpt_4o_200k.json_runtime": 27.2485,
      "eval_gpt_4o_200k.json_samples_per_second": 131.053,
      "eval_gpt_4o_200k.json_steps_per_second": 5.468,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_MathInstruct.json_loss": 0.18143966794013977,
      "eval_MathInstruct.json_runtime": 12.9194,
      "eval_MathInstruct.json_samples_per_second": 253.494,
      "eval_MathInstruct.json_steps_per_second": 10.604,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_alpaca_cleaned.json_loss": 0.9464051127433777,
      "eval_alpaca_cleaned.json_runtime": 2.3922,
      "eval_alpaca_cleaned.json_samples_per_second": 372.039,
      "eval_alpaca_cleaned.json_steps_per_second": 15.885,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_multi_turn_datas_0816.json_loss": 0.3429626226425171,
      "eval_multi_turn_datas_0816.json_runtime": 71.5025,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.201,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.392,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_sharegpt_gpt4.json_loss": 0.7752892374992371,
      "eval_sharegpt_gpt4.json_runtime": 21.7181,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.903,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.809,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_python_code_critic_21k.json_loss": 0.6539245843887329,
      "eval_python_code_critic_21k.json_runtime": 1.9509,
      "eval_python_code_critic_21k.json_samples_per_second": 148.135,
      "eval_python_code_critic_21k.json_steps_per_second": 6.664,
      "step": 400
    },
    {
      "epoch": 0.1661819692563357,
      "eval_agent_instruct.json_loss": 0.23178355395793915,
      "eval_agent_instruct.json_runtime": 0.2442,
      "eval_agent_instruct.json_samples_per_second": 90.104,
      "eval_agent_instruct.json_steps_per_second": 4.096,
      "step": 400
    },
    {
      "epoch": 0.16701287910261736,
      "grad_norm": 0.3802046477794647,
      "learning_rate": 1e-05,
      "loss": 0.4675,
      "step": 402
    },
    {
      "epoch": 0.16784378894889904,
      "grad_norm": 0.3931722044944763,
      "learning_rate": 1e-05,
      "loss": 0.4691,
      "step": 404
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 0.37843549251556396,
      "learning_rate": 1e-05,
      "loss": 0.4625,
      "step": 406
    },
    {
      "epoch": 0.1695056086414624,
      "grad_norm": 0.3837864398956299,
      "learning_rate": 1e-05,
      "loss": 0.4469,
      "step": 408
    },
    {
      "epoch": 0.1703365184877441,
      "grad_norm": 0.3812935948371887,
      "learning_rate": 1e-05,
      "loss": 0.471,
      "step": 410
    },
    {
      "epoch": 0.17116742833402576,
      "grad_norm": 0.38834723830223083,
      "learning_rate": 1e-05,
      "loss": 0.4688,
      "step": 412
    },
    {
      "epoch": 0.17199833818030744,
      "grad_norm": 0.3888213336467743,
      "learning_rate": 1e-05,
      "loss": 0.4663,
      "step": 414
    },
    {
      "epoch": 0.1728292480265891,
      "grad_norm": 0.381172776222229,
      "learning_rate": 1e-05,
      "loss": 0.4591,
      "step": 416
    },
    {
      "epoch": 0.17366015787287079,
      "grad_norm": 0.3848037123680115,
      "learning_rate": 1e-05,
      "loss": 0.4603,
      "step": 418
    },
    {
      "epoch": 0.17449106771915246,
      "grad_norm": 0.37458914518356323,
      "learning_rate": 1e-05,
      "loss": 0.4417,
      "step": 420
    },
    {
      "epoch": 0.17532197756543416,
      "grad_norm": 0.368320494890213,
      "learning_rate": 1e-05,
      "loss": 0.4483,
      "step": 422
    },
    {
      "epoch": 0.17615288741171584,
      "grad_norm": 0.3741687834262848,
      "learning_rate": 1e-05,
      "loss": 0.4483,
      "step": 424
    },
    {
      "epoch": 0.1769837972579975,
      "grad_norm": 0.3787063658237457,
      "learning_rate": 1e-05,
      "loss": 0.4567,
      "step": 426
    },
    {
      "epoch": 0.17781470710427918,
      "grad_norm": 0.39605364203453064,
      "learning_rate": 1e-05,
      "loss": 0.4676,
      "step": 428
    },
    {
      "epoch": 0.17864561695056086,
      "grad_norm": 0.37889164686203003,
      "learning_rate": 1e-05,
      "loss": 0.4634,
      "step": 430
    },
    {
      "epoch": 0.17947652679684253,
      "grad_norm": 0.3858800530433655,
      "learning_rate": 1e-05,
      "loss": 0.4583,
      "step": 432
    },
    {
      "epoch": 0.1803074366431242,
      "grad_norm": 0.3969145119190216,
      "learning_rate": 1e-05,
      "loss": 0.4548,
      "step": 434
    },
    {
      "epoch": 0.1811383464894059,
      "grad_norm": 0.39660677313804626,
      "learning_rate": 1e-05,
      "loss": 0.4531,
      "step": 436
    },
    {
      "epoch": 0.18196925633568758,
      "grad_norm": 0.37023094296455383,
      "learning_rate": 1e-05,
      "loss": 0.4449,
      "step": 438
    },
    {
      "epoch": 0.18280016618196926,
      "grad_norm": 0.3868309557437897,
      "learning_rate": 1e-05,
      "loss": 0.451,
      "step": 440
    },
    {
      "epoch": 0.18363107602825093,
      "grad_norm": 0.3929104208946228,
      "learning_rate": 1e-05,
      "loss": 0.4533,
      "step": 442
    },
    {
      "epoch": 0.1844619858745326,
      "grad_norm": 0.38356223702430725,
      "learning_rate": 1e-05,
      "loss": 0.4835,
      "step": 444
    },
    {
      "epoch": 0.18529289572081428,
      "grad_norm": 0.3948748707771301,
      "learning_rate": 1e-05,
      "loss": 0.4385,
      "step": 446
    },
    {
      "epoch": 0.18612380556709596,
      "grad_norm": 0.3834511339664459,
      "learning_rate": 1e-05,
      "loss": 0.458,
      "step": 448
    },
    {
      "epoch": 0.18695471541337766,
      "grad_norm": 0.3967447876930237,
      "learning_rate": 1e-05,
      "loss": 0.448,
      "step": 450
    },
    {
      "epoch": 0.18778562525965933,
      "grad_norm": 0.3875657320022583,
      "learning_rate": 1e-05,
      "loss": 0.45,
      "step": 452
    },
    {
      "epoch": 0.188616535105941,
      "grad_norm": 0.37462136149406433,
      "learning_rate": 1e-05,
      "loss": 0.4595,
      "step": 454
    },
    {
      "epoch": 0.18944744495222268,
      "grad_norm": 0.3754582405090332,
      "learning_rate": 1e-05,
      "loss": 0.4462,
      "step": 456
    },
    {
      "epoch": 0.19027835479850436,
      "grad_norm": 0.374908983707428,
      "learning_rate": 1e-05,
      "loss": 0.4486,
      "step": 458
    },
    {
      "epoch": 0.19110926464478603,
      "grad_norm": 0.37098222970962524,
      "learning_rate": 1e-05,
      "loss": 0.4431,
      "step": 460
    },
    {
      "epoch": 0.1919401744910677,
      "grad_norm": 0.40945762395858765,
      "learning_rate": 1e-05,
      "loss": 0.4541,
      "step": 462
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 0.3959982395172119,
      "learning_rate": 1e-05,
      "loss": 0.4607,
      "step": 464
    },
    {
      "epoch": 0.19360199418363108,
      "grad_norm": 0.3626880645751953,
      "learning_rate": 1e-05,
      "loss": 0.456,
      "step": 466
    },
    {
      "epoch": 0.19443290402991276,
      "grad_norm": 0.38872116804122925,
      "learning_rate": 1e-05,
      "loss": 0.4584,
      "step": 468
    },
    {
      "epoch": 0.19526381387619443,
      "grad_norm": 0.3764721155166626,
      "learning_rate": 1e-05,
      "loss": 0.4461,
      "step": 470
    },
    {
      "epoch": 0.1960947237224761,
      "grad_norm": 0.3877929747104645,
      "learning_rate": 1e-05,
      "loss": 0.4672,
      "step": 472
    },
    {
      "epoch": 0.19692563356875778,
      "grad_norm": 0.40051591396331787,
      "learning_rate": 1e-05,
      "loss": 0.4667,
      "step": 474
    },
    {
      "epoch": 0.19775654341503948,
      "grad_norm": 0.39472123980522156,
      "learning_rate": 1e-05,
      "loss": 0.4441,
      "step": 476
    },
    {
      "epoch": 0.19858745326132116,
      "grad_norm": 0.3839832544326782,
      "learning_rate": 1e-05,
      "loss": 0.4398,
      "step": 478
    },
    {
      "epoch": 0.19941836310760283,
      "grad_norm": 0.3883185088634491,
      "learning_rate": 1e-05,
      "loss": 0.4554,
      "step": 480
    },
    {
      "epoch": 0.2002492729538845,
      "grad_norm": 0.3927934169769287,
      "learning_rate": 1e-05,
      "loss": 0.4536,
      "step": 482
    },
    {
      "epoch": 0.20108018280016618,
      "grad_norm": 0.382721871137619,
      "learning_rate": 1e-05,
      "loss": 0.4544,
      "step": 484
    },
    {
      "epoch": 0.20191109264644785,
      "grad_norm": 0.39537835121154785,
      "learning_rate": 1e-05,
      "loss": 0.4651,
      "step": 486
    },
    {
      "epoch": 0.20274200249272953,
      "grad_norm": 0.37058988213539124,
      "learning_rate": 1e-05,
      "loss": 0.4547,
      "step": 488
    },
    {
      "epoch": 0.20357291233901123,
      "grad_norm": 0.3934817314147949,
      "learning_rate": 1e-05,
      "loss": 0.4739,
      "step": 490
    },
    {
      "epoch": 0.2044038221852929,
      "grad_norm": 0.3920029103755951,
      "learning_rate": 1e-05,
      "loss": 0.4474,
      "step": 492
    },
    {
      "epoch": 0.20523473203157458,
      "grad_norm": 0.3958110809326172,
      "learning_rate": 1e-05,
      "loss": 0.458,
      "step": 494
    },
    {
      "epoch": 0.20606564187785625,
      "grad_norm": 0.3785530626773834,
      "learning_rate": 1e-05,
      "loss": 0.4612,
      "step": 496
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.3896524906158447,
      "learning_rate": 1e-05,
      "loss": 0.4685,
      "step": 498
    },
    {
      "epoch": 0.2077274615704196,
      "grad_norm": 0.39695924520492554,
      "learning_rate": 1e-05,
      "loss": 0.4625,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_alpaca_gpt4_zh.json_loss": 1.3776657581329346,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4797,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 442.645,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.922,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_ultrainteract_sft.json_loss": 0.4652465879917145,
      "eval_ultrainteract_sft.json_runtime": 17.9956,
      "eval_ultrainteract_sft.json_samples_per_second": 159.484,
      "eval_ultrainteract_sft.json_steps_per_second": 6.668,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_code_feedback_multi_turn.json_loss": 0.5756356716156006,
      "eval_code_feedback_multi_turn.json_runtime": 15.1508,
      "eval_code_feedback_multi_turn.json_samples_per_second": 67.059,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.838,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_tested_143k_python_alpaca.json_loss": 0.3696131110191345,
      "eval_tested_143k_python_alpaca.json_runtime": 14.0873,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.545,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.886,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_synthetic_text_to_sql.json_loss": 0.17702342569828033,
      "eval_synthetic_text_to_sql.json_runtime": 3.4153,
      "eval_synthetic_text_to_sql.json_samples_per_second": 408.459,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.275,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_codefeedback_filtered_instruction.json_loss": 0.4281075596809387,
      "eval_codefeedback_filtered_instruction.json_runtime": 9.987,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.428,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.31,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_train_data_for_qwen.json_loss": 0.02041272260248661,
      "eval_train_data_for_qwen.json_runtime": 3.6405,
      "eval_train_data_for_qwen.json_samples_per_second": 120.863,
      "eval_train_data_for_qwen.json_steps_per_second": 5.219,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.465746521949768,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8895,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 394.289,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.936,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_all_merge_code.json_loss": 0.2538397014141083,
      "eval_all_merge_code.json_runtime": 16.7478,
      "eval_all_merge_code.json_samples_per_second": 206.714,
      "eval_all_merge_code.json_steps_per_second": 8.658,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_xlam_function_calling_60k.json_loss": 0.021773498505353928,
      "eval_xlam_function_calling_60k.json_runtime": 4.4508,
      "eval_xlam_function_calling_60k.json_samples_per_second": 199.291,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.313,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_table_python_code_datas.json_loss": 0.16937051713466644,
      "eval_table_python_code_datas.json_runtime": 66.5255,
      "eval_table_python_code_datas.json_samples_per_second": 70.108,
      "eval_table_python_code_datas.json_steps_per_second": 2.931,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_Table_GPT.json_loss": 0.07517983764410019,
      "eval_Table_GPT.json_runtime": 10.536,
      "eval_Table_GPT.json_samples_per_second": 84.187,
      "eval_Table_GPT.json_steps_per_second": 3.512,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_tabular_llm_data.json_loss": 0.12015797197818756,
      "eval_tabular_llm_data.json_runtime": 50.2821,
      "eval_tabular_llm_data.json_samples_per_second": 58.271,
      "eval_tabular_llm_data.json_steps_per_second": 2.446,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_gpt_4o_200k.json_loss": 0.8583551049232483,
      "eval_gpt_4o_200k.json_runtime": 27.1789,
      "eval_gpt_4o_200k.json_samples_per_second": 131.389,
      "eval_gpt_4o_200k.json_steps_per_second": 5.482,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_MathInstruct.json_loss": 0.1804163157939911,
      "eval_MathInstruct.json_runtime": 12.962,
      "eval_MathInstruct.json_samples_per_second": 252.662,
      "eval_MathInstruct.json_steps_per_second": 10.569,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_alpaca_cleaned.json_loss": 0.943878710269928,
      "eval_alpaca_cleaned.json_runtime": 2.3729,
      "eval_alpaca_cleaned.json_samples_per_second": 375.065,
      "eval_alpaca_cleaned.json_steps_per_second": 16.014,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_multi_turn_datas_0816.json_loss": 0.3367810547351837,
      "eval_multi_turn_datas_0816.json_runtime": 71.4387,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.252,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.394,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_sharegpt_gpt4.json_loss": 0.7718721628189087,
      "eval_sharegpt_gpt4.json_runtime": 21.6157,
      "eval_sharegpt_gpt4.json_samples_per_second": 67.22,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.822,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_python_code_critic_21k.json_loss": 0.6481103301048279,
      "eval_python_code_critic_21k.json_runtime": 1.9533,
      "eval_python_code_critic_21k.json_samples_per_second": 147.953,
      "eval_python_code_critic_21k.json_steps_per_second": 6.655,
      "step": 500
    },
    {
      "epoch": 0.2077274615704196,
      "eval_agent_instruct.json_loss": 0.223960280418396,
      "eval_agent_instruct.json_runtime": 0.2435,
      "eval_agent_instruct.json_samples_per_second": 90.34,
      "eval_agent_instruct.json_steps_per_second": 4.106,
      "step": 500
    },
    {
      "epoch": 0.20855837141670128,
      "grad_norm": 0.3933066725730896,
      "learning_rate": 1e-05,
      "loss": 0.4566,
      "step": 502
    },
    {
      "epoch": 0.20938928126298298,
      "grad_norm": 0.38390231132507324,
      "learning_rate": 1e-05,
      "loss": 0.4505,
      "step": 504
    },
    {
      "epoch": 0.21022019110926465,
      "grad_norm": 0.3922358751296997,
      "learning_rate": 1e-05,
      "loss": 0.4578,
      "step": 506
    },
    {
      "epoch": 0.21105110095554633,
      "grad_norm": 0.36973246932029724,
      "learning_rate": 1e-05,
      "loss": 0.4427,
      "step": 508
    },
    {
      "epoch": 0.211882010801828,
      "grad_norm": 0.3892252743244171,
      "learning_rate": 1e-05,
      "loss": 0.4508,
      "step": 510
    },
    {
      "epoch": 0.21271292064810968,
      "grad_norm": 0.37701615691185,
      "learning_rate": 1e-05,
      "loss": 0.4486,
      "step": 512
    },
    {
      "epoch": 0.21354383049439135,
      "grad_norm": 0.3822026252746582,
      "learning_rate": 1e-05,
      "loss": 0.4431,
      "step": 514
    },
    {
      "epoch": 0.21437474034067303,
      "grad_norm": 0.38101664185523987,
      "learning_rate": 1e-05,
      "loss": 0.4565,
      "step": 516
    },
    {
      "epoch": 0.21520565018695473,
      "grad_norm": 0.39694395661354065,
      "learning_rate": 1e-05,
      "loss": 0.4421,
      "step": 518
    },
    {
      "epoch": 0.2160365600332364,
      "grad_norm": 0.39321330189704895,
      "learning_rate": 1e-05,
      "loss": 0.4477,
      "step": 520
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 0.3821650743484497,
      "learning_rate": 1e-05,
      "loss": 0.4683,
      "step": 522
    },
    {
      "epoch": 0.21769837972579975,
      "grad_norm": 0.3645505905151367,
      "learning_rate": 1e-05,
      "loss": 0.4306,
      "step": 524
    },
    {
      "epoch": 0.21852928957208143,
      "grad_norm": 0.3937512934207916,
      "learning_rate": 1e-05,
      "loss": 0.448,
      "step": 526
    },
    {
      "epoch": 0.2193601994183631,
      "grad_norm": 0.38207146525382996,
      "learning_rate": 1e-05,
      "loss": 0.4529,
      "step": 528
    },
    {
      "epoch": 0.22019110926464477,
      "grad_norm": 0.371461421251297,
      "learning_rate": 1e-05,
      "loss": 0.4587,
      "step": 530
    },
    {
      "epoch": 0.22102201911092648,
      "grad_norm": 0.37201860547065735,
      "learning_rate": 1e-05,
      "loss": 0.4512,
      "step": 532
    },
    {
      "epoch": 0.22185292895720815,
      "grad_norm": 0.3804784119129181,
      "learning_rate": 1e-05,
      "loss": 0.4555,
      "step": 534
    },
    {
      "epoch": 0.22268383880348983,
      "grad_norm": 0.38445067405700684,
      "learning_rate": 1e-05,
      "loss": 0.4464,
      "step": 536
    },
    {
      "epoch": 0.2235147486497715,
      "grad_norm": 0.3730752468109131,
      "learning_rate": 1e-05,
      "loss": 0.4482,
      "step": 538
    },
    {
      "epoch": 0.22434565849605317,
      "grad_norm": 0.4039866626262665,
      "learning_rate": 1e-05,
      "loss": 0.4414,
      "step": 540
    },
    {
      "epoch": 0.22517656834233485,
      "grad_norm": 0.378038614988327,
      "learning_rate": 1e-05,
      "loss": 0.4458,
      "step": 542
    },
    {
      "epoch": 0.22600747818861652,
      "grad_norm": 0.3936101198196411,
      "learning_rate": 1e-05,
      "loss": 0.4423,
      "step": 544
    },
    {
      "epoch": 0.22683838803489823,
      "grad_norm": 0.3897678256034851,
      "learning_rate": 1e-05,
      "loss": 0.4589,
      "step": 546
    },
    {
      "epoch": 0.2276692978811799,
      "grad_norm": 0.36557838320732117,
      "learning_rate": 1e-05,
      "loss": 0.4509,
      "step": 548
    },
    {
      "epoch": 0.22850020772746157,
      "grad_norm": 0.36936575174331665,
      "learning_rate": 1e-05,
      "loss": 0.4554,
      "step": 550
    },
    {
      "epoch": 0.22933111757374325,
      "grad_norm": 0.3700960576534271,
      "learning_rate": 1e-05,
      "loss": 0.4516,
      "step": 552
    },
    {
      "epoch": 0.23016202742002492,
      "grad_norm": 0.3933248519897461,
      "learning_rate": 1e-05,
      "loss": 0.4378,
      "step": 554
    },
    {
      "epoch": 0.2309929372663066,
      "grad_norm": 0.37913212180137634,
      "learning_rate": 1e-05,
      "loss": 0.4309,
      "step": 556
    },
    {
      "epoch": 0.23182384711258827,
      "grad_norm": 0.3654637932777405,
      "learning_rate": 1e-05,
      "loss": 0.4452,
      "step": 558
    },
    {
      "epoch": 0.23265475695886997,
      "grad_norm": 0.3755403757095337,
      "learning_rate": 1e-05,
      "loss": 0.4431,
      "step": 560
    },
    {
      "epoch": 0.23348566680515165,
      "grad_norm": 0.3895112872123718,
      "learning_rate": 1e-05,
      "loss": 0.4428,
      "step": 562
    },
    {
      "epoch": 0.23431657665143332,
      "grad_norm": 0.3754548132419586,
      "learning_rate": 1e-05,
      "loss": 0.4346,
      "step": 564
    },
    {
      "epoch": 0.235147486497715,
      "grad_norm": 0.3834458887577057,
      "learning_rate": 1e-05,
      "loss": 0.442,
      "step": 566
    },
    {
      "epoch": 0.23597839634399667,
      "grad_norm": 0.3752429485321045,
      "learning_rate": 1e-05,
      "loss": 0.452,
      "step": 568
    },
    {
      "epoch": 0.23680930619027835,
      "grad_norm": 0.39138153195381165,
      "learning_rate": 1e-05,
      "loss": 0.4527,
      "step": 570
    },
    {
      "epoch": 0.23764021603656002,
      "grad_norm": 0.37464040517807007,
      "learning_rate": 1e-05,
      "loss": 0.4529,
      "step": 572
    },
    {
      "epoch": 0.23847112588284172,
      "grad_norm": 0.38540467619895935,
      "learning_rate": 1e-05,
      "loss": 0.4571,
      "step": 574
    },
    {
      "epoch": 0.2393020357291234,
      "grad_norm": 0.4374150335788727,
      "learning_rate": 1e-05,
      "loss": 0.4541,
      "step": 576
    },
    {
      "epoch": 0.24013294557540507,
      "grad_norm": 0.370898962020874,
      "learning_rate": 1e-05,
      "loss": 0.4336,
      "step": 578
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 0.3859853446483612,
      "learning_rate": 1e-05,
      "loss": 0.4554,
      "step": 580
    },
    {
      "epoch": 0.24179476526796842,
      "grad_norm": 0.38618722558021545,
      "learning_rate": 1e-05,
      "loss": 0.4544,
      "step": 582
    },
    {
      "epoch": 0.2426256751142501,
      "grad_norm": 0.4066762328147888,
      "learning_rate": 1e-05,
      "loss": 0.4507,
      "step": 584
    },
    {
      "epoch": 0.24345658496053177,
      "grad_norm": 0.3813319206237793,
      "learning_rate": 1e-05,
      "loss": 0.4472,
      "step": 586
    },
    {
      "epoch": 0.24428749480681347,
      "grad_norm": 0.3893090486526489,
      "learning_rate": 1e-05,
      "loss": 0.4511,
      "step": 588
    },
    {
      "epoch": 0.24511840465309515,
      "grad_norm": 0.381661057472229,
      "learning_rate": 1e-05,
      "loss": 0.4278,
      "step": 590
    },
    {
      "epoch": 0.24594931449937682,
      "grad_norm": 0.38983118534088135,
      "learning_rate": 1e-05,
      "loss": 0.4466,
      "step": 592
    },
    {
      "epoch": 0.2467802243456585,
      "grad_norm": 0.3755686283111572,
      "learning_rate": 1e-05,
      "loss": 0.4351,
      "step": 594
    },
    {
      "epoch": 0.24761113419194017,
      "grad_norm": 0.36575397849082947,
      "learning_rate": 1e-05,
      "loss": 0.4553,
      "step": 596
    },
    {
      "epoch": 0.24844204403822184,
      "grad_norm": 0.3785867393016815,
      "learning_rate": 1e-05,
      "loss": 0.442,
      "step": 598
    },
    {
      "epoch": 0.24927295388450352,
      "grad_norm": 0.37871477007865906,
      "learning_rate": 1e-05,
      "loss": 0.4386,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_alpaca_gpt4_zh.json_loss": 1.3793318271636963,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4933,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 438.627,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.75,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_ultrainteract_sft.json_loss": 0.4618740379810333,
      "eval_ultrainteract_sft.json_runtime": 18.0082,
      "eval_ultrainteract_sft.json_samples_per_second": 159.372,
      "eval_ultrainteract_sft.json_steps_per_second": 6.664,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_code_feedback_multi_turn.json_loss": 0.5730599164962769,
      "eval_code_feedback_multi_turn.json_runtime": 15.7679,
      "eval_code_feedback_multi_turn.json_samples_per_second": 64.435,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.727,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_tested_143k_python_alpaca.json_loss": 0.3682435154914856,
      "eval_tested_143k_python_alpaca.json_runtime": 14.1088,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.294,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.875,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_synthetic_text_to_sql.json_loss": 0.1758909672498703,
      "eval_synthetic_text_to_sql.json_runtime": 3.3243,
      "eval_synthetic_text_to_sql.json_samples_per_second": 419.632,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.748,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_codefeedback_filtered_instruction.json_loss": 0.4254109561443329,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0337,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 174.611,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.275,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_train_data_for_qwen.json_loss": 0.019638974219560623,
      "eval_train_data_for_qwen.json_runtime": 3.6537,
      "eval_train_data_for_qwen.json_samples_per_second": 120.426,
      "eval_train_data_for_qwen.json_steps_per_second": 5.2,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4567513465881348,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8839,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 395.457,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.986,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_all_merge_code.json_loss": 0.2502395510673523,
      "eval_all_merge_code.json_runtime": 16.854,
      "eval_all_merge_code.json_samples_per_second": 205.411,
      "eval_all_merge_code.json_steps_per_second": 8.603,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_xlam_function_calling_60k.json_loss": 0.021654721349477768,
      "eval_xlam_function_calling_60k.json_runtime": 4.4106,
      "eval_xlam_function_calling_60k.json_samples_per_second": 201.106,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.389,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_table_python_code_datas.json_loss": 0.1657874584197998,
      "eval_table_python_code_datas.json_runtime": 65.7653,
      "eval_table_python_code_datas.json_samples_per_second": 70.919,
      "eval_table_python_code_datas.json_steps_per_second": 2.965,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_Table_GPT.json_loss": 0.07162044197320938,
      "eval_Table_GPT.json_runtime": 10.5589,
      "eval_Table_GPT.json_samples_per_second": 84.005,
      "eval_Table_GPT.json_steps_per_second": 3.504,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_tabular_llm_data.json_loss": 0.11600812524557114,
      "eval_tabular_llm_data.json_runtime": 50.4195,
      "eval_tabular_llm_data.json_samples_per_second": 58.112,
      "eval_tabular_llm_data.json_steps_per_second": 2.44,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_gpt_4o_200k.json_loss": 0.8574861288070679,
      "eval_gpt_4o_200k.json_runtime": 27.3196,
      "eval_gpt_4o_200k.json_samples_per_second": 130.712,
      "eval_gpt_4o_200k.json_steps_per_second": 5.454,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_MathInstruct.json_loss": 0.17917710542678833,
      "eval_MathInstruct.json_runtime": 12.923,
      "eval_MathInstruct.json_samples_per_second": 253.425,
      "eval_MathInstruct.json_steps_per_second": 10.601,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_alpaca_cleaned.json_loss": 0.9436292052268982,
      "eval_alpaca_cleaned.json_runtime": 2.4375,
      "eval_alpaca_cleaned.json_samples_per_second": 365.125,
      "eval_alpaca_cleaned.json_steps_per_second": 15.59,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_multi_turn_datas_0816.json_loss": 0.3309599757194519,
      "eval_multi_turn_datas_0816.json_runtime": 71.2552,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.399,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.4,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_sharegpt_gpt4.json_loss": 0.7683000564575195,
      "eval_sharegpt_gpt4.json_runtime": 21.7096,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.929,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.81,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_python_code_critic_21k.json_loss": 0.6474975347518921,
      "eval_python_code_critic_21k.json_runtime": 1.9534,
      "eval_python_code_critic_21k.json_samples_per_second": 147.948,
      "eval_python_code_critic_21k.json_steps_per_second": 6.655,
      "step": 600
    },
    {
      "epoch": 0.24927295388450352,
      "eval_agent_instruct.json_loss": 0.21587228775024414,
      "eval_agent_instruct.json_runtime": 0.2431,
      "eval_agent_instruct.json_samples_per_second": 90.479,
      "eval_agent_instruct.json_steps_per_second": 4.113,
      "step": 600
    },
    {
      "epoch": 0.2501038637307852,
      "grad_norm": 0.3837810754776001,
      "learning_rate": 1e-05,
      "loss": 0.4535,
      "step": 602
    },
    {
      "epoch": 0.2509347735770669,
      "grad_norm": 0.37199023365974426,
      "learning_rate": 1e-05,
      "loss": 0.4558,
      "step": 604
    },
    {
      "epoch": 0.25176568342334854,
      "grad_norm": 0.41338497400283813,
      "learning_rate": 1e-05,
      "loss": 0.4411,
      "step": 606
    },
    {
      "epoch": 0.25259659326963024,
      "grad_norm": 0.3700554370880127,
      "learning_rate": 1e-05,
      "loss": 0.4434,
      "step": 608
    },
    {
      "epoch": 0.25342750311591195,
      "grad_norm": 0.39363399147987366,
      "learning_rate": 1e-05,
      "loss": 0.4357,
      "step": 610
    },
    {
      "epoch": 0.2542584129621936,
      "grad_norm": 0.37940728664398193,
      "learning_rate": 1e-05,
      "loss": 0.4497,
      "step": 612
    },
    {
      "epoch": 0.2550893228084753,
      "grad_norm": 0.3616749942302704,
      "learning_rate": 1e-05,
      "loss": 0.4312,
      "step": 614
    },
    {
      "epoch": 0.25592023265475694,
      "grad_norm": 0.37348002195358276,
      "learning_rate": 1e-05,
      "loss": 0.4444,
      "step": 616
    },
    {
      "epoch": 0.25675114250103864,
      "grad_norm": 0.3742141127586365,
      "learning_rate": 1e-05,
      "loss": 0.4364,
      "step": 618
    },
    {
      "epoch": 0.2575820523473203,
      "grad_norm": 0.3745512068271637,
      "learning_rate": 1e-05,
      "loss": 0.4547,
      "step": 620
    },
    {
      "epoch": 0.258412962193602,
      "grad_norm": 0.37418338656425476,
      "learning_rate": 1e-05,
      "loss": 0.4323,
      "step": 622
    },
    {
      "epoch": 0.2592438720398837,
      "grad_norm": 0.3845473825931549,
      "learning_rate": 1e-05,
      "loss": 0.439,
      "step": 624
    },
    {
      "epoch": 0.26007478188616534,
      "grad_norm": 0.3829194903373718,
      "learning_rate": 1e-05,
      "loss": 0.4412,
      "step": 626
    },
    {
      "epoch": 0.26090569173244704,
      "grad_norm": 0.4063732326030731,
      "learning_rate": 1e-05,
      "loss": 0.4453,
      "step": 628
    },
    {
      "epoch": 0.2617366015787287,
      "grad_norm": 0.38282710313796997,
      "learning_rate": 1e-05,
      "loss": 0.4367,
      "step": 630
    },
    {
      "epoch": 0.2625675114250104,
      "grad_norm": 0.41676488518714905,
      "learning_rate": 1e-05,
      "loss": 0.456,
      "step": 632
    },
    {
      "epoch": 0.26339842127129204,
      "grad_norm": 0.3726726472377777,
      "learning_rate": 1e-05,
      "loss": 0.4356,
      "step": 634
    },
    {
      "epoch": 0.26422933111757374,
      "grad_norm": 0.38639479875564575,
      "learning_rate": 1e-05,
      "loss": 0.4515,
      "step": 636
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 0.3757264018058777,
      "learning_rate": 1e-05,
      "loss": 0.4501,
      "step": 638
    },
    {
      "epoch": 0.2658911508101371,
      "grad_norm": 0.39658212661743164,
      "learning_rate": 1e-05,
      "loss": 0.4465,
      "step": 640
    },
    {
      "epoch": 0.2667220606564188,
      "grad_norm": 0.38269826769828796,
      "learning_rate": 1e-05,
      "loss": 0.443,
      "step": 642
    },
    {
      "epoch": 0.26755297050270044,
      "grad_norm": 0.38188010454177856,
      "learning_rate": 1e-05,
      "loss": 0.4344,
      "step": 644
    },
    {
      "epoch": 0.26838388034898214,
      "grad_norm": 0.3658812344074249,
      "learning_rate": 1e-05,
      "loss": 0.4528,
      "step": 646
    },
    {
      "epoch": 0.2692147901952638,
      "grad_norm": 0.3710874319076538,
      "learning_rate": 1e-05,
      "loss": 0.428,
      "step": 648
    },
    {
      "epoch": 0.2700457000415455,
      "grad_norm": 0.40686309337615967,
      "learning_rate": 1e-05,
      "loss": 0.4583,
      "step": 650
    },
    {
      "epoch": 0.2708766098878272,
      "grad_norm": 0.3806234896183014,
      "learning_rate": 1e-05,
      "loss": 0.4584,
      "step": 652
    },
    {
      "epoch": 0.27170751973410884,
      "grad_norm": 0.3890298008918762,
      "learning_rate": 1e-05,
      "loss": 0.4492,
      "step": 654
    },
    {
      "epoch": 0.27253842958039054,
      "grad_norm": 0.4113003611564636,
      "learning_rate": 1e-05,
      "loss": 0.4578,
      "step": 656
    },
    {
      "epoch": 0.2733693394266722,
      "grad_norm": 0.3831964135169983,
      "learning_rate": 1e-05,
      "loss": 0.4576,
      "step": 658
    },
    {
      "epoch": 0.2742002492729539,
      "grad_norm": 0.3939773142337799,
      "learning_rate": 1e-05,
      "loss": 0.4458,
      "step": 660
    },
    {
      "epoch": 0.27503115911923554,
      "grad_norm": 0.3776020407676697,
      "learning_rate": 1e-05,
      "loss": 0.4408,
      "step": 662
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 0.3824210464954376,
      "learning_rate": 1e-05,
      "loss": 0.4379,
      "step": 664
    },
    {
      "epoch": 0.27669297881179894,
      "grad_norm": 0.38113218545913696,
      "learning_rate": 1e-05,
      "loss": 0.4455,
      "step": 666
    },
    {
      "epoch": 0.2775238886580806,
      "grad_norm": 0.3849034905433655,
      "learning_rate": 1e-05,
      "loss": 0.457,
      "step": 668
    },
    {
      "epoch": 0.2783547985043623,
      "grad_norm": 0.36279863119125366,
      "learning_rate": 1e-05,
      "loss": 0.4409,
      "step": 670
    },
    {
      "epoch": 0.27918570835064394,
      "grad_norm": 0.3926472067832947,
      "learning_rate": 1e-05,
      "loss": 0.4441,
      "step": 672
    },
    {
      "epoch": 0.28001661819692564,
      "grad_norm": 0.38586893677711487,
      "learning_rate": 1e-05,
      "loss": 0.4239,
      "step": 674
    },
    {
      "epoch": 0.28084752804320734,
      "grad_norm": 0.36755993962287903,
      "learning_rate": 1e-05,
      "loss": 0.4593,
      "step": 676
    },
    {
      "epoch": 0.281678437889489,
      "grad_norm": 0.36812227964401245,
      "learning_rate": 1e-05,
      "loss": 0.428,
      "step": 678
    },
    {
      "epoch": 0.2825093477357707,
      "grad_norm": 0.3958202004432678,
      "learning_rate": 1e-05,
      "loss": 0.4467,
      "step": 680
    },
    {
      "epoch": 0.28334025758205234,
      "grad_norm": 0.398671418428421,
      "learning_rate": 1e-05,
      "loss": 0.4503,
      "step": 682
    },
    {
      "epoch": 0.28417116742833404,
      "grad_norm": 0.37693747878074646,
      "learning_rate": 1e-05,
      "loss": 0.442,
      "step": 684
    },
    {
      "epoch": 0.2850020772746157,
      "grad_norm": 0.3536854684352875,
      "learning_rate": 1e-05,
      "loss": 0.4267,
      "step": 686
    },
    {
      "epoch": 0.2858329871208974,
      "grad_norm": 0.38479408621788025,
      "learning_rate": 1e-05,
      "loss": 0.4427,
      "step": 688
    },
    {
      "epoch": 0.2866638969671791,
      "grad_norm": 0.3935563564300537,
      "learning_rate": 1e-05,
      "loss": 0.4658,
      "step": 690
    },
    {
      "epoch": 0.28749480681346073,
      "grad_norm": 0.39768052101135254,
      "learning_rate": 1e-05,
      "loss": 0.4494,
      "step": 692
    },
    {
      "epoch": 0.28832571665974244,
      "grad_norm": 0.39273279905319214,
      "learning_rate": 1e-05,
      "loss": 0.4464,
      "step": 694
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 0.39094164967536926,
      "learning_rate": 1e-05,
      "loss": 0.4346,
      "step": 696
    },
    {
      "epoch": 0.2899875363523058,
      "grad_norm": 0.3894290626049042,
      "learning_rate": 1e-05,
      "loss": 0.4475,
      "step": 698
    },
    {
      "epoch": 0.29081844619858743,
      "grad_norm": 0.3693331182003021,
      "learning_rate": 1e-05,
      "loss": 0.4684,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_alpaca_gpt4_zh.json_loss": 1.3734571933746338,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4765,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 443.607,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.963,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_ultrainteract_sft.json_loss": 0.45982590317726135,
      "eval_ultrainteract_sft.json_runtime": 18.0255,
      "eval_ultrainteract_sft.json_samples_per_second": 159.219,
      "eval_ultrainteract_sft.json_steps_per_second": 6.657,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_code_feedback_multi_turn.json_loss": 0.571861207485199,
      "eval_code_feedback_multi_turn.json_runtime": 15.323,
      "eval_code_feedback_multi_turn.json_samples_per_second": 66.306,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.806,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_tested_143k_python_alpaca.json_loss": 0.3648061752319336,
      "eval_tested_143k_python_alpaca.json_runtime": 14.2885,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 162.228,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.789,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_synthetic_text_to_sql.json_loss": 0.17583580315113068,
      "eval_synthetic_text_to_sql.json_runtime": 3.3278,
      "eval_synthetic_text_to_sql.json_samples_per_second": 419.19,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.729,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_codefeedback_filtered_instruction.json_loss": 0.42013347148895264,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0099,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.027,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.293,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_train_data_for_qwen.json_loss": 0.01780911348760128,
      "eval_train_data_for_qwen.json_runtime": 3.6572,
      "eval_train_data_for_qwen.json_samples_per_second": 120.311,
      "eval_train_data_for_qwen.json_steps_per_second": 5.195,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4508861303329468,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8888,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 394.441,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.942,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_all_merge_code.json_loss": 0.24572406709194183,
      "eval_all_merge_code.json_runtime": 16.7528,
      "eval_all_merge_code.json_samples_per_second": 206.651,
      "eval_all_merge_code.json_steps_per_second": 8.655,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_xlam_function_calling_60k.json_loss": 0.020668743178248405,
      "eval_xlam_function_calling_60k.json_runtime": 4.4036,
      "eval_xlam_function_calling_60k.json_samples_per_second": 201.425,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.402,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_table_python_code_datas.json_loss": 0.1635298877954483,
      "eval_table_python_code_datas.json_runtime": 66.289,
      "eval_table_python_code_datas.json_samples_per_second": 70.359,
      "eval_table_python_code_datas.json_steps_per_second": 2.942,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_Table_GPT.json_loss": 0.06697103381156921,
      "eval_Table_GPT.json_runtime": 10.5686,
      "eval_Table_GPT.json_samples_per_second": 83.928,
      "eval_Table_GPT.json_steps_per_second": 3.501,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_tabular_llm_data.json_loss": 0.11491163820028305,
      "eval_tabular_llm_data.json_runtime": 50.4526,
      "eval_tabular_llm_data.json_samples_per_second": 58.074,
      "eval_tabular_llm_data.json_steps_per_second": 2.438,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_gpt_4o_200k.json_loss": 0.8547415137290955,
      "eval_gpt_4o_200k.json_runtime": 27.2248,
      "eval_gpt_4o_200k.json_samples_per_second": 131.167,
      "eval_gpt_4o_200k.json_steps_per_second": 5.473,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_MathInstruct.json_loss": 0.1784396767616272,
      "eval_MathInstruct.json_runtime": 13.0217,
      "eval_MathInstruct.json_samples_per_second": 251.503,
      "eval_MathInstruct.json_steps_per_second": 10.521,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_alpaca_cleaned.json_loss": 0.9403731822967529,
      "eval_alpaca_cleaned.json_runtime": 2.3762,
      "eval_alpaca_cleaned.json_samples_per_second": 374.553,
      "eval_alpaca_cleaned.json_steps_per_second": 15.992,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_multi_turn_datas_0816.json_loss": 0.32617971301078796,
      "eval_multi_turn_datas_0816.json_runtime": 71.2473,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.406,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.4,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_sharegpt_gpt4.json_loss": 0.7635565400123596,
      "eval_sharegpt_gpt4.json_runtime": 21.6973,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.967,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.811,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_python_code_critic_21k.json_loss": 0.6408145427703857,
      "eval_python_code_critic_21k.json_runtime": 1.9533,
      "eval_python_code_critic_21k.json_samples_per_second": 147.954,
      "eval_python_code_critic_21k.json_steps_per_second": 6.655,
      "step": 700
    },
    {
      "epoch": 0.29081844619858743,
      "eval_agent_instruct.json_loss": 0.21123377978801727,
      "eval_agent_instruct.json_runtime": 0.2438,
      "eval_agent_instruct.json_samples_per_second": 90.234,
      "eval_agent_instruct.json_steps_per_second": 4.102,
      "step": 700
    },
    {
      "epoch": 0.29164935604486913,
      "grad_norm": 0.38689124584198,
      "learning_rate": 1e-05,
      "loss": 0.4573,
      "step": 702
    },
    {
      "epoch": 0.29248026589115084,
      "grad_norm": 0.3818666934967041,
      "learning_rate": 1e-05,
      "loss": 0.4527,
      "step": 704
    },
    {
      "epoch": 0.2933111757374325,
      "grad_norm": 0.39988094568252563,
      "learning_rate": 1e-05,
      "loss": 0.4487,
      "step": 706
    },
    {
      "epoch": 0.2941420855837142,
      "grad_norm": 0.3930993974208832,
      "learning_rate": 1e-05,
      "loss": 0.4403,
      "step": 708
    },
    {
      "epoch": 0.29497299542999583,
      "grad_norm": 0.3743358552455902,
      "learning_rate": 1e-05,
      "loss": 0.4312,
      "step": 710
    },
    {
      "epoch": 0.29580390527627753,
      "grad_norm": 0.38736286759376526,
      "learning_rate": 1e-05,
      "loss": 0.4564,
      "step": 712
    },
    {
      "epoch": 0.2966348151225592,
      "grad_norm": 0.359293133020401,
      "learning_rate": 1e-05,
      "loss": 0.428,
      "step": 714
    },
    {
      "epoch": 0.2974657249688409,
      "grad_norm": 0.37262699007987976,
      "learning_rate": 1e-05,
      "loss": 0.443,
      "step": 716
    },
    {
      "epoch": 0.2982966348151226,
      "grad_norm": 0.3652849495410919,
      "learning_rate": 1e-05,
      "loss": 0.4545,
      "step": 718
    },
    {
      "epoch": 0.29912754466140423,
      "grad_norm": 0.39185652136802673,
      "learning_rate": 1e-05,
      "loss": 0.4422,
      "step": 720
    },
    {
      "epoch": 0.29995845450768593,
      "grad_norm": 0.35846269130706787,
      "learning_rate": 1e-05,
      "loss": 0.4356,
      "step": 722
    },
    {
      "epoch": 0.3007893643539676,
      "grad_norm": 0.368708074092865,
      "learning_rate": 1e-05,
      "loss": 0.4199,
      "step": 724
    },
    {
      "epoch": 0.3016202742002493,
      "grad_norm": 0.38969939947128296,
      "learning_rate": 1e-05,
      "loss": 0.4464,
      "step": 726
    },
    {
      "epoch": 0.30245118404653093,
      "grad_norm": 0.3832743763923645,
      "learning_rate": 1e-05,
      "loss": 0.4332,
      "step": 728
    },
    {
      "epoch": 0.30328209389281263,
      "grad_norm": 0.3861016035079956,
      "learning_rate": 1e-05,
      "loss": 0.4579,
      "step": 730
    },
    {
      "epoch": 0.30411300373909433,
      "grad_norm": 0.3743666708469391,
      "learning_rate": 1e-05,
      "loss": 0.4477,
      "step": 732
    },
    {
      "epoch": 0.304943913585376,
      "grad_norm": 0.37870609760284424,
      "learning_rate": 1e-05,
      "loss": 0.4511,
      "step": 734
    },
    {
      "epoch": 0.3057748234316577,
      "grad_norm": 0.3795003592967987,
      "learning_rate": 1e-05,
      "loss": 0.4509,
      "step": 736
    },
    {
      "epoch": 0.30660573327793933,
      "grad_norm": 0.4060972034931183,
      "learning_rate": 1e-05,
      "loss": 0.4268,
      "step": 738
    },
    {
      "epoch": 0.30743664312422103,
      "grad_norm": 0.3609159290790558,
      "learning_rate": 1e-05,
      "loss": 0.4346,
      "step": 740
    },
    {
      "epoch": 0.3082675529705027,
      "grad_norm": 0.3907022178173065,
      "learning_rate": 1e-05,
      "loss": 0.4443,
      "step": 742
    },
    {
      "epoch": 0.3090984628167844,
      "grad_norm": 0.3765166103839874,
      "learning_rate": 1e-05,
      "loss": 0.4424,
      "step": 744
    },
    {
      "epoch": 0.3099293726630661,
      "grad_norm": 0.39032021164894104,
      "learning_rate": 1e-05,
      "loss": 0.4479,
      "step": 746
    },
    {
      "epoch": 0.31076028250934773,
      "grad_norm": 0.37225839495658875,
      "learning_rate": 1e-05,
      "loss": 0.4329,
      "step": 748
    },
    {
      "epoch": 0.31159119235562943,
      "grad_norm": 0.3731112778186798,
      "learning_rate": 1e-05,
      "loss": 0.4301,
      "step": 750
    },
    {
      "epoch": 0.3124221022019111,
      "grad_norm": 0.37030941247940063,
      "learning_rate": 1e-05,
      "loss": 0.4489,
      "step": 752
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 0.3539632260799408,
      "learning_rate": 1e-05,
      "loss": 0.4365,
      "step": 754
    },
    {
      "epoch": 0.3140839218944744,
      "grad_norm": 0.3817583918571472,
      "learning_rate": 1e-05,
      "loss": 0.4396,
      "step": 756
    },
    {
      "epoch": 0.31491483174075613,
      "grad_norm": 0.3629050552845001,
      "learning_rate": 1e-05,
      "loss": 0.4204,
      "step": 758
    },
    {
      "epoch": 0.31574574158703783,
      "grad_norm": 0.3736037015914917,
      "learning_rate": 1e-05,
      "loss": 0.4321,
      "step": 760
    },
    {
      "epoch": 0.3165766514333195,
      "grad_norm": 0.3678704798221588,
      "learning_rate": 1e-05,
      "loss": 0.4298,
      "step": 762
    },
    {
      "epoch": 0.3174075612796012,
      "grad_norm": 0.3958984613418579,
      "learning_rate": 1e-05,
      "loss": 0.4163,
      "step": 764
    },
    {
      "epoch": 0.3182384711258828,
      "grad_norm": 0.3923443853855133,
      "learning_rate": 1e-05,
      "loss": 0.4324,
      "step": 766
    },
    {
      "epoch": 0.31906938097216453,
      "grad_norm": 0.3649122416973114,
      "learning_rate": 1e-05,
      "loss": 0.4493,
      "step": 768
    },
    {
      "epoch": 0.3199002908184462,
      "grad_norm": 0.3600987195968628,
      "learning_rate": 1e-05,
      "loss": 0.4312,
      "step": 770
    },
    {
      "epoch": 0.3207312006647279,
      "grad_norm": 0.39712023735046387,
      "learning_rate": 1e-05,
      "loss": 0.4393,
      "step": 772
    },
    {
      "epoch": 0.3215621105110096,
      "grad_norm": 0.38247382640838623,
      "learning_rate": 1e-05,
      "loss": 0.4558,
      "step": 774
    },
    {
      "epoch": 0.3223930203572912,
      "grad_norm": 0.3733488917350769,
      "learning_rate": 1e-05,
      "loss": 0.4516,
      "step": 776
    },
    {
      "epoch": 0.32322393020357293,
      "grad_norm": 0.3730683922767639,
      "learning_rate": 1e-05,
      "loss": 0.4423,
      "step": 778
    },
    {
      "epoch": 0.3240548400498546,
      "grad_norm": 0.38478440046310425,
      "learning_rate": 1e-05,
      "loss": 0.4284,
      "step": 780
    },
    {
      "epoch": 0.3248857498961363,
      "grad_norm": 0.3958960175514221,
      "learning_rate": 1e-05,
      "loss": 0.432,
      "step": 782
    },
    {
      "epoch": 0.3257166597424179,
      "grad_norm": 0.39261046051979065,
      "learning_rate": 1e-05,
      "loss": 0.4269,
      "step": 784
    },
    {
      "epoch": 0.3265475695886996,
      "grad_norm": 0.3840441107749939,
      "learning_rate": 1e-05,
      "loss": 0.4402,
      "step": 786
    },
    {
      "epoch": 0.32737847943498133,
      "grad_norm": 0.37201496958732605,
      "learning_rate": 1e-05,
      "loss": 0.4372,
      "step": 788
    },
    {
      "epoch": 0.328209389281263,
      "grad_norm": 0.37390875816345215,
      "learning_rate": 1e-05,
      "loss": 0.4371,
      "step": 790
    },
    {
      "epoch": 0.3290402991275447,
      "grad_norm": 0.3824620544910431,
      "learning_rate": 1e-05,
      "loss": 0.452,
      "step": 792
    },
    {
      "epoch": 0.3298712089738263,
      "grad_norm": 0.39682894945144653,
      "learning_rate": 1e-05,
      "loss": 0.4367,
      "step": 794
    },
    {
      "epoch": 0.330702118820108,
      "grad_norm": 0.3950163424015045,
      "learning_rate": 1e-05,
      "loss": 0.4368,
      "step": 796
    },
    {
      "epoch": 0.3315330286663897,
      "grad_norm": 0.3988023102283478,
      "learning_rate": 1e-05,
      "loss": 0.4184,
      "step": 798
    },
    {
      "epoch": 0.3323639385126714,
      "grad_norm": 0.39616402983665466,
      "learning_rate": 1e-05,
      "loss": 0.4301,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_alpaca_gpt4_zh.json_loss": 1.3742204904556274,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4796,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 442.7,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.925,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_ultrainteract_sft.json_loss": 0.45711103081703186,
      "eval_ultrainteract_sft.json_runtime": 18.0199,
      "eval_ultrainteract_sft.json_samples_per_second": 159.269,
      "eval_ultrainteract_sft.json_steps_per_second": 6.659,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_code_feedback_multi_turn.json_loss": 0.5704612135887146,
      "eval_code_feedback_multi_turn.json_runtime": 14.8567,
      "eval_code_feedback_multi_turn.json_samples_per_second": 68.387,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.894,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_tested_143k_python_alpaca.json_loss": 0.3602572977542877,
      "eval_tested_143k_python_alpaca.json_runtime": 14.0741,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.7,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.892,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_synthetic_text_to_sql.json_loss": 0.17536543309688568,
      "eval_synthetic_text_to_sql.json_runtime": 3.4539,
      "eval_synthetic_text_to_sql.json_samples_per_second": 403.897,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.082,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_codefeedback_filtered_instruction.json_loss": 0.4128626585006714,
      "eval_codefeedback_filtered_instruction.json_runtime": 9.9823,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.511,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.313,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_train_data_for_qwen.json_loss": 0.017378706485033035,
      "eval_train_data_for_qwen.json_runtime": 3.6566,
      "eval_train_data_for_qwen.json_samples_per_second": 120.332,
      "eval_train_data_for_qwen.json_steps_per_second": 5.196,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.443985939025879,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8823,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 395.788,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 17.0,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_all_merge_code.json_loss": 0.24168387055397034,
      "eval_all_merge_code.json_runtime": 16.7623,
      "eval_all_merge_code.json_samples_per_second": 206.534,
      "eval_all_merge_code.json_steps_per_second": 8.65,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_xlam_function_calling_60k.json_loss": 0.02041119709610939,
      "eval_xlam_function_calling_60k.json_runtime": 4.4495,
      "eval_xlam_function_calling_60k.json_samples_per_second": 199.347,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.315,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_table_python_code_datas.json_loss": 0.16167886555194855,
      "eval_table_python_code_datas.json_runtime": 66.4975,
      "eval_table_python_code_datas.json_samples_per_second": 70.138,
      "eval_table_python_code_datas.json_steps_per_second": 2.932,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_Table_GPT.json_loss": 0.0650387778878212,
      "eval_Table_GPT.json_runtime": 10.5439,
      "eval_Table_GPT.json_samples_per_second": 84.125,
      "eval_Table_GPT.json_steps_per_second": 3.509,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_tabular_llm_data.json_loss": 0.11706310510635376,
      "eval_tabular_llm_data.json_runtime": 50.4434,
      "eval_tabular_llm_data.json_samples_per_second": 58.085,
      "eval_tabular_llm_data.json_steps_per_second": 2.438,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_gpt_4o_200k.json_loss": 0.8526273965835571,
      "eval_gpt_4o_200k.json_runtime": 27.1621,
      "eval_gpt_4o_200k.json_samples_per_second": 131.47,
      "eval_gpt_4o_200k.json_steps_per_second": 5.486,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_MathInstruct.json_loss": 0.17829403281211853,
      "eval_MathInstruct.json_runtime": 12.9811,
      "eval_MathInstruct.json_samples_per_second": 252.291,
      "eval_MathInstruct.json_steps_per_second": 10.554,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_alpaca_cleaned.json_loss": 0.9417725801467896,
      "eval_alpaca_cleaned.json_runtime": 2.3685,
      "eval_alpaca_cleaned.json_samples_per_second": 375.772,
      "eval_alpaca_cleaned.json_steps_per_second": 16.044,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_multi_turn_datas_0816.json_loss": 0.3222891092300415,
      "eval_multi_turn_datas_0816.json_runtime": 71.2928,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.369,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.399,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_sharegpt_gpt4.json_loss": 0.7607254981994629,
      "eval_sharegpt_gpt4.json_runtime": 21.6698,
      "eval_sharegpt_gpt4.json_samples_per_second": 67.052,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.815,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_python_code_critic_21k.json_loss": 0.6383565068244934,
      "eval_python_code_critic_21k.json_runtime": 1.9397,
      "eval_python_code_critic_21k.json_samples_per_second": 148.991,
      "eval_python_code_critic_21k.json_steps_per_second": 6.702,
      "step": 800
    },
    {
      "epoch": 0.3323639385126714,
      "eval_agent_instruct.json_loss": 0.21440273523330688,
      "eval_agent_instruct.json_runtime": 0.2459,
      "eval_agent_instruct.json_samples_per_second": 89.476,
      "eval_agent_instruct.json_steps_per_second": 4.067,
      "step": 800
    },
    {
      "epoch": 0.3331948483589531,
      "grad_norm": 0.37708330154418945,
      "learning_rate": 1e-05,
      "loss": 0.434,
      "step": 802
    },
    {
      "epoch": 0.3340257582052347,
      "grad_norm": 0.3906972110271454,
      "learning_rate": 1e-05,
      "loss": 0.4442,
      "step": 804
    },
    {
      "epoch": 0.3348566680515164,
      "grad_norm": 0.3706229031085968,
      "learning_rate": 1e-05,
      "loss": 0.4471,
      "step": 806
    },
    {
      "epoch": 0.3356875778977981,
      "grad_norm": 0.3656423091888428,
      "learning_rate": 1e-05,
      "loss": 0.4327,
      "step": 808
    },
    {
      "epoch": 0.3365184877440798,
      "grad_norm": 0.3730226755142212,
      "learning_rate": 1e-05,
      "loss": 0.4355,
      "step": 810
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 0.3771923780441284,
      "learning_rate": 1e-05,
      "loss": 0.4296,
      "step": 812
    },
    {
      "epoch": 0.3381803074366431,
      "grad_norm": 0.38269996643066406,
      "learning_rate": 1e-05,
      "loss": 0.4373,
      "step": 814
    },
    {
      "epoch": 0.3390112172829248,
      "grad_norm": 0.3803582787513733,
      "learning_rate": 1e-05,
      "loss": 0.432,
      "step": 816
    },
    {
      "epoch": 0.3398421271292065,
      "grad_norm": 0.39159882068634033,
      "learning_rate": 1e-05,
      "loss": 0.4415,
      "step": 818
    },
    {
      "epoch": 0.3406730369754882,
      "grad_norm": 0.38586926460266113,
      "learning_rate": 1e-05,
      "loss": 0.4425,
      "step": 820
    },
    {
      "epoch": 0.3415039468217698,
      "grad_norm": 0.35857442021369934,
      "learning_rate": 1e-05,
      "loss": 0.436,
      "step": 822
    },
    {
      "epoch": 0.3423348566680515,
      "grad_norm": 0.3823945224285126,
      "learning_rate": 1e-05,
      "loss": 0.45,
      "step": 824
    },
    {
      "epoch": 0.34316576651433317,
      "grad_norm": 0.39610227942466736,
      "learning_rate": 1e-05,
      "loss": 0.4454,
      "step": 826
    },
    {
      "epoch": 0.3439966763606149,
      "grad_norm": 0.3863031268119812,
      "learning_rate": 1e-05,
      "loss": 0.4417,
      "step": 828
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.3976540267467499,
      "learning_rate": 1e-05,
      "loss": 0.4528,
      "step": 830
    },
    {
      "epoch": 0.3456584960531782,
      "grad_norm": 0.37132102251052856,
      "learning_rate": 1e-05,
      "loss": 0.4312,
      "step": 832
    },
    {
      "epoch": 0.3464894058994599,
      "grad_norm": 0.3738451600074768,
      "learning_rate": 1e-05,
      "loss": 0.427,
      "step": 834
    },
    {
      "epoch": 0.34732031574574157,
      "grad_norm": 0.38497254252433777,
      "learning_rate": 1e-05,
      "loss": 0.4429,
      "step": 836
    },
    {
      "epoch": 0.3481512255920233,
      "grad_norm": 0.39015889167785645,
      "learning_rate": 1e-05,
      "loss": 0.4219,
      "step": 838
    },
    {
      "epoch": 0.3489821354383049,
      "grad_norm": 0.3941672444343567,
      "learning_rate": 1e-05,
      "loss": 0.4304,
      "step": 840
    },
    {
      "epoch": 0.3498130452845866,
      "grad_norm": 0.3903898298740387,
      "learning_rate": 1e-05,
      "loss": 0.4293,
      "step": 842
    },
    {
      "epoch": 0.3506439551308683,
      "grad_norm": 0.37364646792411804,
      "learning_rate": 1e-05,
      "loss": 0.4341,
      "step": 844
    },
    {
      "epoch": 0.35147486497714997,
      "grad_norm": 0.38521745800971985,
      "learning_rate": 1e-05,
      "loss": 0.4398,
      "step": 846
    },
    {
      "epoch": 0.35230577482343167,
      "grad_norm": 0.35345783829689026,
      "learning_rate": 1e-05,
      "loss": 0.4157,
      "step": 848
    },
    {
      "epoch": 0.3531366846697133,
      "grad_norm": 0.3775588274002075,
      "learning_rate": 1e-05,
      "loss": 0.459,
      "step": 850
    },
    {
      "epoch": 0.353967594515995,
      "grad_norm": 0.3586050868034363,
      "learning_rate": 1e-05,
      "loss": 0.4543,
      "step": 852
    },
    {
      "epoch": 0.35479850436227667,
      "grad_norm": 0.37637484073638916,
      "learning_rate": 1e-05,
      "loss": 0.4347,
      "step": 854
    },
    {
      "epoch": 0.35562941420855837,
      "grad_norm": 0.38210904598236084,
      "learning_rate": 1e-05,
      "loss": 0.4206,
      "step": 856
    },
    {
      "epoch": 0.35646032405484007,
      "grad_norm": 0.3943355679512024,
      "learning_rate": 1e-05,
      "loss": 0.4353,
      "step": 858
    },
    {
      "epoch": 0.3572912339011217,
      "grad_norm": 0.36839643120765686,
      "learning_rate": 1e-05,
      "loss": 0.4232,
      "step": 860
    },
    {
      "epoch": 0.3581221437474034,
      "grad_norm": 0.38726645708084106,
      "learning_rate": 1e-05,
      "loss": 0.4211,
      "step": 862
    },
    {
      "epoch": 0.35895305359368507,
      "grad_norm": 0.36574557423591614,
      "learning_rate": 1e-05,
      "loss": 0.4272,
      "step": 864
    },
    {
      "epoch": 0.35978396343996677,
      "grad_norm": 0.3732050061225891,
      "learning_rate": 1e-05,
      "loss": 0.4246,
      "step": 866
    },
    {
      "epoch": 0.3606148732862484,
      "grad_norm": 0.3834652602672577,
      "learning_rate": 1e-05,
      "loss": 0.4345,
      "step": 868
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 0.37450703978538513,
      "learning_rate": 1e-05,
      "loss": 0.4407,
      "step": 870
    },
    {
      "epoch": 0.3622766929788118,
      "grad_norm": 0.3754009008407593,
      "learning_rate": 1e-05,
      "loss": 0.4329,
      "step": 872
    },
    {
      "epoch": 0.36310760282509347,
      "grad_norm": 0.3734050989151001,
      "learning_rate": 1e-05,
      "loss": 0.4281,
      "step": 874
    },
    {
      "epoch": 0.36393851267137517,
      "grad_norm": 0.40032801032066345,
      "learning_rate": 1e-05,
      "loss": 0.4375,
      "step": 876
    },
    {
      "epoch": 0.3647694225176568,
      "grad_norm": 0.39302611351013184,
      "learning_rate": 1e-05,
      "loss": 0.4462,
      "step": 878
    },
    {
      "epoch": 0.3656003323639385,
      "grad_norm": 0.36948326230049133,
      "learning_rate": 1e-05,
      "loss": 0.4417,
      "step": 880
    },
    {
      "epoch": 0.36643124221022016,
      "grad_norm": 0.3806324899196625,
      "learning_rate": 1e-05,
      "loss": 0.4307,
      "step": 882
    },
    {
      "epoch": 0.36726215205650187,
      "grad_norm": 0.389180064201355,
      "learning_rate": 1e-05,
      "loss": 0.4363,
      "step": 884
    },
    {
      "epoch": 0.36809306190278357,
      "grad_norm": 0.3790798783302307,
      "learning_rate": 1e-05,
      "loss": 0.4443,
      "step": 886
    },
    {
      "epoch": 0.3689239717490652,
      "grad_norm": 0.3683941662311554,
      "learning_rate": 1e-05,
      "loss": 0.4276,
      "step": 888
    },
    {
      "epoch": 0.3697548815953469,
      "grad_norm": 0.3728275001049042,
      "learning_rate": 1e-05,
      "loss": 0.4243,
      "step": 890
    },
    {
      "epoch": 0.37058579144162856,
      "grad_norm": 0.37048232555389404,
      "learning_rate": 1e-05,
      "loss": 0.439,
      "step": 892
    },
    {
      "epoch": 0.37141670128791027,
      "grad_norm": 0.3672337532043457,
      "learning_rate": 1e-05,
      "loss": 0.429,
      "step": 894
    },
    {
      "epoch": 0.3722476111341919,
      "grad_norm": 0.37829896807670593,
      "learning_rate": 1e-05,
      "loss": 0.4078,
      "step": 896
    },
    {
      "epoch": 0.3730785209804736,
      "grad_norm": 0.3842991590499878,
      "learning_rate": 1e-05,
      "loss": 0.4276,
      "step": 898
    },
    {
      "epoch": 0.3739094308267553,
      "grad_norm": 0.38691824674606323,
      "learning_rate": 1e-05,
      "loss": 0.433,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_alpaca_gpt4_zh.json_loss": 1.3738563060760498,
      "eval_alpaca_gpt4_zh.json_runtime": 1.468,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 446.182,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 19.073,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_ultrainteract_sft.json_loss": 0.4551907777786255,
      "eval_ultrainteract_sft.json_runtime": 18.0409,
      "eval_ultrainteract_sft.json_samples_per_second": 159.083,
      "eval_ultrainteract_sft.json_steps_per_second": 6.652,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_code_feedback_multi_turn.json_loss": 0.5685745477676392,
      "eval_code_feedback_multi_turn.json_runtime": 15.7152,
      "eval_code_feedback_multi_turn.json_samples_per_second": 64.651,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.736,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_tested_143k_python_alpaca.json_loss": 0.35608041286468506,
      "eval_tested_143k_python_alpaca.json_runtime": 14.3017,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 162.078,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.782,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_synthetic_text_to_sql.json_loss": 0.17178285121917725,
      "eval_synthetic_text_to_sql.json_runtime": 3.3352,
      "eval_synthetic_text_to_sql.json_samples_per_second": 418.268,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.69,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_codefeedback_filtered_instruction.json_loss": 0.4065958261489868,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0032,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.143,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.298,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_train_data_for_qwen.json_loss": 0.017576081678271294,
      "eval_train_data_for_qwen.json_runtime": 3.6639,
      "eval_train_data_for_qwen.json_samples_per_second": 120.089,
      "eval_train_data_for_qwen.json_steps_per_second": 5.186,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4393959045410156,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8916,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 393.853,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.917,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_all_merge_code.json_loss": 0.23730668425559998,
      "eval_all_merge_code.json_runtime": 16.8256,
      "eval_all_merge_code.json_samples_per_second": 205.758,
      "eval_all_merge_code.json_steps_per_second": 8.618,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_xlam_function_calling_60k.json_loss": 0.01943599246442318,
      "eval_xlam_function_calling_60k.json_runtime": 4.4347,
      "eval_xlam_function_calling_60k.json_samples_per_second": 200.015,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.343,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_table_python_code_datas.json_loss": 0.15937048196792603,
      "eval_table_python_code_datas.json_runtime": 66.583,
      "eval_table_python_code_datas.json_samples_per_second": 70.048,
      "eval_table_python_code_datas.json_steps_per_second": 2.929,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_Table_GPT.json_loss": 0.06400437653064728,
      "eval_Table_GPT.json_runtime": 10.5628,
      "eval_Table_GPT.json_samples_per_second": 83.974,
      "eval_Table_GPT.json_steps_per_second": 3.503,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_tabular_llm_data.json_loss": 0.11294592916965485,
      "eval_tabular_llm_data.json_runtime": 50.5936,
      "eval_tabular_llm_data.json_samples_per_second": 57.912,
      "eval_tabular_llm_data.json_steps_per_second": 2.431,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_gpt_4o_200k.json_loss": 0.8516356348991394,
      "eval_gpt_4o_200k.json_runtime": 27.2116,
      "eval_gpt_4o_200k.json_samples_per_second": 131.231,
      "eval_gpt_4o_200k.json_steps_per_second": 5.476,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_MathInstruct.json_loss": 0.17747150361537933,
      "eval_MathInstruct.json_runtime": 12.9892,
      "eval_MathInstruct.json_samples_per_second": 252.132,
      "eval_MathInstruct.json_steps_per_second": 10.547,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_alpaca_cleaned.json_loss": 0.9383381605148315,
      "eval_alpaca_cleaned.json_runtime": 2.3684,
      "eval_alpaca_cleaned.json_samples_per_second": 375.777,
      "eval_alpaca_cleaned.json_steps_per_second": 16.044,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_multi_turn_datas_0816.json_loss": 0.31736767292022705,
      "eval_multi_turn_datas_0816.json_runtime": 71.1258,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.504,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.404,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_sharegpt_gpt4.json_loss": 0.7571661472320557,
      "eval_sharegpt_gpt4.json_runtime": 21.8445,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.516,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.792,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_python_code_critic_21k.json_loss": 0.6352238655090332,
      "eval_python_code_critic_21k.json_runtime": 1.9554,
      "eval_python_code_critic_21k.json_samples_per_second": 147.793,
      "eval_python_code_critic_21k.json_steps_per_second": 6.648,
      "step": 900
    },
    {
      "epoch": 0.3739094308267553,
      "eval_agent_instruct.json_loss": 0.20921798050403595,
      "eval_agent_instruct.json_runtime": 0.244,
      "eval_agent_instruct.json_samples_per_second": 90.165,
      "eval_agent_instruct.json_steps_per_second": 4.098,
      "step": 900
    },
    {
      "epoch": 0.37474034067303696,
      "grad_norm": 0.37590956687927246,
      "learning_rate": 1e-05,
      "loss": 0.4227,
      "step": 902
    },
    {
      "epoch": 0.37557125051931867,
      "grad_norm": 0.3593798577785492,
      "learning_rate": 1e-05,
      "loss": 0.4192,
      "step": 904
    },
    {
      "epoch": 0.3764021603656003,
      "grad_norm": 0.37829598784446716,
      "learning_rate": 1e-05,
      "loss": 0.4356,
      "step": 906
    },
    {
      "epoch": 0.377233070211882,
      "grad_norm": 0.3938077986240387,
      "learning_rate": 1e-05,
      "loss": 0.4318,
      "step": 908
    },
    {
      "epoch": 0.37806398005816366,
      "grad_norm": 0.380633145570755,
      "learning_rate": 1e-05,
      "loss": 0.4362,
      "step": 910
    },
    {
      "epoch": 0.37889488990444536,
      "grad_norm": 0.3651394844055176,
      "learning_rate": 1e-05,
      "loss": 0.4276,
      "step": 912
    },
    {
      "epoch": 0.37972579975072707,
      "grad_norm": 0.38481053709983826,
      "learning_rate": 1e-05,
      "loss": 0.427,
      "step": 914
    },
    {
      "epoch": 0.3805567095970087,
      "grad_norm": 0.3618808686733246,
      "learning_rate": 1e-05,
      "loss": 0.4273,
      "step": 916
    },
    {
      "epoch": 0.3813876194432904,
      "grad_norm": 0.37558692693710327,
      "learning_rate": 1e-05,
      "loss": 0.4376,
      "step": 918
    },
    {
      "epoch": 0.38221852928957206,
      "grad_norm": 0.3870772123336792,
      "learning_rate": 1e-05,
      "loss": 0.4219,
      "step": 920
    },
    {
      "epoch": 0.38304943913585376,
      "grad_norm": 0.40019750595092773,
      "learning_rate": 1e-05,
      "loss": 0.4243,
      "step": 922
    },
    {
      "epoch": 0.3838803489821354,
      "grad_norm": 0.36779364943504333,
      "learning_rate": 1e-05,
      "loss": 0.4454,
      "step": 924
    },
    {
      "epoch": 0.3847112588284171,
      "grad_norm": 0.3685802221298218,
      "learning_rate": 1e-05,
      "loss": 0.415,
      "step": 926
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 0.41098788380622864,
      "learning_rate": 1e-05,
      "loss": 0.4382,
      "step": 928
    },
    {
      "epoch": 0.38637307852098046,
      "grad_norm": 0.3926888704299927,
      "learning_rate": 1e-05,
      "loss": 0.4375,
      "step": 930
    },
    {
      "epoch": 0.38720398836726216,
      "grad_norm": 0.3783082664012909,
      "learning_rate": 1e-05,
      "loss": 0.4349,
      "step": 932
    },
    {
      "epoch": 0.3880348982135438,
      "grad_norm": 0.37253594398498535,
      "learning_rate": 1e-05,
      "loss": 0.4334,
      "step": 934
    },
    {
      "epoch": 0.3888658080598255,
      "grad_norm": 0.382032573223114,
      "learning_rate": 1e-05,
      "loss": 0.4149,
      "step": 936
    },
    {
      "epoch": 0.3896967179061072,
      "grad_norm": 0.38657715916633606,
      "learning_rate": 1e-05,
      "loss": 0.4344,
      "step": 938
    },
    {
      "epoch": 0.39052762775238886,
      "grad_norm": 0.3829430341720581,
      "learning_rate": 1e-05,
      "loss": 0.4422,
      "step": 940
    },
    {
      "epoch": 0.39135853759867056,
      "grad_norm": 0.37411829829216003,
      "learning_rate": 1e-05,
      "loss": 0.4269,
      "step": 942
    },
    {
      "epoch": 0.3921894474449522,
      "grad_norm": 0.41974636912345886,
      "learning_rate": 1e-05,
      "loss": 0.4189,
      "step": 944
    },
    {
      "epoch": 0.3930203572912339,
      "grad_norm": 0.37492895126342773,
      "learning_rate": 1e-05,
      "loss": 0.4334,
      "step": 946
    },
    {
      "epoch": 0.39385126713751556,
      "grad_norm": 0.3813185393810272,
      "learning_rate": 1e-05,
      "loss": 0.4168,
      "step": 948
    },
    {
      "epoch": 0.39468217698379726,
      "grad_norm": 0.38931363821029663,
      "learning_rate": 1e-05,
      "loss": 0.436,
      "step": 950
    },
    {
      "epoch": 0.39551308683007896,
      "grad_norm": 0.3777899146080017,
      "learning_rate": 1e-05,
      "loss": 0.437,
      "step": 952
    },
    {
      "epoch": 0.3963439966763606,
      "grad_norm": 0.3865474462509155,
      "learning_rate": 1e-05,
      "loss": 0.4211,
      "step": 954
    },
    {
      "epoch": 0.3971749065226423,
      "grad_norm": 0.3829583525657654,
      "learning_rate": 1e-05,
      "loss": 0.4132,
      "step": 956
    },
    {
      "epoch": 0.39800581636892396,
      "grad_norm": 0.35884889960289,
      "learning_rate": 1e-05,
      "loss": 0.4266,
      "step": 958
    },
    {
      "epoch": 0.39883672621520566,
      "grad_norm": 0.3922320306301117,
      "learning_rate": 1e-05,
      "loss": 0.4207,
      "step": 960
    },
    {
      "epoch": 0.3996676360614873,
      "grad_norm": 0.3669825792312622,
      "learning_rate": 1e-05,
      "loss": 0.4311,
      "step": 962
    },
    {
      "epoch": 0.400498545907769,
      "grad_norm": 0.3928632438182831,
      "learning_rate": 1e-05,
      "loss": 0.4166,
      "step": 964
    },
    {
      "epoch": 0.4013294557540507,
      "grad_norm": 0.35970818996429443,
      "learning_rate": 1e-05,
      "loss": 0.4272,
      "step": 966
    },
    {
      "epoch": 0.40216036560033236,
      "grad_norm": 0.3881351947784424,
      "learning_rate": 1e-05,
      "loss": 0.4493,
      "step": 968
    },
    {
      "epoch": 0.40299127544661406,
      "grad_norm": 0.3936481475830078,
      "learning_rate": 1e-05,
      "loss": 0.4462,
      "step": 970
    },
    {
      "epoch": 0.4038221852928957,
      "grad_norm": 0.3670540153980255,
      "learning_rate": 1e-05,
      "loss": 0.4281,
      "step": 972
    },
    {
      "epoch": 0.4046530951391774,
      "grad_norm": 0.35581815242767334,
      "learning_rate": 1e-05,
      "loss": 0.4262,
      "step": 974
    },
    {
      "epoch": 0.40548400498545906,
      "grad_norm": 0.38287052512168884,
      "learning_rate": 1e-05,
      "loss": 0.4333,
      "step": 976
    },
    {
      "epoch": 0.40631491483174076,
      "grad_norm": 0.37307021021842957,
      "learning_rate": 1e-05,
      "loss": 0.4261,
      "step": 978
    },
    {
      "epoch": 0.40714582467802246,
      "grad_norm": 0.34996283054351807,
      "learning_rate": 1e-05,
      "loss": 0.4263,
      "step": 980
    },
    {
      "epoch": 0.4079767345243041,
      "grad_norm": 0.36345019936561584,
      "learning_rate": 1e-05,
      "loss": 0.4331,
      "step": 982
    },
    {
      "epoch": 0.4088076443705858,
      "grad_norm": 0.371852308511734,
      "learning_rate": 1e-05,
      "loss": 0.4359,
      "step": 984
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 0.38082149624824524,
      "learning_rate": 1e-05,
      "loss": 0.421,
      "step": 986
    },
    {
      "epoch": 0.41046946406314916,
      "grad_norm": 0.38683319091796875,
      "learning_rate": 1e-05,
      "loss": 0.4241,
      "step": 988
    },
    {
      "epoch": 0.4113003739094308,
      "grad_norm": 0.362937331199646,
      "learning_rate": 1e-05,
      "loss": 0.4362,
      "step": 990
    },
    {
      "epoch": 0.4121312837557125,
      "grad_norm": 0.39014407992362976,
      "learning_rate": 1e-05,
      "loss": 0.4098,
      "step": 992
    },
    {
      "epoch": 0.4129621936019942,
      "grad_norm": 0.3858861029148102,
      "learning_rate": 1e-05,
      "loss": 0.4365,
      "step": 994
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.38172727823257446,
      "learning_rate": 1e-05,
      "loss": 0.4477,
      "step": 996
    },
    {
      "epoch": 0.41462401329455756,
      "grad_norm": 0.3850913345813751,
      "learning_rate": 1e-05,
      "loss": 0.4476,
      "step": 998
    },
    {
      "epoch": 0.4154549231408392,
      "grad_norm": 0.3631599545478821,
      "learning_rate": 1e-05,
      "loss": 0.417,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_alpaca_gpt4_zh.json_loss": 1.3685559034347534,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4643,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 447.304,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 19.121,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_ultrainteract_sft.json_loss": 0.4538356363773346,
      "eval_ultrainteract_sft.json_runtime": 17.9903,
      "eval_ultrainteract_sft.json_samples_per_second": 159.531,
      "eval_ultrainteract_sft.json_steps_per_second": 6.67,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_code_feedback_multi_turn.json_loss": 0.5684928297996521,
      "eval_code_feedback_multi_turn.json_runtime": 16.0813,
      "eval_code_feedback_multi_turn.json_samples_per_second": 63.179,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.674,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_tested_143k_python_alpaca.json_loss": 0.3542466163635254,
      "eval_tested_143k_python_alpaca.json_runtime": 14.3762,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 161.239,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.747,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_synthetic_text_to_sql.json_loss": 0.17230819165706635,
      "eval_synthetic_text_to_sql.json_runtime": 3.3251,
      "eval_synthetic_text_to_sql.json_samples_per_second": 419.536,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.744,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_codefeedback_filtered_instruction.json_loss": 0.4017263650894165,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0312,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 174.655,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.277,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_train_data_for_qwen.json_loss": 0.014937681145966053,
      "eval_train_data_for_qwen.json_runtime": 3.656,
      "eval_train_data_for_qwen.json_samples_per_second": 120.35,
      "eval_train_data_for_qwen.json_steps_per_second": 5.197,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4362821578979492,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8914,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 393.898,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.919,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_all_merge_code.json_loss": 0.23438894748687744,
      "eval_all_merge_code.json_runtime": 16.8063,
      "eval_all_merge_code.json_samples_per_second": 205.995,
      "eval_all_merge_code.json_steps_per_second": 8.628,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_xlam_function_calling_60k.json_loss": 0.01940287835896015,
      "eval_xlam_function_calling_60k.json_runtime": 4.4315,
      "eval_xlam_function_calling_60k.json_samples_per_second": 200.158,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.349,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_table_python_code_datas.json_loss": 0.15819525718688965,
      "eval_table_python_code_datas.json_runtime": 65.6255,
      "eval_table_python_code_datas.json_samples_per_second": 71.07,
      "eval_table_python_code_datas.json_steps_per_second": 2.971,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_Table_GPT.json_loss": 0.06377816945314407,
      "eval_Table_GPT.json_runtime": 10.5811,
      "eval_Table_GPT.json_samples_per_second": 83.829,
      "eval_Table_GPT.json_steps_per_second": 3.497,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_tabular_llm_data.json_loss": 0.11119720339775085,
      "eval_tabular_llm_data.json_runtime": 50.356,
      "eval_tabular_llm_data.json_samples_per_second": 58.186,
      "eval_tabular_llm_data.json_steps_per_second": 2.443,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_gpt_4o_200k.json_loss": 0.8512440919876099,
      "eval_gpt_4o_200k.json_runtime": 27.3216,
      "eval_gpt_4o_200k.json_samples_per_second": 130.702,
      "eval_gpt_4o_200k.json_steps_per_second": 5.454,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_MathInstruct.json_loss": 0.1773221641778946,
      "eval_MathInstruct.json_runtime": 12.9473,
      "eval_MathInstruct.json_samples_per_second": 252.949,
      "eval_MathInstruct.json_steps_per_second": 10.581,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_alpaca_cleaned.json_loss": 0.9382585287094116,
      "eval_alpaca_cleaned.json_runtime": 2.375,
      "eval_alpaca_cleaned.json_samples_per_second": 374.739,
      "eval_alpaca_cleaned.json_steps_per_second": 16.0,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_multi_turn_datas_0816.json_loss": 0.31267547607421875,
      "eval_multi_turn_datas_0816.json_runtime": 71.4265,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.262,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.394,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_sharegpt_gpt4.json_loss": 0.7530646920204163,
      "eval_sharegpt_gpt4.json_runtime": 21.7922,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.675,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.799,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_python_code_critic_21k.json_loss": 0.6326174736022949,
      "eval_python_code_critic_21k.json_runtime": 1.955,
      "eval_python_code_critic_21k.json_samples_per_second": 147.826,
      "eval_python_code_critic_21k.json_steps_per_second": 6.65,
      "step": 1000
    },
    {
      "epoch": 0.4154549231408392,
      "eval_agent_instruct.json_loss": 0.21303440630435944,
      "eval_agent_instruct.json_runtime": 0.2439,
      "eval_agent_instruct.json_samples_per_second": 90.193,
      "eval_agent_instruct.json_steps_per_second": 4.1,
      "step": 1000
    },
    {
      "epoch": 0.4162858329871209,
      "grad_norm": 0.3551112413406372,
      "learning_rate": 1e-05,
      "loss": 0.4179,
      "step": 1002
    },
    {
      "epoch": 0.41711674283340255,
      "grad_norm": 0.3792528510093689,
      "learning_rate": 1e-05,
      "loss": 0.4165,
      "step": 1004
    },
    {
      "epoch": 0.41794765267968426,
      "grad_norm": 0.35975953936576843,
      "learning_rate": 1e-05,
      "loss": 0.416,
      "step": 1006
    },
    {
      "epoch": 0.41877856252596596,
      "grad_norm": 0.38774240016937256,
      "learning_rate": 1e-05,
      "loss": 0.4257,
      "step": 1008
    },
    {
      "epoch": 0.4196094723722476,
      "grad_norm": 0.3491792380809784,
      "learning_rate": 1e-05,
      "loss": 0.4144,
      "step": 1010
    },
    {
      "epoch": 0.4204403822185293,
      "grad_norm": 0.3818664252758026,
      "learning_rate": 1e-05,
      "loss": 0.4269,
      "step": 1012
    },
    {
      "epoch": 0.42127129206481095,
      "grad_norm": 0.37957119941711426,
      "learning_rate": 1e-05,
      "loss": 0.433,
      "step": 1014
    },
    {
      "epoch": 0.42210220191109266,
      "grad_norm": 0.37515321373939514,
      "learning_rate": 1e-05,
      "loss": 0.4254,
      "step": 1016
    },
    {
      "epoch": 0.4229331117573743,
      "grad_norm": 0.36205533146858215,
      "learning_rate": 1e-05,
      "loss": 0.4208,
      "step": 1018
    },
    {
      "epoch": 0.423764021603656,
      "grad_norm": 0.3704536557197571,
      "learning_rate": 1e-05,
      "loss": 0.4363,
      "step": 1020
    },
    {
      "epoch": 0.4245949314499377,
      "grad_norm": 0.3584047853946686,
      "learning_rate": 1e-05,
      "loss": 0.4384,
      "step": 1022
    },
    {
      "epoch": 0.42542584129621935,
      "grad_norm": 0.4073798954486847,
      "learning_rate": 1e-05,
      "loss": 0.4315,
      "step": 1024
    },
    {
      "epoch": 0.42625675114250106,
      "grad_norm": 0.36557894945144653,
      "learning_rate": 1e-05,
      "loss": 0.416,
      "step": 1026
    },
    {
      "epoch": 0.4270876609887827,
      "grad_norm": 0.37782570719718933,
      "learning_rate": 1e-05,
      "loss": 0.4272,
      "step": 1028
    },
    {
      "epoch": 0.4279185708350644,
      "grad_norm": 0.3667062222957611,
      "learning_rate": 1e-05,
      "loss": 0.4177,
      "step": 1030
    },
    {
      "epoch": 0.42874948068134605,
      "grad_norm": 0.38035523891448975,
      "learning_rate": 1e-05,
      "loss": 0.4305,
      "step": 1032
    },
    {
      "epoch": 0.42958039052762775,
      "grad_norm": 0.3538805842399597,
      "learning_rate": 1e-05,
      "loss": 0.4138,
      "step": 1034
    },
    {
      "epoch": 0.43041130037390946,
      "grad_norm": 0.3610248565673828,
      "learning_rate": 1e-05,
      "loss": 0.4188,
      "step": 1036
    },
    {
      "epoch": 0.4312422102201911,
      "grad_norm": 0.37049630284309387,
      "learning_rate": 1e-05,
      "loss": 0.4339,
      "step": 1038
    },
    {
      "epoch": 0.4320731200664728,
      "grad_norm": 0.3864262104034424,
      "learning_rate": 1e-05,
      "loss": 0.4352,
      "step": 1040
    },
    {
      "epoch": 0.43290402991275445,
      "grad_norm": 0.37603050470352173,
      "learning_rate": 1e-05,
      "loss": 0.4429,
      "step": 1042
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 0.39905837178230286,
      "learning_rate": 1e-05,
      "loss": 0.4219,
      "step": 1044
    },
    {
      "epoch": 0.4345658496053178,
      "grad_norm": 0.37017321586608887,
      "learning_rate": 1e-05,
      "loss": 0.4325,
      "step": 1046
    },
    {
      "epoch": 0.4353967594515995,
      "grad_norm": 0.3921617269515991,
      "learning_rate": 1e-05,
      "loss": 0.4169,
      "step": 1048
    },
    {
      "epoch": 0.4362276692978812,
      "grad_norm": 0.37648695707321167,
      "learning_rate": 1e-05,
      "loss": 0.44,
      "step": 1050
    },
    {
      "epoch": 0.43705857914416285,
      "grad_norm": 0.38411736488342285,
      "learning_rate": 1e-05,
      "loss": 0.4179,
      "step": 1052
    },
    {
      "epoch": 0.43788948899044455,
      "grad_norm": 0.37911128997802734,
      "learning_rate": 1e-05,
      "loss": 0.4325,
      "step": 1054
    },
    {
      "epoch": 0.4387203988367262,
      "grad_norm": 0.3869103491306305,
      "learning_rate": 1e-05,
      "loss": 0.4173,
      "step": 1056
    },
    {
      "epoch": 0.4395513086830079,
      "grad_norm": 0.3864297568798065,
      "learning_rate": 1e-05,
      "loss": 0.4201,
      "step": 1058
    },
    {
      "epoch": 0.44038221852928955,
      "grad_norm": 0.39165177941322327,
      "learning_rate": 1e-05,
      "loss": 0.4283,
      "step": 1060
    },
    {
      "epoch": 0.44121312837557125,
      "grad_norm": 0.4110879600048065,
      "learning_rate": 1e-05,
      "loss": 0.4306,
      "step": 1062
    },
    {
      "epoch": 0.44204403822185295,
      "grad_norm": 0.37222233414649963,
      "learning_rate": 1e-05,
      "loss": 0.4125,
      "step": 1064
    },
    {
      "epoch": 0.4428749480681346,
      "grad_norm": 0.3840391933917999,
      "learning_rate": 1e-05,
      "loss": 0.4271,
      "step": 1066
    },
    {
      "epoch": 0.4437058579144163,
      "grad_norm": 0.4024052321910858,
      "learning_rate": 1e-05,
      "loss": 0.4099,
      "step": 1068
    },
    {
      "epoch": 0.44453676776069795,
      "grad_norm": 0.3721942901611328,
      "learning_rate": 1e-05,
      "loss": 0.4276,
      "step": 1070
    },
    {
      "epoch": 0.44536767760697965,
      "grad_norm": 0.3877382278442383,
      "learning_rate": 1e-05,
      "loss": 0.4357,
      "step": 1072
    },
    {
      "epoch": 0.4461985874532613,
      "grad_norm": 0.3778764009475708,
      "learning_rate": 1e-05,
      "loss": 0.4205,
      "step": 1074
    },
    {
      "epoch": 0.447029497299543,
      "grad_norm": 0.3652397096157074,
      "learning_rate": 1e-05,
      "loss": 0.415,
      "step": 1076
    },
    {
      "epoch": 0.4478604071458247,
      "grad_norm": 0.3744623363018036,
      "learning_rate": 1e-05,
      "loss": 0.4287,
      "step": 1078
    },
    {
      "epoch": 0.44869131699210635,
      "grad_norm": 0.36236804723739624,
      "learning_rate": 1e-05,
      "loss": 0.4007,
      "step": 1080
    },
    {
      "epoch": 0.44952222683838805,
      "grad_norm": 0.38786476850509644,
      "learning_rate": 1e-05,
      "loss": 0.4316,
      "step": 1082
    },
    {
      "epoch": 0.4503531366846697,
      "grad_norm": 0.3761746287345886,
      "learning_rate": 1e-05,
      "loss": 0.4252,
      "step": 1084
    },
    {
      "epoch": 0.4511840465309514,
      "grad_norm": 0.3984936773777008,
      "learning_rate": 1e-05,
      "loss": 0.4214,
      "step": 1086
    },
    {
      "epoch": 0.45201495637723305,
      "grad_norm": 0.3804509937763214,
      "learning_rate": 1e-05,
      "loss": 0.4287,
      "step": 1088
    },
    {
      "epoch": 0.45284586622351475,
      "grad_norm": 0.37328359484672546,
      "learning_rate": 1e-05,
      "loss": 0.4133,
      "step": 1090
    },
    {
      "epoch": 0.45367677606979645,
      "grad_norm": 0.3866887092590332,
      "learning_rate": 1e-05,
      "loss": 0.4171,
      "step": 1092
    },
    {
      "epoch": 0.4545076859160781,
      "grad_norm": 0.38746926188468933,
      "learning_rate": 1e-05,
      "loss": 0.3957,
      "step": 1094
    },
    {
      "epoch": 0.4553385957623598,
      "grad_norm": 0.3874302804470062,
      "learning_rate": 1e-05,
      "loss": 0.4282,
      "step": 1096
    },
    {
      "epoch": 0.45616950560864145,
      "grad_norm": 0.363804429769516,
      "learning_rate": 1e-05,
      "loss": 0.408,
      "step": 1098
    },
    {
      "epoch": 0.45700041545492315,
      "grad_norm": 0.37992849946022034,
      "learning_rate": 1e-05,
      "loss": 0.4283,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_alpaca_gpt4_zh.json_loss": 1.371953010559082,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4753,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 443.986,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.98,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_ultrainteract_sft.json_loss": 0.4521130323410034,
      "eval_ultrainteract_sft.json_runtime": 18.0315,
      "eval_ultrainteract_sft.json_samples_per_second": 159.166,
      "eval_ultrainteract_sft.json_steps_per_second": 6.655,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_code_feedback_multi_turn.json_loss": 0.56526780128479,
      "eval_code_feedback_multi_turn.json_runtime": 15.4206,
      "eval_code_feedback_multi_turn.json_samples_per_second": 65.886,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.788,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_tested_143k_python_alpaca.json_loss": 0.35170286893844604,
      "eval_tested_143k_python_alpaca.json_runtime": 14.0891,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.525,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.885,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_synthetic_text_to_sql.json_loss": 0.16954708099365234,
      "eval_synthetic_text_to_sql.json_runtime": 3.3303,
      "eval_synthetic_text_to_sql.json_samples_per_second": 418.884,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.716,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_codefeedback_filtered_instruction.json_loss": 0.3989376723766327,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0182,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 174.882,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.287,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_train_data_for_qwen.json_loss": 0.015250733122229576,
      "eval_train_data_for_qwen.json_runtime": 3.6743,
      "eval_train_data_for_qwen.json_samples_per_second": 119.749,
      "eval_train_data_for_qwen.json_steps_per_second": 5.171,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.430275321006775,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.883,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 395.645,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.994,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_all_merge_code.json_loss": 0.23072893917560577,
      "eval_all_merge_code.json_runtime": 16.8239,
      "eval_all_merge_code.json_samples_per_second": 205.779,
      "eval_all_merge_code.json_steps_per_second": 8.619,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_xlam_function_calling_60k.json_loss": 0.019868385046720505,
      "eval_xlam_function_calling_60k.json_runtime": 4.4183,
      "eval_xlam_function_calling_60k.json_samples_per_second": 200.758,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.374,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_table_python_code_datas.json_loss": 0.15623697638511658,
      "eval_table_python_code_datas.json_runtime": 66.1059,
      "eval_table_python_code_datas.json_samples_per_second": 70.553,
      "eval_table_python_code_datas.json_steps_per_second": 2.95,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_Table_GPT.json_loss": 0.06546618789434433,
      "eval_Table_GPT.json_runtime": 10.5934,
      "eval_Table_GPT.json_samples_per_second": 83.731,
      "eval_Table_GPT.json_steps_per_second": 3.493,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_tabular_llm_data.json_loss": 0.10864464938640594,
      "eval_tabular_llm_data.json_runtime": 50.8414,
      "eval_tabular_llm_data.json_samples_per_second": 57.63,
      "eval_tabular_llm_data.json_steps_per_second": 2.419,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_gpt_4o_200k.json_loss": 0.8503633141517639,
      "eval_gpt_4o_200k.json_runtime": 27.2146,
      "eval_gpt_4o_200k.json_samples_per_second": 131.216,
      "eval_gpt_4o_200k.json_steps_per_second": 5.475,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_MathInstruct.json_loss": 0.1760071963071823,
      "eval_MathInstruct.json_runtime": 13.0362,
      "eval_MathInstruct.json_samples_per_second": 251.224,
      "eval_MathInstruct.json_steps_per_second": 10.509,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_alpaca_cleaned.json_loss": 0.9372878670692444,
      "eval_alpaca_cleaned.json_runtime": 2.4223,
      "eval_alpaca_cleaned.json_samples_per_second": 367.418,
      "eval_alpaca_cleaned.json_steps_per_second": 15.687,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_multi_turn_datas_0816.json_loss": 0.30792951583862305,
      "eval_multi_turn_datas_0816.json_runtime": 71.3746,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.303,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.396,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_sharegpt_gpt4.json_loss": 0.7498281598091125,
      "eval_sharegpt_gpt4.json_runtime": 21.8849,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.393,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.787,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_python_code_critic_21k.json_loss": 0.6323665976524353,
      "eval_python_code_critic_21k.json_runtime": 1.9498,
      "eval_python_code_critic_21k.json_samples_per_second": 148.224,
      "eval_python_code_critic_21k.json_steps_per_second": 6.668,
      "step": 1100
    },
    {
      "epoch": 0.45700041545492315,
      "eval_agent_instruct.json_loss": 0.20739014446735382,
      "eval_agent_instruct.json_runtime": 0.2487,
      "eval_agent_instruct.json_samples_per_second": 88.452,
      "eval_agent_instruct.json_steps_per_second": 4.021,
      "step": 1100
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 0.37726396322250366,
      "learning_rate": 1e-05,
      "loss": 0.409,
      "step": 1102
    },
    {
      "epoch": 0.4586622351474865,
      "grad_norm": 0.3658864200115204,
      "learning_rate": 1e-05,
      "loss": 0.4123,
      "step": 1104
    },
    {
      "epoch": 0.4594931449937682,
      "grad_norm": 0.39758431911468506,
      "learning_rate": 1e-05,
      "loss": 0.4432,
      "step": 1106
    },
    {
      "epoch": 0.46032405484004985,
      "grad_norm": 0.3932802677154541,
      "learning_rate": 1e-05,
      "loss": 0.4316,
      "step": 1108
    },
    {
      "epoch": 0.46115496468633155,
      "grad_norm": 0.379184752702713,
      "learning_rate": 1e-05,
      "loss": 0.419,
      "step": 1110
    },
    {
      "epoch": 0.4619858745326132,
      "grad_norm": 0.39145198464393616,
      "learning_rate": 1e-05,
      "loss": 0.4202,
      "step": 1112
    },
    {
      "epoch": 0.4628167843788949,
      "grad_norm": 0.3771417438983917,
      "learning_rate": 1e-05,
      "loss": 0.4302,
      "step": 1114
    },
    {
      "epoch": 0.46364769422517654,
      "grad_norm": 0.37379202246665955,
      "learning_rate": 1e-05,
      "loss": 0.4132,
      "step": 1116
    },
    {
      "epoch": 0.46447860407145825,
      "grad_norm": 0.38667505979537964,
      "learning_rate": 1e-05,
      "loss": 0.4057,
      "step": 1118
    },
    {
      "epoch": 0.46530951391773995,
      "grad_norm": 0.37206387519836426,
      "learning_rate": 1e-05,
      "loss": 0.4129,
      "step": 1120
    },
    {
      "epoch": 0.4661404237640216,
      "grad_norm": 0.3933306634426117,
      "learning_rate": 1e-05,
      "loss": 0.4288,
      "step": 1122
    },
    {
      "epoch": 0.4669713336103033,
      "grad_norm": 0.3680415153503418,
      "learning_rate": 1e-05,
      "loss": 0.4155,
      "step": 1124
    },
    {
      "epoch": 0.46780224345658494,
      "grad_norm": 0.3957715630531311,
      "learning_rate": 1e-05,
      "loss": 0.4251,
      "step": 1126
    },
    {
      "epoch": 0.46863315330286665,
      "grad_norm": 0.39224594831466675,
      "learning_rate": 1e-05,
      "loss": 0.4224,
      "step": 1128
    },
    {
      "epoch": 0.4694640631491483,
      "grad_norm": 0.3940064311027527,
      "learning_rate": 1e-05,
      "loss": 0.4184,
      "step": 1130
    },
    {
      "epoch": 0.47029497299543,
      "grad_norm": 0.39272743463516235,
      "learning_rate": 1e-05,
      "loss": 0.4412,
      "step": 1132
    },
    {
      "epoch": 0.4711258828417117,
      "grad_norm": 0.4028641879558563,
      "learning_rate": 1e-05,
      "loss": 0.4277,
      "step": 1134
    },
    {
      "epoch": 0.47195679268799334,
      "grad_norm": 0.3683210611343384,
      "learning_rate": 1e-05,
      "loss": 0.4228,
      "step": 1136
    },
    {
      "epoch": 0.47278770253427504,
      "grad_norm": 0.38239017128944397,
      "learning_rate": 1e-05,
      "loss": 0.4276,
      "step": 1138
    },
    {
      "epoch": 0.4736186123805567,
      "grad_norm": 0.3766772449016571,
      "learning_rate": 1e-05,
      "loss": 0.4209,
      "step": 1140
    },
    {
      "epoch": 0.4744495222268384,
      "grad_norm": 0.395188570022583,
      "learning_rate": 1e-05,
      "loss": 0.4405,
      "step": 1142
    },
    {
      "epoch": 0.47528043207312004,
      "grad_norm": 0.3808802664279938,
      "learning_rate": 1e-05,
      "loss": 0.4141,
      "step": 1144
    },
    {
      "epoch": 0.47611134191940174,
      "grad_norm": 0.3928436040878296,
      "learning_rate": 1e-05,
      "loss": 0.423,
      "step": 1146
    },
    {
      "epoch": 0.47694225176568344,
      "grad_norm": 0.38921499252319336,
      "learning_rate": 1e-05,
      "loss": 0.4154,
      "step": 1148
    },
    {
      "epoch": 0.4777731616119651,
      "grad_norm": 0.3568366765975952,
      "learning_rate": 1e-05,
      "loss": 0.407,
      "step": 1150
    },
    {
      "epoch": 0.4786040714582468,
      "grad_norm": 0.3909783363342285,
      "learning_rate": 1e-05,
      "loss": 0.4253,
      "step": 1152
    },
    {
      "epoch": 0.47943498130452844,
      "grad_norm": 0.37712931632995605,
      "learning_rate": 1e-05,
      "loss": 0.4206,
      "step": 1154
    },
    {
      "epoch": 0.48026589115081014,
      "grad_norm": 0.36154189705848694,
      "learning_rate": 1e-05,
      "loss": 0.4344,
      "step": 1156
    },
    {
      "epoch": 0.4810968009970918,
      "grad_norm": 0.3764767646789551,
      "learning_rate": 1e-05,
      "loss": 0.4304,
      "step": 1158
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 0.37971052527427673,
      "learning_rate": 1e-05,
      "loss": 0.412,
      "step": 1160
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 0.39215683937072754,
      "learning_rate": 1e-05,
      "loss": 0.4207,
      "step": 1162
    },
    {
      "epoch": 0.48358953053593684,
      "grad_norm": 0.36686280369758606,
      "learning_rate": 1e-05,
      "loss": 0.4157,
      "step": 1164
    },
    {
      "epoch": 0.48442044038221854,
      "grad_norm": 0.3716476261615753,
      "learning_rate": 1e-05,
      "loss": 0.4155,
      "step": 1166
    },
    {
      "epoch": 0.4852513502285002,
      "grad_norm": 0.38088127970695496,
      "learning_rate": 1e-05,
      "loss": 0.4061,
      "step": 1168
    },
    {
      "epoch": 0.4860822600747819,
      "grad_norm": 0.38457104563713074,
      "learning_rate": 1e-05,
      "loss": 0.4228,
      "step": 1170
    },
    {
      "epoch": 0.48691316992106354,
      "grad_norm": 0.3749920427799225,
      "learning_rate": 1e-05,
      "loss": 0.4213,
      "step": 1172
    },
    {
      "epoch": 0.48774407976734524,
      "grad_norm": 0.37584760785102844,
      "learning_rate": 1e-05,
      "loss": 0.4012,
      "step": 1174
    },
    {
      "epoch": 0.48857498961362694,
      "grad_norm": 0.38475149869918823,
      "learning_rate": 1e-05,
      "loss": 0.4273,
      "step": 1176
    },
    {
      "epoch": 0.4894058994599086,
      "grad_norm": 0.3688208758831024,
      "learning_rate": 1e-05,
      "loss": 0.4021,
      "step": 1178
    },
    {
      "epoch": 0.4902368093061903,
      "grad_norm": 0.3625032901763916,
      "learning_rate": 1e-05,
      "loss": 0.4265,
      "step": 1180
    },
    {
      "epoch": 0.49106771915247194,
      "grad_norm": 0.3861531615257263,
      "learning_rate": 1e-05,
      "loss": 0.42,
      "step": 1182
    },
    {
      "epoch": 0.49189862899875364,
      "grad_norm": 0.371694952249527,
      "learning_rate": 1e-05,
      "loss": 0.4182,
      "step": 1184
    },
    {
      "epoch": 0.4927295388450353,
      "grad_norm": 0.3660416305065155,
      "learning_rate": 1e-05,
      "loss": 0.4235,
      "step": 1186
    },
    {
      "epoch": 0.493560448691317,
      "grad_norm": 0.40820443630218506,
      "learning_rate": 1e-05,
      "loss": 0.4405,
      "step": 1188
    },
    {
      "epoch": 0.4943913585375987,
      "grad_norm": 0.36377257108688354,
      "learning_rate": 1e-05,
      "loss": 0.4257,
      "step": 1190
    },
    {
      "epoch": 0.49522226838388034,
      "grad_norm": 0.376449316740036,
      "learning_rate": 1e-05,
      "loss": 0.4212,
      "step": 1192
    },
    {
      "epoch": 0.49605317823016204,
      "grad_norm": 0.39757606387138367,
      "learning_rate": 1e-05,
      "loss": 0.4212,
      "step": 1194
    },
    {
      "epoch": 0.4968840880764437,
      "grad_norm": 0.3895131051540375,
      "learning_rate": 1e-05,
      "loss": 0.4202,
      "step": 1196
    },
    {
      "epoch": 0.4977149979227254,
      "grad_norm": 0.3953578770160675,
      "learning_rate": 1e-05,
      "loss": 0.4153,
      "step": 1198
    },
    {
      "epoch": 0.49854590776900704,
      "grad_norm": 0.3758751153945923,
      "learning_rate": 1e-05,
      "loss": 0.4098,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_alpaca_gpt4_zh.json_loss": 1.3757191896438599,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4781,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 443.139,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.943,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_ultrainteract_sft.json_loss": 0.4499751627445221,
      "eval_ultrainteract_sft.json_runtime": 17.9999,
      "eval_ultrainteract_sft.json_samples_per_second": 159.446,
      "eval_ultrainteract_sft.json_steps_per_second": 6.667,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_code_feedback_multi_turn.json_loss": 0.5648687481880188,
      "eval_code_feedback_multi_turn.json_runtime": 15.7348,
      "eval_code_feedback_multi_turn.json_samples_per_second": 64.57,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.733,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_tested_143k_python_alpaca.json_loss": 0.3497188687324524,
      "eval_tested_143k_python_alpaca.json_runtime": 14.106,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.327,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.877,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_synthetic_text_to_sql.json_loss": 0.1695891171693802,
      "eval_synthetic_text_to_sql.json_runtime": 3.3288,
      "eval_synthetic_text_to_sql.json_samples_per_second": 419.065,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.724,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_codefeedback_filtered_instruction.json_loss": 0.39545127749443054,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0206,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 174.84,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.285,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_train_data_for_qwen.json_loss": 0.01349810790270567,
      "eval_train_data_for_qwen.json_runtime": 3.6494,
      "eval_train_data_for_qwen.json_samples_per_second": 120.566,
      "eval_train_data_for_qwen.json_steps_per_second": 5.206,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.426719069480896,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8907,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 394.035,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.925,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_all_merge_code.json_loss": 0.2282778024673462,
      "eval_all_merge_code.json_runtime": 16.7824,
      "eval_all_merge_code.json_samples_per_second": 206.287,
      "eval_all_merge_code.json_steps_per_second": 8.64,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_xlam_function_calling_60k.json_loss": 0.019282003864645958,
      "eval_xlam_function_calling_60k.json_runtime": 4.4353,
      "eval_xlam_function_calling_60k.json_samples_per_second": 199.985,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.342,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_table_python_code_datas.json_loss": 0.1555047184228897,
      "eval_table_python_code_datas.json_runtime": 66.2019,
      "eval_table_python_code_datas.json_samples_per_second": 70.451,
      "eval_table_python_code_datas.json_steps_per_second": 2.946,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_Table_GPT.json_loss": 0.059843726456165314,
      "eval_Table_GPT.json_runtime": 10.5731,
      "eval_Table_GPT.json_samples_per_second": 83.892,
      "eval_Table_GPT.json_steps_per_second": 3.499,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_tabular_llm_data.json_loss": 0.10740937292575836,
      "eval_tabular_llm_data.json_runtime": 50.7051,
      "eval_tabular_llm_data.json_samples_per_second": 57.785,
      "eval_tabular_llm_data.json_steps_per_second": 2.426,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_gpt_4o_200k.json_loss": 0.849137008190155,
      "eval_gpt_4o_200k.json_runtime": 27.2208,
      "eval_gpt_4o_200k.json_samples_per_second": 131.187,
      "eval_gpt_4o_200k.json_steps_per_second": 5.474,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_MathInstruct.json_loss": 0.17629596590995789,
      "eval_MathInstruct.json_runtime": 13.044,
      "eval_MathInstruct.json_samples_per_second": 251.073,
      "eval_MathInstruct.json_steps_per_second": 10.503,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_alpaca_cleaned.json_loss": 0.936781644821167,
      "eval_alpaca_cleaned.json_runtime": 2.3743,
      "eval_alpaca_cleaned.json_samples_per_second": 374.846,
      "eval_alpaca_cleaned.json_steps_per_second": 16.005,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_multi_turn_datas_0816.json_loss": 0.3043861985206604,
      "eval_multi_turn_datas_0816.json_runtime": 71.295,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.367,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.398,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_sharegpt_gpt4.json_loss": 0.7467411160469055,
      "eval_sharegpt_gpt4.json_runtime": 21.6769,
      "eval_sharegpt_gpt4.json_samples_per_second": 67.03,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.814,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_python_code_critic_21k.json_loss": 0.6285628080368042,
      "eval_python_code_critic_21k.json_runtime": 1.9469,
      "eval_python_code_critic_21k.json_samples_per_second": 148.442,
      "eval_python_code_critic_21k.json_steps_per_second": 6.677,
      "step": 1200
    },
    {
      "epoch": 0.49854590776900704,
      "eval_agent_instruct.json_loss": 0.20790953934192657,
      "eval_agent_instruct.json_runtime": 0.2442,
      "eval_agent_instruct.json_samples_per_second": 90.102,
      "eval_agent_instruct.json_steps_per_second": 4.096,
      "step": 1200
    },
    {
      "epoch": 0.49937681761528874,
      "grad_norm": 0.3755420446395874,
      "learning_rate": 1e-05,
      "loss": 0.4147,
      "step": 1202
    },
    {
      "epoch": 0.5002077274615704,
      "grad_norm": 0.38185104727745056,
      "learning_rate": 1e-05,
      "loss": 0.4131,
      "step": 1204
    },
    {
      "epoch": 0.5010386373078521,
      "grad_norm": 0.37501153349876404,
      "learning_rate": 1e-05,
      "loss": 0.4145,
      "step": 1206
    },
    {
      "epoch": 0.5018695471541338,
      "grad_norm": 0.3818304240703583,
      "learning_rate": 1e-05,
      "loss": 0.414,
      "step": 1208
    },
    {
      "epoch": 0.5027004570004154,
      "grad_norm": 0.4040709435939789,
      "learning_rate": 1e-05,
      "loss": 0.4163,
      "step": 1210
    },
    {
      "epoch": 0.5035313668466971,
      "grad_norm": 0.35316115617752075,
      "learning_rate": 1e-05,
      "loss": 0.4148,
      "step": 1212
    },
    {
      "epoch": 0.5043622766929788,
      "grad_norm": 0.37270382046699524,
      "learning_rate": 1e-05,
      "loss": 0.4175,
      "step": 1214
    },
    {
      "epoch": 0.5051931865392605,
      "grad_norm": 0.378383606672287,
      "learning_rate": 1e-05,
      "loss": 0.4202,
      "step": 1216
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 0.3677118420600891,
      "learning_rate": 1e-05,
      "loss": 0.4287,
      "step": 1218
    },
    {
      "epoch": 0.5068550062318239,
      "grad_norm": 0.3904450833797455,
      "learning_rate": 1e-05,
      "loss": 0.4107,
      "step": 1220
    },
    {
      "epoch": 0.5076859160781055,
      "grad_norm": 0.3920349180698395,
      "learning_rate": 1e-05,
      "loss": 0.4268,
      "step": 1222
    },
    {
      "epoch": 0.5085168259243872,
      "grad_norm": 0.35089394450187683,
      "learning_rate": 1e-05,
      "loss": 0.415,
      "step": 1224
    },
    {
      "epoch": 0.5093477357706688,
      "grad_norm": 0.38006535172462463,
      "learning_rate": 1e-05,
      "loss": 0.4209,
      "step": 1226
    },
    {
      "epoch": 0.5101786456169506,
      "grad_norm": 0.3616582751274109,
      "learning_rate": 1e-05,
      "loss": 0.4111,
      "step": 1228
    },
    {
      "epoch": 0.5110095554632322,
      "grad_norm": 0.36526596546173096,
      "learning_rate": 1e-05,
      "loss": 0.4174,
      "step": 1230
    },
    {
      "epoch": 0.5118404653095139,
      "grad_norm": 0.3624982237815857,
      "learning_rate": 1e-05,
      "loss": 0.4192,
      "step": 1232
    },
    {
      "epoch": 0.5126713751557956,
      "grad_norm": 0.3955772817134857,
      "learning_rate": 1e-05,
      "loss": 0.416,
      "step": 1234
    },
    {
      "epoch": 0.5135022850020773,
      "grad_norm": 0.3830726444721222,
      "learning_rate": 1e-05,
      "loss": 0.4183,
      "step": 1236
    },
    {
      "epoch": 0.5143331948483589,
      "grad_norm": 0.35212722420692444,
      "learning_rate": 1e-05,
      "loss": 0.3995,
      "step": 1238
    },
    {
      "epoch": 0.5151641046946406,
      "grad_norm": 0.3852325975894928,
      "learning_rate": 1e-05,
      "loss": 0.4115,
      "step": 1240
    },
    {
      "epoch": 0.5159950145409223,
      "grad_norm": 0.3796394467353821,
      "learning_rate": 1e-05,
      "loss": 0.4113,
      "step": 1242
    },
    {
      "epoch": 0.516825924387204,
      "grad_norm": 0.3712610900402069,
      "learning_rate": 1e-05,
      "loss": 0.3962,
      "step": 1244
    },
    {
      "epoch": 0.5176568342334856,
      "grad_norm": 0.37730735540390015,
      "learning_rate": 1e-05,
      "loss": 0.4111,
      "step": 1246
    },
    {
      "epoch": 0.5184877440797674,
      "grad_norm": 0.37493664026260376,
      "learning_rate": 1e-05,
      "loss": 0.4066,
      "step": 1248
    },
    {
      "epoch": 0.519318653926049,
      "grad_norm": 0.39399605989456177,
      "learning_rate": 1e-05,
      "loss": 0.3955,
      "step": 1250
    },
    {
      "epoch": 0.5201495637723307,
      "grad_norm": 0.37417128682136536,
      "learning_rate": 1e-05,
      "loss": 0.4158,
      "step": 1252
    },
    {
      "epoch": 0.5209804736186123,
      "grad_norm": 0.40154075622558594,
      "learning_rate": 1e-05,
      "loss": 0.4086,
      "step": 1254
    },
    {
      "epoch": 0.5218113834648941,
      "grad_norm": 0.37512949109077454,
      "learning_rate": 1e-05,
      "loss": 0.415,
      "step": 1256
    },
    {
      "epoch": 0.5226422933111757,
      "grad_norm": 0.37684309482574463,
      "learning_rate": 1e-05,
      "loss": 0.4134,
      "step": 1258
    },
    {
      "epoch": 0.5234732031574574,
      "grad_norm": 0.3678477108478546,
      "learning_rate": 1e-05,
      "loss": 0.4022,
      "step": 1260
    },
    {
      "epoch": 0.5243041130037391,
      "grad_norm": 0.38637059926986694,
      "learning_rate": 1e-05,
      "loss": 0.4158,
      "step": 1262
    },
    {
      "epoch": 0.5251350228500208,
      "grad_norm": 0.3993285000324249,
      "learning_rate": 1e-05,
      "loss": 0.4115,
      "step": 1264
    },
    {
      "epoch": 0.5259659326963024,
      "grad_norm": 0.39291781187057495,
      "learning_rate": 1e-05,
      "loss": 0.4061,
      "step": 1266
    },
    {
      "epoch": 0.5267968425425841,
      "grad_norm": 0.38639628887176514,
      "learning_rate": 1e-05,
      "loss": 0.4078,
      "step": 1268
    },
    {
      "epoch": 0.5276277523888658,
      "grad_norm": 0.36408641934394836,
      "learning_rate": 1e-05,
      "loss": 0.3991,
      "step": 1270
    },
    {
      "epoch": 0.5284586622351475,
      "grad_norm": 0.4076022505760193,
      "learning_rate": 1e-05,
      "loss": 0.3909,
      "step": 1272
    },
    {
      "epoch": 0.5292895720814291,
      "grad_norm": 0.3823798596858978,
      "learning_rate": 1e-05,
      "loss": 0.4117,
      "step": 1274
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 0.35945871472358704,
      "learning_rate": 1e-05,
      "loss": 0.4085,
      "step": 1276
    },
    {
      "epoch": 0.5309513917739925,
      "grad_norm": 0.38245850801467896,
      "learning_rate": 1e-05,
      "loss": 0.4098,
      "step": 1278
    },
    {
      "epoch": 0.5317823016202742,
      "grad_norm": 0.3866448700428009,
      "learning_rate": 1e-05,
      "loss": 0.3954,
      "step": 1280
    },
    {
      "epoch": 0.5326132114665558,
      "grad_norm": 0.3899223506450653,
      "learning_rate": 1e-05,
      "loss": 0.4014,
      "step": 1282
    },
    {
      "epoch": 0.5334441213128376,
      "grad_norm": 0.399030476808548,
      "learning_rate": 1e-05,
      "loss": 0.3972,
      "step": 1284
    },
    {
      "epoch": 0.5342750311591192,
      "grad_norm": 0.3601337671279907,
      "learning_rate": 1e-05,
      "loss": 0.4141,
      "step": 1286
    },
    {
      "epoch": 0.5351059410054009,
      "grad_norm": 0.4149631857872009,
      "learning_rate": 1e-05,
      "loss": 0.4213,
      "step": 1288
    },
    {
      "epoch": 0.5359368508516826,
      "grad_norm": 0.38191646337509155,
      "learning_rate": 1e-05,
      "loss": 0.3997,
      "step": 1290
    },
    {
      "epoch": 0.5367677606979643,
      "grad_norm": 0.38194504380226135,
      "learning_rate": 1e-05,
      "loss": 0.4254,
      "step": 1292
    },
    {
      "epoch": 0.5375986705442459,
      "grad_norm": 0.39620673656463623,
      "learning_rate": 1e-05,
      "loss": 0.4215,
      "step": 1294
    },
    {
      "epoch": 0.5384295803905276,
      "grad_norm": 0.3788962960243225,
      "learning_rate": 1e-05,
      "loss": 0.4127,
      "step": 1296
    },
    {
      "epoch": 0.5392604902368093,
      "grad_norm": 0.3816172182559967,
      "learning_rate": 1e-05,
      "loss": 0.4182,
      "step": 1298
    },
    {
      "epoch": 0.540091400083091,
      "grad_norm": 0.37787193059921265,
      "learning_rate": 1e-05,
      "loss": 0.4166,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_alpaca_gpt4_zh.json_loss": 1.372747540473938,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4905,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 439.463,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.786,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_ultrainteract_sft.json_loss": 0.44845831394195557,
      "eval_ultrainteract_sft.json_runtime": 17.9869,
      "eval_ultrainteract_sft.json_samples_per_second": 159.561,
      "eval_ultrainteract_sft.json_steps_per_second": 6.672,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_code_feedback_multi_turn.json_loss": 0.5636616945266724,
      "eval_code_feedback_multi_turn.json_runtime": 15.6548,
      "eval_code_feedback_multi_turn.json_samples_per_second": 64.9,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.747,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_tested_143k_python_alpaca.json_loss": 0.34563103318214417,
      "eval_tested_143k_python_alpaca.json_runtime": 14.3769,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 161.23,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.747,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_synthetic_text_to_sql.json_loss": 0.16870570182800293,
      "eval_synthetic_text_to_sql.json_runtime": 3.3357,
      "eval_synthetic_text_to_sql.json_samples_per_second": 418.207,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.688,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_codefeedback_filtered_instruction.json_loss": 0.38966286182403564,
      "eval_codefeedback_filtered_instruction.json_runtime": 9.9832,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.495,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.312,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_train_data_for_qwen.json_loss": 0.014312411658465862,
      "eval_train_data_for_qwen.json_runtime": 3.672,
      "eval_train_data_for_qwen.json_samples_per_second": 119.826,
      "eval_train_data_for_qwen.json_steps_per_second": 5.174,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4180437326431274,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8845,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 395.338,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.981,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_all_merge_code.json_loss": 0.22431698441505432,
      "eval_all_merge_code.json_runtime": 16.7676,
      "eval_all_merge_code.json_samples_per_second": 206.47,
      "eval_all_merge_code.json_steps_per_second": 8.648,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_xlam_function_calling_60k.json_loss": 0.019800638779997826,
      "eval_xlam_function_calling_60k.json_runtime": 4.4129,
      "eval_xlam_function_calling_60k.json_samples_per_second": 201.003,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.385,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_table_python_code_datas.json_loss": 0.153811514377594,
      "eval_table_python_code_datas.json_runtime": 66.9177,
      "eval_table_python_code_datas.json_samples_per_second": 69.698,
      "eval_table_python_code_datas.json_steps_per_second": 2.914,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_Table_GPT.json_loss": 0.05911598727107048,
      "eval_Table_GPT.json_runtime": 10.6081,
      "eval_Table_GPT.json_samples_per_second": 83.616,
      "eval_Table_GPT.json_steps_per_second": 3.488,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_tabular_llm_data.json_loss": 0.10617751628160477,
      "eval_tabular_llm_data.json_runtime": 50.2831,
      "eval_tabular_llm_data.json_samples_per_second": 58.27,
      "eval_tabular_llm_data.json_steps_per_second": 2.446,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_gpt_4o_200k.json_loss": 0.8491767644882202,
      "eval_gpt_4o_200k.json_runtime": 27.2923,
      "eval_gpt_4o_200k.json_samples_per_second": 130.843,
      "eval_gpt_4o_200k.json_steps_per_second": 5.459,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_MathInstruct.json_loss": 0.1753709763288498,
      "eval_MathInstruct.json_runtime": 12.9529,
      "eval_MathInstruct.json_samples_per_second": 252.839,
      "eval_MathInstruct.json_steps_per_second": 10.577,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_alpaca_cleaned.json_loss": 0.9350064992904663,
      "eval_alpaca_cleaned.json_runtime": 2.3711,
      "eval_alpaca_cleaned.json_samples_per_second": 375.354,
      "eval_alpaca_cleaned.json_steps_per_second": 16.026,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_multi_turn_datas_0816.json_loss": 0.2987470030784607,
      "eval_multi_turn_datas_0816.json_runtime": 71.3352,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.335,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.397,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_sharegpt_gpt4.json_loss": 0.743951678276062,
      "eval_sharegpt_gpt4.json_runtime": 21.8318,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.554,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.794,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_python_code_critic_21k.json_loss": 0.6273874044418335,
      "eval_python_code_critic_21k.json_runtime": 1.9548,
      "eval_python_code_critic_21k.json_samples_per_second": 147.837,
      "eval_python_code_critic_21k.json_steps_per_second": 6.65,
      "step": 1300
    },
    {
      "epoch": 0.540091400083091,
      "eval_agent_instruct.json_loss": 0.20687253773212433,
      "eval_agent_instruct.json_runtime": 0.2441,
      "eval_agent_instruct.json_samples_per_second": 90.119,
      "eval_agent_instruct.json_steps_per_second": 4.096,
      "step": 1300
    },
    {
      "epoch": 0.5409223099293726,
      "grad_norm": 0.38505956530570984,
      "learning_rate": 1e-05,
      "loss": 0.4126,
      "step": 1302
    },
    {
      "epoch": 0.5417532197756544,
      "grad_norm": 0.3742436468601227,
      "learning_rate": 1e-05,
      "loss": 0.4171,
      "step": 1304
    },
    {
      "epoch": 0.542584129621936,
      "grad_norm": 0.40847161412239075,
      "learning_rate": 1e-05,
      "loss": 0.423,
      "step": 1306
    },
    {
      "epoch": 0.5434150394682177,
      "grad_norm": 0.39443033933639526,
      "learning_rate": 1e-05,
      "loss": 0.4025,
      "step": 1308
    },
    {
      "epoch": 0.5442459493144993,
      "grad_norm": 0.3648662269115448,
      "learning_rate": 1e-05,
      "loss": 0.4221,
      "step": 1310
    },
    {
      "epoch": 0.5450768591607811,
      "grad_norm": 0.384576678276062,
      "learning_rate": 1e-05,
      "loss": 0.4096,
      "step": 1312
    },
    {
      "epoch": 0.5459077690070627,
      "grad_norm": 0.38063448667526245,
      "learning_rate": 1e-05,
      "loss": 0.4191,
      "step": 1314
    },
    {
      "epoch": 0.5467386788533444,
      "grad_norm": 0.3942050039768219,
      "learning_rate": 1e-05,
      "loss": 0.4129,
      "step": 1316
    },
    {
      "epoch": 0.5475695886996261,
      "grad_norm": 0.37111732363700867,
      "learning_rate": 1e-05,
      "loss": 0.3964,
      "step": 1318
    },
    {
      "epoch": 0.5484004985459078,
      "grad_norm": 0.38255712389945984,
      "learning_rate": 1e-05,
      "loss": 0.4104,
      "step": 1320
    },
    {
      "epoch": 0.5492314083921894,
      "grad_norm": 0.3707699477672577,
      "learning_rate": 1e-05,
      "loss": 0.411,
      "step": 1322
    },
    {
      "epoch": 0.5500623182384711,
      "grad_norm": 0.3655988276004791,
      "learning_rate": 1e-05,
      "loss": 0.4085,
      "step": 1324
    },
    {
      "epoch": 0.5508932280847528,
      "grad_norm": 0.39512765407562256,
      "learning_rate": 1e-05,
      "loss": 0.4097,
      "step": 1326
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.37182366847991943,
      "learning_rate": 1e-05,
      "loss": 0.4123,
      "step": 1328
    },
    {
      "epoch": 0.5525550477773161,
      "grad_norm": 0.3933617174625397,
      "learning_rate": 1e-05,
      "loss": 0.4097,
      "step": 1330
    },
    {
      "epoch": 0.5533859576235979,
      "grad_norm": 0.3905732035636902,
      "learning_rate": 1e-05,
      "loss": 0.4084,
      "step": 1332
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 0.37454912066459656,
      "learning_rate": 1e-05,
      "loss": 0.4066,
      "step": 1334
    },
    {
      "epoch": 0.5550477773161612,
      "grad_norm": 0.3726365268230438,
      "learning_rate": 1e-05,
      "loss": 0.3953,
      "step": 1336
    },
    {
      "epoch": 0.5558786871624429,
      "grad_norm": 0.375201553106308,
      "learning_rate": 1e-05,
      "loss": 0.4048,
      "step": 1338
    },
    {
      "epoch": 0.5567095970087246,
      "grad_norm": 0.37291380763053894,
      "learning_rate": 1e-05,
      "loss": 0.403,
      "step": 1340
    },
    {
      "epoch": 0.5575405068550062,
      "grad_norm": 0.3727644383907318,
      "learning_rate": 1e-05,
      "loss": 0.4172,
      "step": 1342
    },
    {
      "epoch": 0.5583714167012879,
      "grad_norm": 0.35430729389190674,
      "learning_rate": 1e-05,
      "loss": 0.4005,
      "step": 1344
    },
    {
      "epoch": 0.5592023265475696,
      "grad_norm": 0.36957523226737976,
      "learning_rate": 1e-05,
      "loss": 0.4062,
      "step": 1346
    },
    {
      "epoch": 0.5600332363938513,
      "grad_norm": 0.39267483353614807,
      "learning_rate": 1e-05,
      "loss": 0.4041,
      "step": 1348
    },
    {
      "epoch": 0.5608641462401329,
      "grad_norm": 0.38299691677093506,
      "learning_rate": 1e-05,
      "loss": 0.3931,
      "step": 1350
    },
    {
      "epoch": 0.5616950560864147,
      "grad_norm": 0.3810291886329651,
      "learning_rate": 1e-05,
      "loss": 0.418,
      "step": 1352
    },
    {
      "epoch": 0.5625259659326963,
      "grad_norm": 0.3629259467124939,
      "learning_rate": 1e-05,
      "loss": 0.4064,
      "step": 1354
    },
    {
      "epoch": 0.563356875778978,
      "grad_norm": 0.3695560097694397,
      "learning_rate": 1e-05,
      "loss": 0.4075,
      "step": 1356
    },
    {
      "epoch": 0.5641877856252596,
      "grad_norm": 0.3742305040359497,
      "learning_rate": 1e-05,
      "loss": 0.3978,
      "step": 1358
    },
    {
      "epoch": 0.5650186954715414,
      "grad_norm": 0.37772244215011597,
      "learning_rate": 1e-05,
      "loss": 0.4222,
      "step": 1360
    },
    {
      "epoch": 0.565849605317823,
      "grad_norm": 0.3794150650501251,
      "learning_rate": 1e-05,
      "loss": 0.4061,
      "step": 1362
    },
    {
      "epoch": 0.5666805151641047,
      "grad_norm": 0.38053521513938904,
      "learning_rate": 1e-05,
      "loss": 0.4002,
      "step": 1364
    },
    {
      "epoch": 0.5675114250103864,
      "grad_norm": 0.38356906175613403,
      "learning_rate": 1e-05,
      "loss": 0.4123,
      "step": 1366
    },
    {
      "epoch": 0.5683423348566681,
      "grad_norm": 0.3881264328956604,
      "learning_rate": 1e-05,
      "loss": 0.3871,
      "step": 1368
    },
    {
      "epoch": 0.5691732447029497,
      "grad_norm": 0.3832606077194214,
      "learning_rate": 1e-05,
      "loss": 0.4019,
      "step": 1370
    },
    {
      "epoch": 0.5700041545492314,
      "grad_norm": 0.3791566491127014,
      "learning_rate": 1e-05,
      "loss": 0.4052,
      "step": 1372
    },
    {
      "epoch": 0.5708350643955131,
      "grad_norm": 0.37720930576324463,
      "learning_rate": 1e-05,
      "loss": 0.4038,
      "step": 1374
    },
    {
      "epoch": 0.5716659742417948,
      "grad_norm": 0.3920806646347046,
      "learning_rate": 1e-05,
      "loss": 0.4131,
      "step": 1376
    },
    {
      "epoch": 0.5724968840880764,
      "grad_norm": 0.3717060685157776,
      "learning_rate": 1e-05,
      "loss": 0.4175,
      "step": 1378
    },
    {
      "epoch": 0.5733277939343582,
      "grad_norm": 0.35852858424186707,
      "learning_rate": 1e-05,
      "loss": 0.4129,
      "step": 1380
    },
    {
      "epoch": 0.5741587037806398,
      "grad_norm": 0.378675252199173,
      "learning_rate": 1e-05,
      "loss": 0.4053,
      "step": 1382
    },
    {
      "epoch": 0.5749896136269215,
      "grad_norm": 0.38083615899086,
      "learning_rate": 1e-05,
      "loss": 0.4067,
      "step": 1384
    },
    {
      "epoch": 0.5758205234732031,
      "grad_norm": 0.3762880563735962,
      "learning_rate": 1e-05,
      "loss": 0.3978,
      "step": 1386
    },
    {
      "epoch": 0.5766514333194849,
      "grad_norm": 0.39091816544532776,
      "learning_rate": 1e-05,
      "loss": 0.4148,
      "step": 1388
    },
    {
      "epoch": 0.5774823431657665,
      "grad_norm": 0.39682304859161377,
      "learning_rate": 1e-05,
      "loss": 0.4054,
      "step": 1390
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 0.37844571471214294,
      "learning_rate": 1e-05,
      "loss": 0.4141,
      "step": 1392
    },
    {
      "epoch": 0.5791441628583299,
      "grad_norm": 0.39657866954803467,
      "learning_rate": 1e-05,
      "loss": 0.4065,
      "step": 1394
    },
    {
      "epoch": 0.5799750727046116,
      "grad_norm": 0.39888307452201843,
      "learning_rate": 1e-05,
      "loss": 0.3982,
      "step": 1396
    },
    {
      "epoch": 0.5808059825508932,
      "grad_norm": 0.3738526999950409,
      "learning_rate": 1e-05,
      "loss": 0.3933,
      "step": 1398
    },
    {
      "epoch": 0.5816368923971749,
      "grad_norm": 0.37905585765838623,
      "learning_rate": 1e-05,
      "loss": 0.4211,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_alpaca_gpt4_zh.json_loss": 1.3711687326431274,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4759,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 443.805,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.972,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_ultrainteract_sft.json_loss": 0.44720596075057983,
      "eval_ultrainteract_sft.json_runtime": 18.0606,
      "eval_ultrainteract_sft.json_samples_per_second": 158.909,
      "eval_ultrainteract_sft.json_steps_per_second": 6.644,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_code_feedback_multi_turn.json_loss": 0.5628970861434937,
      "eval_code_feedback_multi_turn.json_runtime": 15.6527,
      "eval_code_feedback_multi_turn.json_samples_per_second": 64.909,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.747,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_tested_143k_python_alpaca.json_loss": 0.3442595601081848,
      "eval_tested_143k_python_alpaca.json_runtime": 14.3691,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 161.318,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.751,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_synthetic_text_to_sql.json_loss": 0.16902178525924683,
      "eval_synthetic_text_to_sql.json_runtime": 3.3389,
      "eval_synthetic_text_to_sql.json_samples_per_second": 417.806,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.671,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_codefeedback_filtered_instruction.json_loss": 0.3851953446865082,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0375,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 174.545,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.273,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_train_data_for_qwen.json_loss": 0.014180943369865417,
      "eval_train_data_for_qwen.json_runtime": 3.682,
      "eval_train_data_for_qwen.json_samples_per_second": 119.499,
      "eval_train_data_for_qwen.json_steps_per_second": 5.16,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4209064245224,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8898,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 394.217,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.933,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_all_merge_code.json_loss": 0.22094738483428955,
      "eval_all_merge_code.json_runtime": 16.8446,
      "eval_all_merge_code.json_samples_per_second": 205.526,
      "eval_all_merge_code.json_steps_per_second": 8.608,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_xlam_function_calling_60k.json_loss": 0.019567323848605156,
      "eval_xlam_function_calling_60k.json_runtime": 4.4228,
      "eval_xlam_function_calling_60k.json_samples_per_second": 200.55,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.366,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_table_python_code_datas.json_loss": 0.15232205390930176,
      "eval_table_python_code_datas.json_runtime": 65.8217,
      "eval_table_python_code_datas.json_samples_per_second": 70.858,
      "eval_table_python_code_datas.json_steps_per_second": 2.963,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_Table_GPT.json_loss": 0.057372067123651505,
      "eval_Table_GPT.json_runtime": 10.6258,
      "eval_Table_GPT.json_samples_per_second": 83.476,
      "eval_Table_GPT.json_steps_per_second": 3.482,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_tabular_llm_data.json_loss": 0.1066935807466507,
      "eval_tabular_llm_data.json_runtime": 50.8127,
      "eval_tabular_llm_data.json_samples_per_second": 57.663,
      "eval_tabular_llm_data.json_steps_per_second": 2.421,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_gpt_4o_200k.json_loss": 0.8480329513549805,
      "eval_gpt_4o_200k.json_runtime": 27.4365,
      "eval_gpt_4o_200k.json_samples_per_second": 130.155,
      "eval_gpt_4o_200k.json_steps_per_second": 5.431,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_MathInstruct.json_loss": 0.17522703111171722,
      "eval_MathInstruct.json_runtime": 12.9696,
      "eval_MathInstruct.json_samples_per_second": 252.514,
      "eval_MathInstruct.json_steps_per_second": 10.563,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_alpaca_cleaned.json_loss": 0.9334685206413269,
      "eval_alpaca_cleaned.json_runtime": 2.3793,
      "eval_alpaca_cleaned.json_samples_per_second": 374.052,
      "eval_alpaca_cleaned.json_steps_per_second": 15.971,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_multi_turn_datas_0816.json_loss": 0.2932318150997162,
      "eval_multi_turn_datas_0816.json_runtime": 71.578,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.14,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.389,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_sharegpt_gpt4.json_loss": 0.741651713848114,
      "eval_sharegpt_gpt4.json_runtime": 21.8944,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.364,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.786,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_python_code_critic_21k.json_loss": 0.6225956678390503,
      "eval_python_code_critic_21k.json_runtime": 1.9487,
      "eval_python_code_critic_21k.json_samples_per_second": 148.301,
      "eval_python_code_critic_21k.json_steps_per_second": 6.671,
      "step": 1400
    },
    {
      "epoch": 0.5816368923971749,
      "eval_agent_instruct.json_loss": 0.2056816667318344,
      "eval_agent_instruct.json_runtime": 0.2451,
      "eval_agent_instruct.json_samples_per_second": 89.748,
      "eval_agent_instruct.json_steps_per_second": 4.079,
      "step": 1400
    },
    {
      "epoch": 0.5824678022434566,
      "grad_norm": 0.38693875074386597,
      "learning_rate": 1e-05,
      "loss": 0.4072,
      "step": 1402
    },
    {
      "epoch": 0.5832987120897383,
      "grad_norm": 0.3645879030227661,
      "learning_rate": 1e-05,
      "loss": 0.4123,
      "step": 1404
    },
    {
      "epoch": 0.5841296219360199,
      "grad_norm": 0.3789058029651642,
      "learning_rate": 1e-05,
      "loss": 0.3887,
      "step": 1406
    },
    {
      "epoch": 0.5849605317823017,
      "grad_norm": 0.3622429668903351,
      "learning_rate": 1e-05,
      "loss": 0.4214,
      "step": 1408
    },
    {
      "epoch": 0.5857914416285833,
      "grad_norm": 0.38520076870918274,
      "learning_rate": 1e-05,
      "loss": 0.41,
      "step": 1410
    },
    {
      "epoch": 0.586622351474865,
      "grad_norm": 0.3843233585357666,
      "learning_rate": 1e-05,
      "loss": 0.4188,
      "step": 1412
    },
    {
      "epoch": 0.5874532613211466,
      "grad_norm": 0.3896225690841675,
      "learning_rate": 1e-05,
      "loss": 0.3991,
      "step": 1414
    },
    {
      "epoch": 0.5882841711674284,
      "grad_norm": 0.3837020695209503,
      "learning_rate": 1e-05,
      "loss": 0.3894,
      "step": 1416
    },
    {
      "epoch": 0.58911508101371,
      "grad_norm": 0.3833214342594147,
      "learning_rate": 1e-05,
      "loss": 0.4045,
      "step": 1418
    },
    {
      "epoch": 0.5899459908599917,
      "grad_norm": 0.379413366317749,
      "learning_rate": 1e-05,
      "loss": 0.3938,
      "step": 1420
    },
    {
      "epoch": 0.5907769007062734,
      "grad_norm": 0.3961108326911926,
      "learning_rate": 1e-05,
      "loss": 0.4036,
      "step": 1422
    },
    {
      "epoch": 0.5916078105525551,
      "grad_norm": 0.3844679296016693,
      "learning_rate": 1e-05,
      "loss": 0.4139,
      "step": 1424
    },
    {
      "epoch": 0.5924387203988367,
      "grad_norm": 0.3842119872570038,
      "learning_rate": 1e-05,
      "loss": 0.4038,
      "step": 1426
    },
    {
      "epoch": 0.5932696302451184,
      "grad_norm": 0.3904360830783844,
      "learning_rate": 1e-05,
      "loss": 0.4146,
      "step": 1428
    },
    {
      "epoch": 0.5941005400914001,
      "grad_norm": 0.37042325735092163,
      "learning_rate": 1e-05,
      "loss": 0.401,
      "step": 1430
    },
    {
      "epoch": 0.5949314499376818,
      "grad_norm": 0.42344844341278076,
      "learning_rate": 1e-05,
      "loss": 0.4042,
      "step": 1432
    },
    {
      "epoch": 0.5957623597839634,
      "grad_norm": 0.380095899105072,
      "learning_rate": 1e-05,
      "loss": 0.4269,
      "step": 1434
    },
    {
      "epoch": 0.5965932696302452,
      "grad_norm": 0.3633849322795868,
      "learning_rate": 1e-05,
      "loss": 0.4154,
      "step": 1436
    },
    {
      "epoch": 0.5974241794765268,
      "grad_norm": 0.3844614624977112,
      "learning_rate": 1e-05,
      "loss": 0.4032,
      "step": 1438
    },
    {
      "epoch": 0.5982550893228085,
      "grad_norm": 0.3755004107952118,
      "learning_rate": 1e-05,
      "loss": 0.4072,
      "step": 1440
    },
    {
      "epoch": 0.5990859991690901,
      "grad_norm": 0.3703066110610962,
      "learning_rate": 1e-05,
      "loss": 0.403,
      "step": 1442
    },
    {
      "epoch": 0.5999169090153719,
      "grad_norm": 0.37559548020362854,
      "learning_rate": 1e-05,
      "loss": 0.4054,
      "step": 1444
    },
    {
      "epoch": 0.6007478188616535,
      "grad_norm": 0.3883635401725769,
      "learning_rate": 1e-05,
      "loss": 0.4151,
      "step": 1446
    },
    {
      "epoch": 0.6015787287079352,
      "grad_norm": 0.36647966504096985,
      "learning_rate": 1e-05,
      "loss": 0.4079,
      "step": 1448
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 0.3779089152812958,
      "learning_rate": 1e-05,
      "loss": 0.3987,
      "step": 1450
    },
    {
      "epoch": 0.6032405484004986,
      "grad_norm": 0.38923773169517517,
      "learning_rate": 1e-05,
      "loss": 0.4052,
      "step": 1452
    },
    {
      "epoch": 0.6040714582467802,
      "grad_norm": 0.39189013838768005,
      "learning_rate": 1e-05,
      "loss": 0.3983,
      "step": 1454
    },
    {
      "epoch": 0.6049023680930619,
      "grad_norm": 0.3794521689414978,
      "learning_rate": 1e-05,
      "loss": 0.4136,
      "step": 1456
    },
    {
      "epoch": 0.6057332779393436,
      "grad_norm": 0.3650713562965393,
      "learning_rate": 1e-05,
      "loss": 0.3935,
      "step": 1458
    },
    {
      "epoch": 0.6065641877856253,
      "grad_norm": 0.3864278197288513,
      "learning_rate": 1e-05,
      "loss": 0.4098,
      "step": 1460
    },
    {
      "epoch": 0.6073950976319069,
      "grad_norm": 0.36979958415031433,
      "learning_rate": 1e-05,
      "loss": 0.4264,
      "step": 1462
    },
    {
      "epoch": 0.6082260074781887,
      "grad_norm": 0.3906637132167816,
      "learning_rate": 1e-05,
      "loss": 0.4236,
      "step": 1464
    },
    {
      "epoch": 0.6090569173244703,
      "grad_norm": 0.366325706243515,
      "learning_rate": 1e-05,
      "loss": 0.4013,
      "step": 1466
    },
    {
      "epoch": 0.609887827170752,
      "grad_norm": 0.3844982385635376,
      "learning_rate": 1e-05,
      "loss": 0.414,
      "step": 1468
    },
    {
      "epoch": 0.6107187370170336,
      "grad_norm": 0.39369112253189087,
      "learning_rate": 1e-05,
      "loss": 0.4139,
      "step": 1470
    },
    {
      "epoch": 0.6115496468633154,
      "grad_norm": 0.3907407522201538,
      "learning_rate": 1e-05,
      "loss": 0.4113,
      "step": 1472
    },
    {
      "epoch": 0.612380556709597,
      "grad_norm": 0.39736124873161316,
      "learning_rate": 1e-05,
      "loss": 0.4121,
      "step": 1474
    },
    {
      "epoch": 0.6132114665558787,
      "grad_norm": 0.3988563120365143,
      "learning_rate": 1e-05,
      "loss": 0.3984,
      "step": 1476
    },
    {
      "epoch": 0.6140423764021604,
      "grad_norm": 0.3824082314968109,
      "learning_rate": 1e-05,
      "loss": 0.3928,
      "step": 1478
    },
    {
      "epoch": 0.6148732862484421,
      "grad_norm": 0.3880847990512848,
      "learning_rate": 1e-05,
      "loss": 0.4075,
      "step": 1480
    },
    {
      "epoch": 0.6157041960947237,
      "grad_norm": 0.3919200897216797,
      "learning_rate": 1e-05,
      "loss": 0.4016,
      "step": 1482
    },
    {
      "epoch": 0.6165351059410054,
      "grad_norm": 0.38663244247436523,
      "learning_rate": 1e-05,
      "loss": 0.407,
      "step": 1484
    },
    {
      "epoch": 0.6173660157872871,
      "grad_norm": 0.39964044094085693,
      "learning_rate": 1e-05,
      "loss": 0.4201,
      "step": 1486
    },
    {
      "epoch": 0.6181969256335688,
      "grad_norm": 0.3796275556087494,
      "learning_rate": 1e-05,
      "loss": 0.4001,
      "step": 1488
    },
    {
      "epoch": 0.6190278354798504,
      "grad_norm": 0.38901033997535706,
      "learning_rate": 1e-05,
      "loss": 0.3939,
      "step": 1490
    },
    {
      "epoch": 0.6198587453261322,
      "grad_norm": 0.39256179332733154,
      "learning_rate": 1e-05,
      "loss": 0.4193,
      "step": 1492
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.3936039209365845,
      "learning_rate": 1e-05,
      "loss": 0.4008,
      "step": 1494
    },
    {
      "epoch": 0.6215205650186955,
      "grad_norm": 0.3979041576385498,
      "learning_rate": 1e-05,
      "loss": 0.4098,
      "step": 1496
    },
    {
      "epoch": 0.6223514748649771,
      "grad_norm": 0.36848825216293335,
      "learning_rate": 1e-05,
      "loss": 0.4045,
      "step": 1498
    },
    {
      "epoch": 0.6231823847112589,
      "grad_norm": 0.4032812714576721,
      "learning_rate": 1e-05,
      "loss": 0.4101,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_alpaca_gpt4_zh.json_loss": 1.3790924549102783,
      "eval_alpaca_gpt4_zh.json_runtime": 1.475,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 444.074,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 18.983,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_ultrainteract_sft.json_loss": 0.44618335366249084,
      "eval_ultrainteract_sft.json_runtime": 17.9842,
      "eval_ultrainteract_sft.json_samples_per_second": 159.585,
      "eval_ultrainteract_sft.json_steps_per_second": 6.673,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_code_feedback_multi_turn.json_loss": 0.5629762411117554,
      "eval_code_feedback_multi_turn.json_runtime": 15.2152,
      "eval_code_feedback_multi_turn.json_samples_per_second": 66.776,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.826,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_tested_143k_python_alpaca.json_loss": 0.34165218472480774,
      "eval_tested_143k_python_alpaca.json_runtime": 14.3872,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 161.116,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.742,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_synthetic_text_to_sql.json_loss": 0.1691683977842331,
      "eval_synthetic_text_to_sql.json_runtime": 3.3275,
      "eval_synthetic_text_to_sql.json_samples_per_second": 419.228,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.731,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_codefeedback_filtered_instruction.json_loss": 0.38198670744895935,
      "eval_codefeedback_filtered_instruction.json_runtime": 9.9982,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.231,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.301,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_train_data_for_qwen.json_loss": 0.015169116668403149,
      "eval_train_data_for_qwen.json_runtime": 3.6685,
      "eval_train_data_for_qwen.json_samples_per_second": 119.94,
      "eval_train_data_for_qwen.json_steps_per_second": 5.179,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4140759706497192,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.9636,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 379.401,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.296,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_all_merge_code.json_loss": 0.21811489760875702,
      "eval_all_merge_code.json_runtime": 16.8551,
      "eval_all_merge_code.json_samples_per_second": 205.398,
      "eval_all_merge_code.json_steps_per_second": 8.603,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_xlam_function_calling_60k.json_loss": 0.01884652115404606,
      "eval_xlam_function_calling_60k.json_runtime": 4.4203,
      "eval_xlam_function_calling_60k.json_samples_per_second": 200.665,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.37,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_table_python_code_datas.json_loss": 0.15219846367835999,
      "eval_table_python_code_datas.json_runtime": 66.171,
      "eval_table_python_code_datas.json_samples_per_second": 70.484,
      "eval_table_python_code_datas.json_steps_per_second": 2.947,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_Table_GPT.json_loss": 0.05799243599176407,
      "eval_Table_GPT.json_runtime": 10.5961,
      "eval_Table_GPT.json_samples_per_second": 83.71,
      "eval_Table_GPT.json_steps_per_second": 3.492,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_tabular_llm_data.json_loss": 0.10681363940238953,
      "eval_tabular_llm_data.json_runtime": 50.668,
      "eval_tabular_llm_data.json_samples_per_second": 57.827,
      "eval_tabular_llm_data.json_steps_per_second": 2.428,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_gpt_4o_200k.json_loss": 0.8485134840011597,
      "eval_gpt_4o_200k.json_runtime": 27.2427,
      "eval_gpt_4o_200k.json_samples_per_second": 131.081,
      "eval_gpt_4o_200k.json_steps_per_second": 5.469,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_MathInstruct.json_loss": 0.1751236915588379,
      "eval_MathInstruct.json_runtime": 12.9748,
      "eval_MathInstruct.json_samples_per_second": 252.412,
      "eval_MathInstruct.json_steps_per_second": 10.559,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_alpaca_cleaned.json_loss": 0.9336560964584351,
      "eval_alpaca_cleaned.json_runtime": 2.3899,
      "eval_alpaca_cleaned.json_samples_per_second": 372.398,
      "eval_alpaca_cleaned.json_steps_per_second": 15.9,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_multi_turn_datas_0816.json_loss": 0.28784313797950745,
      "eval_multi_turn_datas_0816.json_runtime": 71.6028,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.121,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.388,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_sharegpt_gpt4.json_loss": 0.7392477989196777,
      "eval_sharegpt_gpt4.json_runtime": 21.6925,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.982,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.812,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_python_code_critic_21k.json_loss": 0.6229996085166931,
      "eval_python_code_critic_21k.json_runtime": 1.954,
      "eval_python_code_critic_21k.json_samples_per_second": 147.903,
      "eval_python_code_critic_21k.json_steps_per_second": 6.653,
      "step": 1500
    },
    {
      "epoch": 0.6231823847112589,
      "eval_agent_instruct.json_loss": 0.2027963548898697,
      "eval_agent_instruct.json_runtime": 0.246,
      "eval_agent_instruct.json_samples_per_second": 89.429,
      "eval_agent_instruct.json_steps_per_second": 4.065,
      "step": 1500
    },
    {
      "epoch": 0.6240132945575405,
      "grad_norm": 0.37124744057655334,
      "learning_rate": 1e-05,
      "loss": 0.4107,
      "step": 1502
    },
    {
      "epoch": 0.6248442044038222,
      "grad_norm": 0.3786878287792206,
      "learning_rate": 1e-05,
      "loss": 0.3846,
      "step": 1504
    },
    {
      "epoch": 0.6256751142501039,
      "grad_norm": 0.3777852952480316,
      "learning_rate": 1e-05,
      "loss": 0.3962,
      "step": 1506
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 0.3929501473903656,
      "learning_rate": 1e-05,
      "loss": 0.3898,
      "step": 1508
    },
    {
      "epoch": 0.6273369339426672,
      "grad_norm": 0.39523744583129883,
      "learning_rate": 1e-05,
      "loss": 0.4088,
      "step": 1510
    },
    {
      "epoch": 0.6281678437889489,
      "grad_norm": 0.3886941373348236,
      "learning_rate": 1e-05,
      "loss": 0.4105,
      "step": 1512
    },
    {
      "epoch": 0.6289987536352306,
      "grad_norm": 0.3897187113761902,
      "learning_rate": 1e-05,
      "loss": 0.3901,
      "step": 1514
    },
    {
      "epoch": 0.6298296634815123,
      "grad_norm": 0.37097635865211487,
      "learning_rate": 1e-05,
      "loss": 0.4053,
      "step": 1516
    },
    {
      "epoch": 0.6306605733277939,
      "grad_norm": 0.35823529958724976,
      "learning_rate": 1e-05,
      "loss": 0.4087,
      "step": 1518
    },
    {
      "epoch": 0.6314914831740757,
      "grad_norm": 0.4065542221069336,
      "learning_rate": 1e-05,
      "loss": 0.4107,
      "step": 1520
    },
    {
      "epoch": 0.6323223930203573,
      "grad_norm": 0.39129912853240967,
      "learning_rate": 1e-05,
      "loss": 0.4183,
      "step": 1522
    },
    {
      "epoch": 0.633153302866639,
      "grad_norm": 0.4041009247303009,
      "learning_rate": 1e-05,
      "loss": 0.4088,
      "step": 1524
    },
    {
      "epoch": 0.6339842127129206,
      "grad_norm": 0.37875527143478394,
      "learning_rate": 1e-05,
      "loss": 0.397,
      "step": 1526
    },
    {
      "epoch": 0.6348151225592024,
      "grad_norm": 0.3799017071723938,
      "learning_rate": 1e-05,
      "loss": 0.4107,
      "step": 1528
    },
    {
      "epoch": 0.635646032405484,
      "grad_norm": 0.3798377811908722,
      "learning_rate": 1e-05,
      "loss": 0.3968,
      "step": 1530
    },
    {
      "epoch": 0.6364769422517657,
      "grad_norm": 0.37747645378112793,
      "learning_rate": 1e-05,
      "loss": 0.39,
      "step": 1532
    },
    {
      "epoch": 0.6373078520980474,
      "grad_norm": 0.39652398228645325,
      "learning_rate": 1e-05,
      "loss": 0.4086,
      "step": 1534
    },
    {
      "epoch": 0.6381387619443291,
      "grad_norm": 0.4018811881542206,
      "learning_rate": 1e-05,
      "loss": 0.4094,
      "step": 1536
    },
    {
      "epoch": 0.6389696717906107,
      "grad_norm": 0.3806191682815552,
      "learning_rate": 1e-05,
      "loss": 0.3916,
      "step": 1538
    },
    {
      "epoch": 0.6398005816368924,
      "grad_norm": 0.3776761293411255,
      "learning_rate": 1e-05,
      "loss": 0.4104,
      "step": 1540
    },
    {
      "epoch": 0.6406314914831741,
      "grad_norm": 0.35857099294662476,
      "learning_rate": 1e-05,
      "loss": 0.3996,
      "step": 1542
    },
    {
      "epoch": 0.6414624013294558,
      "grad_norm": 0.39281323552131653,
      "learning_rate": 1e-05,
      "loss": 0.4058,
      "step": 1544
    },
    {
      "epoch": 0.6422933111757374,
      "grad_norm": 0.3716391324996948,
      "learning_rate": 1e-05,
      "loss": 0.3932,
      "step": 1546
    },
    {
      "epoch": 0.6431242210220192,
      "grad_norm": 0.3866826891899109,
      "learning_rate": 1e-05,
      "loss": 0.3841,
      "step": 1548
    },
    {
      "epoch": 0.6439551308683008,
      "grad_norm": 0.36163103580474854,
      "learning_rate": 1e-05,
      "loss": 0.3997,
      "step": 1550
    },
    {
      "epoch": 0.6447860407145825,
      "grad_norm": 0.41015100479125977,
      "learning_rate": 1e-05,
      "loss": 0.3902,
      "step": 1552
    },
    {
      "epoch": 0.6456169505608641,
      "grad_norm": 0.3587234616279602,
      "learning_rate": 1e-05,
      "loss": 0.3877,
      "step": 1554
    },
    {
      "epoch": 0.6464478604071459,
      "grad_norm": 0.3883909285068512,
      "learning_rate": 1e-05,
      "loss": 0.3985,
      "step": 1556
    },
    {
      "epoch": 0.6472787702534275,
      "grad_norm": 0.3740590214729309,
      "learning_rate": 1e-05,
      "loss": 0.4138,
      "step": 1558
    },
    {
      "epoch": 0.6481096800997092,
      "grad_norm": 0.3845783472061157,
      "learning_rate": 1e-05,
      "loss": 0.3935,
      "step": 1560
    },
    {
      "epoch": 0.6489405899459909,
      "grad_norm": 0.37389472126960754,
      "learning_rate": 1e-05,
      "loss": 0.3819,
      "step": 1562
    },
    {
      "epoch": 0.6497714997922726,
      "grad_norm": 0.37676987051963806,
      "learning_rate": 1e-05,
      "loss": 0.3904,
      "step": 1564
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 0.39855799078941345,
      "learning_rate": 1e-05,
      "loss": 0.396,
      "step": 1566
    },
    {
      "epoch": 0.6514333194848358,
      "grad_norm": 0.38531097769737244,
      "learning_rate": 1e-05,
      "loss": 0.4018,
      "step": 1568
    },
    {
      "epoch": 0.6522642293311176,
      "grad_norm": 0.3781912922859192,
      "learning_rate": 1e-05,
      "loss": 0.3904,
      "step": 1570
    },
    {
      "epoch": 0.6530951391773993,
      "grad_norm": 0.3847458064556122,
      "learning_rate": 1e-05,
      "loss": 0.3882,
      "step": 1572
    },
    {
      "epoch": 0.6539260490236809,
      "grad_norm": 0.3692390024662018,
      "learning_rate": 1e-05,
      "loss": 0.3995,
      "step": 1574
    },
    {
      "epoch": 0.6547569588699627,
      "grad_norm": 0.4045485556125641,
      "learning_rate": 1e-05,
      "loss": 0.4173,
      "step": 1576
    },
    {
      "epoch": 0.6555878687162443,
      "grad_norm": 0.3799736797809601,
      "learning_rate": 1e-05,
      "loss": 0.3975,
      "step": 1578
    },
    {
      "epoch": 0.656418778562526,
      "grad_norm": 0.3776188790798187,
      "learning_rate": 1e-05,
      "loss": 0.398,
      "step": 1580
    },
    {
      "epoch": 0.6572496884088076,
      "grad_norm": 0.3760836124420166,
      "learning_rate": 1e-05,
      "loss": 0.4022,
      "step": 1582
    },
    {
      "epoch": 0.6580805982550894,
      "grad_norm": 0.39492499828338623,
      "learning_rate": 1e-05,
      "loss": 0.413,
      "step": 1584
    },
    {
      "epoch": 0.658911508101371,
      "grad_norm": 0.3791895806789398,
      "learning_rate": 1e-05,
      "loss": 0.4149,
      "step": 1586
    },
    {
      "epoch": 0.6597424179476526,
      "grad_norm": 0.38073983788490295,
      "learning_rate": 1e-05,
      "loss": 0.4056,
      "step": 1588
    },
    {
      "epoch": 0.6605733277939344,
      "grad_norm": 0.39741215109825134,
      "learning_rate": 1e-05,
      "loss": 0.3878,
      "step": 1590
    },
    {
      "epoch": 0.661404237640216,
      "grad_norm": 0.40375518798828125,
      "learning_rate": 1e-05,
      "loss": 0.4127,
      "step": 1592
    },
    {
      "epoch": 0.6622351474864977,
      "grad_norm": 0.3843057453632355,
      "learning_rate": 1e-05,
      "loss": 0.3983,
      "step": 1594
    },
    {
      "epoch": 0.6630660573327793,
      "grad_norm": 0.36339709162712097,
      "learning_rate": 1e-05,
      "loss": 0.3882,
      "step": 1596
    },
    {
      "epoch": 0.6638969671790611,
      "grad_norm": 0.3820953667163849,
      "learning_rate": 1e-05,
      "loss": 0.39,
      "step": 1598
    },
    {
      "epoch": 0.6647278770253428,
      "grad_norm": 0.40530359745025635,
      "learning_rate": 1e-05,
      "loss": 0.3963,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_alpaca_gpt4_zh.json_loss": 1.3773400783538818,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4668,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 446.546,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 19.089,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_ultrainteract_sft.json_loss": 0.44468316435813904,
      "eval_ultrainteract_sft.json_runtime": 18.0849,
      "eval_ultrainteract_sft.json_samples_per_second": 158.696,
      "eval_ultrainteract_sft.json_steps_per_second": 6.635,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_code_feedback_multi_turn.json_loss": 0.5617782473564148,
      "eval_code_feedback_multi_turn.json_runtime": 15.4325,
      "eval_code_feedback_multi_turn.json_samples_per_second": 65.835,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.786,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_tested_143k_python_alpaca.json_loss": 0.33946192264556885,
      "eval_tested_143k_python_alpaca.json_runtime": 14.1169,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.201,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.871,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_synthetic_text_to_sql.json_loss": 0.1667151153087616,
      "eval_synthetic_text_to_sql.json_runtime": 3.3397,
      "eval_synthetic_text_to_sql.json_samples_per_second": 417.697,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.666,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_codefeedback_filtered_instruction.json_loss": 0.3807128965854645,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0101,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.023,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.293,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_train_data_for_qwen.json_loss": 0.013592731207609177,
      "eval_train_data_for_qwen.json_runtime": 3.6596,
      "eval_train_data_for_qwen.json_samples_per_second": 120.233,
      "eval_train_data_for_qwen.json_steps_per_second": 5.192,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.41326105594635,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8867,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 394.871,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.961,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_all_merge_code.json_loss": 0.21458129584789276,
      "eval_all_merge_code.json_runtime": 16.8274,
      "eval_all_merge_code.json_samples_per_second": 205.736,
      "eval_all_merge_code.json_steps_per_second": 8.617,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_xlam_function_calling_60k.json_loss": 0.019211100414395332,
      "eval_xlam_function_calling_60k.json_runtime": 4.4465,
      "eval_xlam_function_calling_60k.json_samples_per_second": 199.483,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.321,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_table_python_code_datas.json_loss": 0.15095511078834534,
      "eval_table_python_code_datas.json_runtime": 66.4682,
      "eval_table_python_code_datas.json_samples_per_second": 70.169,
      "eval_table_python_code_datas.json_steps_per_second": 2.934,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_Table_GPT.json_loss": 0.05785409361124039,
      "eval_Table_GPT.json_runtime": 10.6414,
      "eval_Table_GPT.json_samples_per_second": 83.354,
      "eval_Table_GPT.json_steps_per_second": 3.477,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_tabular_llm_data.json_loss": 0.1039615198969841,
      "eval_tabular_llm_data.json_runtime": 50.7536,
      "eval_tabular_llm_data.json_samples_per_second": 57.73,
      "eval_tabular_llm_data.json_steps_per_second": 2.423,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_gpt_4o_200k.json_loss": 0.8484693765640259,
      "eval_gpt_4o_200k.json_runtime": 27.2902,
      "eval_gpt_4o_200k.json_samples_per_second": 130.853,
      "eval_gpt_4o_200k.json_steps_per_second": 5.46,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_MathInstruct.json_loss": 0.17541150748729706,
      "eval_MathInstruct.json_runtime": 12.9853,
      "eval_MathInstruct.json_samples_per_second": 252.209,
      "eval_MathInstruct.json_steps_per_second": 10.55,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_alpaca_cleaned.json_loss": 0.9335516095161438,
      "eval_alpaca_cleaned.json_runtime": 2.3838,
      "eval_alpaca_cleaned.json_samples_per_second": 373.359,
      "eval_alpaca_cleaned.json_steps_per_second": 15.941,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_multi_turn_datas_0816.json_loss": 0.2813113033771515,
      "eval_multi_turn_datas_0816.json_runtime": 71.1467,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.487,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.403,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_sharegpt_gpt4.json_loss": 0.7364738583564758,
      "eval_sharegpt_gpt4.json_runtime": 21.7362,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.847,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.806,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_python_code_critic_21k.json_loss": 0.6199436187744141,
      "eval_python_code_critic_21k.json_runtime": 1.9525,
      "eval_python_code_critic_21k.json_samples_per_second": 148.017,
      "eval_python_code_critic_21k.json_steps_per_second": 6.658,
      "step": 1600
    },
    {
      "epoch": 0.6647278770253428,
      "eval_agent_instruct.json_loss": 0.20446376502513885,
      "eval_agent_instruct.json_runtime": 0.2437,
      "eval_agent_instruct.json_samples_per_second": 90.265,
      "eval_agent_instruct.json_steps_per_second": 4.103,
      "step": 1600
    },
    {
      "epoch": 0.6655587868716244,
      "grad_norm": 0.374536395072937,
      "learning_rate": 1e-05,
      "loss": 0.4071,
      "step": 1602
    },
    {
      "epoch": 0.6663896967179062,
      "grad_norm": 0.36786890029907227,
      "learning_rate": 1e-05,
      "loss": 0.3842,
      "step": 1604
    },
    {
      "epoch": 0.6672206065641878,
      "grad_norm": 0.3683464229106903,
      "learning_rate": 1e-05,
      "loss": 0.3876,
      "step": 1606
    },
    {
      "epoch": 0.6680515164104694,
      "grad_norm": 0.3909376263618469,
      "learning_rate": 1e-05,
      "loss": 0.3903,
      "step": 1608
    },
    {
      "epoch": 0.6688824262567511,
      "grad_norm": 0.40142926573753357,
      "learning_rate": 1e-05,
      "loss": 0.3988,
      "step": 1610
    },
    {
      "epoch": 0.6697133361030329,
      "grad_norm": 0.3999320864677429,
      "learning_rate": 1e-05,
      "loss": 0.4001,
      "step": 1612
    },
    {
      "epoch": 0.6705442459493145,
      "grad_norm": 0.3805783987045288,
      "learning_rate": 1e-05,
      "loss": 0.4026,
      "step": 1614
    },
    {
      "epoch": 0.6713751557955961,
      "grad_norm": 0.3708449602127075,
      "learning_rate": 1e-05,
      "loss": 0.3912,
      "step": 1616
    },
    {
      "epoch": 0.6722060656418779,
      "grad_norm": 0.396992951631546,
      "learning_rate": 1e-05,
      "loss": 0.3892,
      "step": 1618
    },
    {
      "epoch": 0.6730369754881596,
      "grad_norm": 0.3861373960971832,
      "learning_rate": 1e-05,
      "loss": 0.3902,
      "step": 1620
    },
    {
      "epoch": 0.6738678853344412,
      "grad_norm": 0.385542094707489,
      "learning_rate": 1e-05,
      "loss": 0.412,
      "step": 1622
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 0.39261847734451294,
      "learning_rate": 1e-05,
      "loss": 0.3945,
      "step": 1624
    },
    {
      "epoch": 0.6755297050270046,
      "grad_norm": 0.3930520713329315,
      "learning_rate": 1e-05,
      "loss": 0.3989,
      "step": 1626
    },
    {
      "epoch": 0.6763606148732862,
      "grad_norm": 0.3651345372200012,
      "learning_rate": 1e-05,
      "loss": 0.3705,
      "step": 1628
    },
    {
      "epoch": 0.6771915247195679,
      "grad_norm": 0.3996664583683014,
      "learning_rate": 1e-05,
      "loss": 0.397,
      "step": 1630
    },
    {
      "epoch": 0.6780224345658497,
      "grad_norm": 0.38902899622917175,
      "learning_rate": 1e-05,
      "loss": 0.3943,
      "step": 1632
    },
    {
      "epoch": 0.6788533444121313,
      "grad_norm": 0.3788131773471832,
      "learning_rate": 1e-05,
      "loss": 0.4031,
      "step": 1634
    },
    {
      "epoch": 0.679684254258413,
      "grad_norm": 0.3756197690963745,
      "learning_rate": 1e-05,
      "loss": 0.3957,
      "step": 1636
    },
    {
      "epoch": 0.6805151641046946,
      "grad_norm": 0.39925459027290344,
      "learning_rate": 1e-05,
      "loss": 0.3935,
      "step": 1638
    },
    {
      "epoch": 0.6813460739509763,
      "grad_norm": 0.3786354959011078,
      "learning_rate": 1e-05,
      "loss": 0.4071,
      "step": 1640
    },
    {
      "epoch": 0.682176983797258,
      "grad_norm": 0.3901037275791168,
      "learning_rate": 1e-05,
      "loss": 0.3926,
      "step": 1642
    },
    {
      "epoch": 0.6830078936435396,
      "grad_norm": 0.40761223435401917,
      "learning_rate": 1e-05,
      "loss": 0.3852,
      "step": 1644
    },
    {
      "epoch": 0.6838388034898214,
      "grad_norm": 0.37521082162857056,
      "learning_rate": 1e-05,
      "loss": 0.3946,
      "step": 1646
    },
    {
      "epoch": 0.684669713336103,
      "grad_norm": 0.4173513352870941,
      "learning_rate": 1e-05,
      "loss": 0.3948,
      "step": 1648
    },
    {
      "epoch": 0.6855006231823847,
      "grad_norm": 0.3909183442592621,
      "learning_rate": 1e-05,
      "loss": 0.3992,
      "step": 1650
    },
    {
      "epoch": 0.6863315330286663,
      "grad_norm": 0.3774026930332184,
      "learning_rate": 1e-05,
      "loss": 0.3812,
      "step": 1652
    },
    {
      "epoch": 0.6871624428749481,
      "grad_norm": 0.4014265537261963,
      "learning_rate": 1e-05,
      "loss": 0.3912,
      "step": 1654
    },
    {
      "epoch": 0.6879933527212297,
      "grad_norm": 0.40009644627571106,
      "learning_rate": 1e-05,
      "loss": 0.3801,
      "step": 1656
    },
    {
      "epoch": 0.6888242625675114,
      "grad_norm": 0.38964182138442993,
      "learning_rate": 1e-05,
      "loss": 0.3998,
      "step": 1658
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.37672853469848633,
      "learning_rate": 1e-05,
      "loss": 0.3968,
      "step": 1660
    },
    {
      "epoch": 0.6904860822600748,
      "grad_norm": 0.3893624246120453,
      "learning_rate": 1e-05,
      "loss": 0.4003,
      "step": 1662
    },
    {
      "epoch": 0.6913169921063564,
      "grad_norm": 0.382771372795105,
      "learning_rate": 1e-05,
      "loss": 0.3855,
      "step": 1664
    },
    {
      "epoch": 0.6921479019526381,
      "grad_norm": 0.36974939703941345,
      "learning_rate": 1e-05,
      "loss": 0.3792,
      "step": 1666
    },
    {
      "epoch": 0.6929788117989198,
      "grad_norm": 0.3828820288181305,
      "learning_rate": 1e-05,
      "loss": 0.391,
      "step": 1668
    },
    {
      "epoch": 0.6938097216452015,
      "grad_norm": 0.3604958653450012,
      "learning_rate": 1e-05,
      "loss": 0.3931,
      "step": 1670
    },
    {
      "epoch": 0.6946406314914831,
      "grad_norm": 0.4006652235984802,
      "learning_rate": 1e-05,
      "loss": 0.3854,
      "step": 1672
    },
    {
      "epoch": 0.6954715413377649,
      "grad_norm": 0.38409027457237244,
      "learning_rate": 1e-05,
      "loss": 0.3882,
      "step": 1674
    },
    {
      "epoch": 0.6963024511840465,
      "grad_norm": 0.3934977650642395,
      "learning_rate": 1e-05,
      "loss": 0.3947,
      "step": 1676
    },
    {
      "epoch": 0.6971333610303282,
      "grad_norm": 0.3991418182849884,
      "learning_rate": 1e-05,
      "loss": 0.3893,
      "step": 1678
    },
    {
      "epoch": 0.6979642708766098,
      "grad_norm": 0.397217720746994,
      "learning_rate": 1e-05,
      "loss": 0.4041,
      "step": 1680
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 0.37988707423210144,
      "learning_rate": 1e-05,
      "loss": 0.4076,
      "step": 1682
    },
    {
      "epoch": 0.6996260905691732,
      "grad_norm": 0.37393924593925476,
      "learning_rate": 1e-05,
      "loss": 0.4031,
      "step": 1684
    },
    {
      "epoch": 0.7004570004154549,
      "grad_norm": 0.3735659122467041,
      "learning_rate": 1e-05,
      "loss": 0.3824,
      "step": 1686
    },
    {
      "epoch": 0.7012879102617366,
      "grad_norm": 0.4098476767539978,
      "learning_rate": 1e-05,
      "loss": 0.4022,
      "step": 1688
    },
    {
      "epoch": 0.7021188201080183,
      "grad_norm": 0.3944278359413147,
      "learning_rate": 1e-05,
      "loss": 0.3891,
      "step": 1690
    },
    {
      "epoch": 0.7029497299542999,
      "grad_norm": 0.37695810198783875,
      "learning_rate": 1e-05,
      "loss": 0.3833,
      "step": 1692
    },
    {
      "epoch": 0.7037806398005816,
      "grad_norm": 0.3773661255836487,
      "learning_rate": 1e-05,
      "loss": 0.3927,
      "step": 1694
    },
    {
      "epoch": 0.7046115496468633,
      "grad_norm": 0.39600786566734314,
      "learning_rate": 1e-05,
      "loss": 0.3879,
      "step": 1696
    },
    {
      "epoch": 0.705442459493145,
      "grad_norm": 0.3877989649772644,
      "learning_rate": 1e-05,
      "loss": 0.3842,
      "step": 1698
    },
    {
      "epoch": 0.7062733693394266,
      "grad_norm": 0.3853127062320709,
      "learning_rate": 1e-05,
      "loss": 0.3932,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_alpaca_gpt4_zh.json_loss": 1.372586727142334,
      "eval_alpaca_gpt4_zh.json_runtime": 1.466,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 446.799,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 19.1,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_ultrainteract_sft.json_loss": 0.4429360330104828,
      "eval_ultrainteract_sft.json_runtime": 18.0046,
      "eval_ultrainteract_sft.json_samples_per_second": 159.404,
      "eval_ultrainteract_sft.json_steps_per_second": 6.665,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_code_feedback_multi_turn.json_loss": 0.5586556196212769,
      "eval_code_feedback_multi_turn.json_runtime": 15.3997,
      "eval_code_feedback_multi_turn.json_samples_per_second": 65.975,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.792,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_tested_143k_python_alpaca.json_loss": 0.33648404479026794,
      "eval_tested_143k_python_alpaca.json_runtime": 14.445,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 160.471,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.715,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_synthetic_text_to_sql.json_loss": 0.16628913581371307,
      "eval_synthetic_text_to_sql.json_runtime": 3.3305,
      "eval_synthetic_text_to_sql.json_samples_per_second": 418.855,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.715,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_codefeedback_filtered_instruction.json_loss": 0.3773447573184967,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0104,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.018,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.292,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_train_data_for_qwen.json_loss": 0.014143863692879677,
      "eval_train_data_for_qwen.json_runtime": 3.6756,
      "eval_train_data_for_qwen.json_samples_per_second": 119.707,
      "eval_train_data_for_qwen.json_steps_per_second": 5.169,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4108377695083618,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.9104,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 389.973,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.751,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_all_merge_code.json_loss": 0.2105834037065506,
      "eval_all_merge_code.json_runtime": 16.7926,
      "eval_all_merge_code.json_samples_per_second": 206.163,
      "eval_all_merge_code.json_steps_per_second": 8.635,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_xlam_function_calling_60k.json_loss": 0.018564319238066673,
      "eval_xlam_function_calling_60k.json_runtime": 4.398,
      "eval_xlam_function_calling_60k.json_samples_per_second": 201.685,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.413,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_table_python_code_datas.json_loss": 0.1498892605304718,
      "eval_table_python_code_datas.json_runtime": 66.9617,
      "eval_table_python_code_datas.json_samples_per_second": 69.652,
      "eval_table_python_code_datas.json_steps_per_second": 2.912,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_Table_GPT.json_loss": 0.058944545686244965,
      "eval_Table_GPT.json_runtime": 10.6219,
      "eval_Table_GPT.json_samples_per_second": 83.506,
      "eval_Table_GPT.json_steps_per_second": 3.483,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_tabular_llm_data.json_loss": 0.10512414574623108,
      "eval_tabular_llm_data.json_runtime": 50.5661,
      "eval_tabular_llm_data.json_samples_per_second": 57.944,
      "eval_tabular_llm_data.json_steps_per_second": 2.432,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_gpt_4o_200k.json_loss": 0.848205029964447,
      "eval_gpt_4o_200k.json_runtime": 27.4014,
      "eval_gpt_4o_200k.json_samples_per_second": 130.322,
      "eval_gpt_4o_200k.json_steps_per_second": 5.438,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_MathInstruct.json_loss": 0.17442595958709717,
      "eval_MathInstruct.json_runtime": 12.9453,
      "eval_MathInstruct.json_samples_per_second": 252.988,
      "eval_MathInstruct.json_steps_per_second": 10.583,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_alpaca_cleaned.json_loss": 0.9318088889122009,
      "eval_alpaca_cleaned.json_runtime": 2.4544,
      "eval_alpaca_cleaned.json_samples_per_second": 362.615,
      "eval_alpaca_cleaned.json_steps_per_second": 15.482,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_multi_turn_datas_0816.json_loss": 0.27406254410743713,
      "eval_multi_turn_datas_0816.json_runtime": 71.6945,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.048,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.385,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_sharegpt_gpt4.json_loss": 0.7333217263221741,
      "eval_sharegpt_gpt4.json_runtime": 21.8497,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.5,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.792,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_python_code_critic_21k.json_loss": 0.6179649829864502,
      "eval_python_code_critic_21k.json_runtime": 1.9645,
      "eval_python_code_critic_21k.json_samples_per_second": 147.11,
      "eval_python_code_critic_21k.json_steps_per_second": 6.617,
      "step": 1700
    },
    {
      "epoch": 0.7062733693394266,
      "eval_agent_instruct.json_loss": 0.20254962146282196,
      "eval_agent_instruct.json_runtime": 0.2428,
      "eval_agent_instruct.json_samples_per_second": 90.613,
      "eval_agent_instruct.json_steps_per_second": 4.119,
      "step": 1700
    },
    {
      "epoch": 0.7071042791857084,
      "grad_norm": 0.3821764588356018,
      "learning_rate": 1e-05,
      "loss": 0.3844,
      "step": 1702
    },
    {
      "epoch": 0.70793518903199,
      "grad_norm": 0.38821300864219666,
      "learning_rate": 1e-05,
      "loss": 0.3807,
      "step": 1704
    },
    {
      "epoch": 0.7087660988782717,
      "grad_norm": 0.3925268054008484,
      "learning_rate": 1e-05,
      "loss": 0.3889,
      "step": 1706
    },
    {
      "epoch": 0.7095970087245533,
      "grad_norm": 0.3779332637786865,
      "learning_rate": 1e-05,
      "loss": 0.393,
      "step": 1708
    },
    {
      "epoch": 0.7104279185708351,
      "grad_norm": 0.3771838843822479,
      "learning_rate": 1e-05,
      "loss": 0.3867,
      "step": 1710
    },
    {
      "epoch": 0.7112588284171167,
      "grad_norm": 0.41636884212493896,
      "learning_rate": 1e-05,
      "loss": 0.3847,
      "step": 1712
    },
    {
      "epoch": 0.7120897382633984,
      "grad_norm": 0.37215402722358704,
      "learning_rate": 1e-05,
      "loss": 0.3839,
      "step": 1714
    },
    {
      "epoch": 0.7129206481096801,
      "grad_norm": 0.40045323967933655,
      "learning_rate": 1e-05,
      "loss": 0.3917,
      "step": 1716
    },
    {
      "epoch": 0.7137515579559618,
      "grad_norm": 0.3978826403617859,
      "learning_rate": 1e-05,
      "loss": 0.4033,
      "step": 1718
    },
    {
      "epoch": 0.7145824678022434,
      "grad_norm": 0.3942776322364807,
      "learning_rate": 1e-05,
      "loss": 0.3956,
      "step": 1720
    },
    {
      "epoch": 0.7154133776485251,
      "grad_norm": 0.4055032730102539,
      "learning_rate": 1e-05,
      "loss": 0.4011,
      "step": 1722
    },
    {
      "epoch": 0.7162442874948068,
      "grad_norm": 0.35816439986228943,
      "learning_rate": 1e-05,
      "loss": 0.3969,
      "step": 1724
    },
    {
      "epoch": 0.7170751973410885,
      "grad_norm": 0.3591909110546112,
      "learning_rate": 1e-05,
      "loss": 0.3991,
      "step": 1726
    },
    {
      "epoch": 0.7179061071873701,
      "grad_norm": 0.38122379779815674,
      "learning_rate": 1e-05,
      "loss": 0.3865,
      "step": 1728
    },
    {
      "epoch": 0.7187370170336519,
      "grad_norm": 0.3699202537536621,
      "learning_rate": 1e-05,
      "loss": 0.3805,
      "step": 1730
    },
    {
      "epoch": 0.7195679268799335,
      "grad_norm": 0.3963080644607544,
      "learning_rate": 1e-05,
      "loss": 0.3827,
      "step": 1732
    },
    {
      "epoch": 0.7203988367262152,
      "grad_norm": 0.39928168058395386,
      "learning_rate": 1e-05,
      "loss": 0.3792,
      "step": 1734
    },
    {
      "epoch": 0.7212297465724968,
      "grad_norm": 0.3789239525794983,
      "learning_rate": 1e-05,
      "loss": 0.3916,
      "step": 1736
    },
    {
      "epoch": 0.7220606564187786,
      "grad_norm": 0.3801620304584503,
      "learning_rate": 1e-05,
      "loss": 0.3892,
      "step": 1738
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 0.3901013433933258,
      "learning_rate": 1e-05,
      "loss": 0.3939,
      "step": 1740
    },
    {
      "epoch": 0.7237224761113419,
      "grad_norm": 0.400133341550827,
      "learning_rate": 1e-05,
      "loss": 0.3936,
      "step": 1742
    },
    {
      "epoch": 0.7245533859576236,
      "grad_norm": 0.4058607518672943,
      "learning_rate": 1e-05,
      "loss": 0.3839,
      "step": 1744
    },
    {
      "epoch": 0.7253842958039053,
      "grad_norm": 0.391688734292984,
      "learning_rate": 1e-05,
      "loss": 0.3866,
      "step": 1746
    },
    {
      "epoch": 0.7262152056501869,
      "grad_norm": 0.36831173300743103,
      "learning_rate": 1e-05,
      "loss": 0.3988,
      "step": 1748
    },
    {
      "epoch": 0.7270461154964686,
      "grad_norm": 0.4061128795146942,
      "learning_rate": 1e-05,
      "loss": 0.3739,
      "step": 1750
    },
    {
      "epoch": 0.7278770253427503,
      "grad_norm": 0.36268672347068787,
      "learning_rate": 1e-05,
      "loss": 0.3789,
      "step": 1752
    },
    {
      "epoch": 0.728707935189032,
      "grad_norm": 0.38043609261512756,
      "learning_rate": 1e-05,
      "loss": 0.3926,
      "step": 1754
    },
    {
      "epoch": 0.7295388450353136,
      "grad_norm": 0.3850746154785156,
      "learning_rate": 1e-05,
      "loss": 0.3942,
      "step": 1756
    },
    {
      "epoch": 0.7303697548815954,
      "grad_norm": 0.40683799982070923,
      "learning_rate": 1e-05,
      "loss": 0.3891,
      "step": 1758
    },
    {
      "epoch": 0.731200664727877,
      "grad_norm": 0.38436323404312134,
      "learning_rate": 1e-05,
      "loss": 0.3974,
      "step": 1760
    },
    {
      "epoch": 0.7320315745741587,
      "grad_norm": 0.37668997049331665,
      "learning_rate": 1e-05,
      "loss": 0.3841,
      "step": 1762
    },
    {
      "epoch": 0.7328624844204403,
      "grad_norm": 0.4013286828994751,
      "learning_rate": 1e-05,
      "loss": 0.4131,
      "step": 1764
    },
    {
      "epoch": 0.7336933942667221,
      "grad_norm": 0.39920127391815186,
      "learning_rate": 1e-05,
      "loss": 0.3791,
      "step": 1766
    },
    {
      "epoch": 0.7345243041130037,
      "grad_norm": 0.38598915934562683,
      "learning_rate": 1e-05,
      "loss": 0.3903,
      "step": 1768
    },
    {
      "epoch": 0.7353552139592854,
      "grad_norm": 0.3962099552154541,
      "learning_rate": 1e-05,
      "loss": 0.3981,
      "step": 1770
    },
    {
      "epoch": 0.7361861238055671,
      "grad_norm": 0.3980482220649719,
      "learning_rate": 1e-05,
      "loss": 0.3856,
      "step": 1772
    },
    {
      "epoch": 0.7370170336518488,
      "grad_norm": 0.40845006704330444,
      "learning_rate": 1e-05,
      "loss": 0.3946,
      "step": 1774
    },
    {
      "epoch": 0.7378479434981304,
      "grad_norm": 0.3795938789844513,
      "learning_rate": 1e-05,
      "loss": 0.386,
      "step": 1776
    },
    {
      "epoch": 0.7386788533444121,
      "grad_norm": 0.3900623917579651,
      "learning_rate": 1e-05,
      "loss": 0.3892,
      "step": 1778
    },
    {
      "epoch": 0.7395097631906938,
      "grad_norm": 0.3808479309082031,
      "learning_rate": 1e-05,
      "loss": 0.3908,
      "step": 1780
    },
    {
      "epoch": 0.7403406730369755,
      "grad_norm": 0.3916843831539154,
      "learning_rate": 1e-05,
      "loss": 0.3896,
      "step": 1782
    },
    {
      "epoch": 0.7411715828832571,
      "grad_norm": 0.40731433033943176,
      "learning_rate": 1e-05,
      "loss": 0.3877,
      "step": 1784
    },
    {
      "epoch": 0.7420024927295389,
      "grad_norm": 0.3936115801334381,
      "learning_rate": 1e-05,
      "loss": 0.4073,
      "step": 1786
    },
    {
      "epoch": 0.7428334025758205,
      "grad_norm": 0.373811274766922,
      "learning_rate": 1e-05,
      "loss": 0.3869,
      "step": 1788
    },
    {
      "epoch": 0.7436643124221022,
      "grad_norm": 0.3850429654121399,
      "learning_rate": 1e-05,
      "loss": 0.397,
      "step": 1790
    },
    {
      "epoch": 0.7444952222683838,
      "grad_norm": 0.39711496233940125,
      "learning_rate": 1e-05,
      "loss": 0.3913,
      "step": 1792
    },
    {
      "epoch": 0.7453261321146656,
      "grad_norm": 0.38975709676742554,
      "learning_rate": 1e-05,
      "loss": 0.3841,
      "step": 1794
    },
    {
      "epoch": 0.7461570419609472,
      "grad_norm": 0.38171109557151794,
      "learning_rate": 1e-05,
      "loss": 0.3827,
      "step": 1796
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 0.38662147521972656,
      "learning_rate": 1e-05,
      "loss": 0.3847,
      "step": 1798
    },
    {
      "epoch": 0.7478188616535106,
      "grad_norm": 0.3920147120952606,
      "learning_rate": 1e-05,
      "loss": 0.3982,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_alpaca_gpt4_zh.json_loss": 1.3721518516540527,
      "eval_alpaca_gpt4_zh.json_runtime": 1.4715,
      "eval_alpaca_gpt4_zh.json_samples_per_second": 445.134,
      "eval_alpaca_gpt4_zh.json_steps_per_second": 19.029,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_ultrainteract_sft.json_loss": 0.4420817196369171,
      "eval_ultrainteract_sft.json_runtime": 18.062,
      "eval_ultrainteract_sft.json_samples_per_second": 158.897,
      "eval_ultrainteract_sft.json_steps_per_second": 6.644,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_code_feedback_multi_turn.json_loss": 0.5585647821426392,
      "eval_code_feedback_multi_turn.json_runtime": 16.0084,
      "eval_code_feedback_multi_turn.json_samples_per_second": 63.467,
      "eval_code_feedback_multi_turn.json_steps_per_second": 2.686,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_tested_143k_python_alpaca.json_loss": 0.3365645408630371,
      "eval_tested_143k_python_alpaca.json_runtime": 14.0901,
      "eval_tested_143k_python_alpaca.json_samples_per_second": 164.513,
      "eval_tested_143k_python_alpaca.json_steps_per_second": 6.884,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_synthetic_text_to_sql.json_loss": 0.16514596343040466,
      "eval_synthetic_text_to_sql.json_runtime": 3.4561,
      "eval_synthetic_text_to_sql.json_samples_per_second": 403.631,
      "eval_synthetic_text_to_sql.json_steps_per_second": 17.071,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_codefeedback_filtered_instruction.json_loss": 0.3755227029323578,
      "eval_codefeedback_filtered_instruction.json_runtime": 10.0001,
      "eval_codefeedback_filtered_instruction.json_samples_per_second": 175.198,
      "eval_codefeedback_filtered_instruction.json_steps_per_second": 7.3,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_train_data_for_qwen.json_loss": 0.012360488064587116,
      "eval_train_data_for_qwen.json_runtime": 3.6828,
      "eval_train_data_for_qwen.json_samples_per_second": 119.474,
      "eval_train_data_for_qwen.json_steps_per_second": 5.159,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_alpaca_data_gpt4_chinese.json_loss": 1.4063692092895508,
      "eval_alpaca_data_gpt4_chinese.json_runtime": 1.8859,
      "eval_alpaca_data_gpt4_chinese.json_samples_per_second": 395.044,
      "eval_alpaca_data_gpt4_chinese.json_steps_per_second": 16.968,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_all_merge_code.json_loss": 0.209135040640831,
      "eval_all_merge_code.json_runtime": 16.828,
      "eval_all_merge_code.json_samples_per_second": 205.728,
      "eval_all_merge_code.json_steps_per_second": 8.617,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_xlam_function_calling_60k.json_loss": 0.01853661984205246,
      "eval_xlam_function_calling_60k.json_runtime": 4.4446,
      "eval_xlam_function_calling_60k.json_samples_per_second": 199.568,
      "eval_xlam_function_calling_60k.json_steps_per_second": 8.325,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_table_python_code_datas.json_loss": 0.1494590789079666,
      "eval_table_python_code_datas.json_runtime": 65.6241,
      "eval_table_python_code_datas.json_samples_per_second": 71.071,
      "eval_table_python_code_datas.json_steps_per_second": 2.971,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_Table_GPT.json_loss": 0.056889377534389496,
      "eval_Table_GPT.json_runtime": 10.6406,
      "eval_Table_GPT.json_samples_per_second": 83.36,
      "eval_Table_GPT.json_steps_per_second": 3.477,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_tabular_llm_data.json_loss": 0.10293608158826828,
      "eval_tabular_llm_data.json_runtime": 50.6331,
      "eval_tabular_llm_data.json_samples_per_second": 57.867,
      "eval_tabular_llm_data.json_steps_per_second": 2.429,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_gpt_4o_200k.json_loss": 0.8484760522842407,
      "eval_gpt_4o_200k.json_runtime": 27.392,
      "eval_gpt_4o_200k.json_samples_per_second": 130.366,
      "eval_gpt_4o_200k.json_steps_per_second": 5.44,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_MathInstruct.json_loss": 0.17498403787612915,
      "eval_MathInstruct.json_runtime": 12.9348,
      "eval_MathInstruct.json_samples_per_second": 253.192,
      "eval_MathInstruct.json_steps_per_second": 10.592,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_alpaca_cleaned.json_loss": 0.931241512298584,
      "eval_alpaca_cleaned.json_runtime": 2.3716,
      "eval_alpaca_cleaned.json_samples_per_second": 375.273,
      "eval_alpaca_cleaned.json_steps_per_second": 16.023,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_multi_turn_datas_0816.json_loss": 0.2654540240764618,
      "eval_multi_turn_datas_0816.json_runtime": 71.5248,
      "eval_multi_turn_datas_0816.json_samples_per_second": 57.183,
      "eval_multi_turn_datas_0816.json_steps_per_second": 2.391,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_sharegpt_gpt4.json_loss": 0.7302489280700684,
      "eval_sharegpt_gpt4.json_runtime": 21.7951,
      "eval_sharegpt_gpt4.json_samples_per_second": 66.666,
      "eval_sharegpt_gpt4.json_steps_per_second": 2.799,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_python_code_critic_21k.json_loss": 0.6166369915008545,
      "eval_python_code_critic_21k.json_runtime": 1.9635,
      "eval_python_code_critic_21k.json_samples_per_second": 147.19,
      "eval_python_code_critic_21k.json_steps_per_second": 6.621,
      "step": 1800
    },
    {
      "epoch": 0.7478188616535106,
      "eval_agent_instruct.json_loss": 0.2036135196685791,
      "eval_agent_instruct.json_runtime": 0.2418,
      "eval_agent_instruct.json_samples_per_second": 90.992,
      "eval_agent_instruct.json_steps_per_second": 4.136,
      "step": 1800
    }
  ],
  "logging_steps": 2,
  "max_steps": 2407,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3125757298267075e+20,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
